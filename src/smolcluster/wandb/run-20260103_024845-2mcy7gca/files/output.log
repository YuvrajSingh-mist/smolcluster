[Leader] Accepted connection from ('127.0.0.1', 57779)
[Leader] Handling worker at ('127.0.0.1', 57779)
2026-01-03 02:49:20,501 - Server - INFO - Handling worker at ('127.0.0.1', 57779)
[Leader] Accepted connection from ('127.0.0.1', 57785)
[Leader] Handling worker at ('127.0.0.1', 57785)
2026-01-03 02:49:32,094 - Server - INFO - Handling worker at ('127.0.0.1', 57785)

[Leader] Starting training for 10 epochs.
[Leader] Starting epoch 1/10
[Leader] Epoch 1, Batch 0: Received gradients from 1/2 workers.
[Leader] Waiting for more gradients for batch 0...
[Leader] Received gradients from worker ('127.0.0.1', 57785) with ID 1 for batch 0
2026-01-03 02:49:32,544 - Server - INFO - Received gradients from worker ('127.0.0.1', 57779) with ID 1 for batch 0
[Leader] Storing gradients from worker 1 for batch 0
2026-01-03 02:49:32,544 - Server - INFO - Received gradients from worker ('127.0.0.1', 57785) with ID 1 for batch 0
[Leader] Storing gradients from worker 1 for batch 0
2026-01-03 02:49:32,546 - Server - INFO - Storing gradients from worker 1 for batch 0

[Leader] Epoch 1, Batch 1: Received gradients from 1/2 workers.
[Leader] Waiting for more gradients for batch 1...
[Leader] Epoch 1, Batch 1: Received gradients from 1/2 workers.
[Leader] Waiting for more gradients for batch 1...
[Leader] Error handling worker ('127.0.0.1', 57785): cannot unpack non-iterable NoneType object
2026-01-03 02:49:32,898 - Server - ERROR - Error handling worker ('127.0.0.1', 57785): cannot unpack non-iterable NoneType object
[Leader] Worker ('127.0.0.1', 57785) disconnected
2026-01-03 02:49:32,899 - Server - INFO - Worker ('127.0.0.1', 57785) disconnected
[Leader] Error handling worker ('127.0.0.1', 57779): cannot unpack non-iterable NoneType object
2026-01-03 02:49:32,926 - Server - ERROR - Error handling worker ('127.0.0.1', 57779): cannot unpack non-iterable NoneType object
[Leader] Worker ('127.0.0.1', 57779) disconnected
2026-01-03 02:49:32,926 - Server - INFO - Worker ('127.0.0.1', 57779) disconnected
[Leader] Epoch 1, Batch 1: Received gradients from 1/2 workers.
[Leader] Waiting for more gradients for batch 1...
[Leader] Timeout waiting for gradients for batch 1. Proceeding with available gradients.
Traceback (most recent call last):
  File "/Users/yuvrajsingh9886/Desktop/smolcluster/src/smolcluster/./server.py", line 321, in <module>
    main()
    ~~~~^^
  File "/Users/yuvrajsingh9886/Desktop/smolcluster/src/smolcluster/./server.py", line 268, in main
    send_message(
    ~~~~~~~~~~~~^
        worker_socket, ("averaged_gradients", batch_idx, worker_reduced)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/yuvrajsingh9886/Desktop/smolcluster/src/smolcluster/utils/common_utils.py", line 11, in send_message
    sock.sendall(struct.pack(">I", len(data)) + data)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
OSError: [Errno 9] Bad file descriptor
