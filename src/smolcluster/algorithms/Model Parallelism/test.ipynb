{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89dfafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "08a02456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"openai-community/gpt2\")\n",
    "config.tie_word_embeddings = False  # Disable weight tying\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "857b92d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.n_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d5d2015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a7984e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=50257, bias=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcdbe27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=50257, bias=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.transformer.h[0]\n",
    "model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "178b325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file\n",
    "\n",
    "state_dict = load_file(\"../../../data/model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49978696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h.0.attn.bias\n",
      "h.0.attn.c_attn.bias\n",
      "h.0.attn.c_attn.weight\n",
      "h.0.attn.c_proj.bias\n",
      "h.0.attn.c_proj.weight\n",
      "h.0.ln_1.bias\n",
      "h.0.ln_1.weight\n",
      "h.0.ln_2.bias\n",
      "h.0.ln_2.weight\n",
      "h.0.mlp.c_fc.bias\n",
      "h.0.mlp.c_fc.weight\n",
      "h.0.mlp.c_proj.bias\n",
      "h.0.mlp.c_proj.weight\n",
      "h.1.attn.bias\n",
      "h.1.attn.c_attn.bias\n",
      "h.1.attn.c_attn.weight\n",
      "h.1.attn.c_proj.bias\n",
      "h.1.attn.c_proj.weight\n",
      "h.1.ln_1.bias\n",
      "h.1.ln_1.weight\n",
      "h.1.ln_2.bias\n",
      "h.1.ln_2.weight\n",
      "h.1.mlp.c_fc.bias\n",
      "h.1.mlp.c_fc.weight\n",
      "h.1.mlp.c_proj.bias\n",
      "h.1.mlp.c_proj.weight\n",
      "h.10.attn.bias\n",
      "h.10.attn.c_attn.bias\n",
      "h.10.attn.c_attn.weight\n",
      "h.10.attn.c_proj.bias\n",
      "h.10.attn.c_proj.weight\n",
      "h.10.ln_1.bias\n",
      "h.10.ln_1.weight\n",
      "h.10.ln_2.bias\n",
      "h.10.ln_2.weight\n",
      "h.10.mlp.c_fc.bias\n",
      "h.10.mlp.c_fc.weight\n",
      "h.10.mlp.c_proj.bias\n",
      "h.10.mlp.c_proj.weight\n",
      "h.11.attn.bias\n",
      "h.11.attn.c_attn.bias\n",
      "h.11.attn.c_attn.weight\n",
      "h.11.attn.c_proj.bias\n",
      "h.11.attn.c_proj.weight\n",
      "h.11.ln_1.bias\n",
      "h.11.ln_1.weight\n",
      "h.11.ln_2.bias\n",
      "h.11.ln_2.weight\n",
      "h.11.mlp.c_fc.bias\n",
      "h.11.mlp.c_fc.weight\n",
      "h.11.mlp.c_proj.bias\n",
      "h.11.mlp.c_proj.weight\n",
      "h.2.attn.bias\n",
      "h.2.attn.c_attn.bias\n",
      "h.2.attn.c_attn.weight\n",
      "h.2.attn.c_proj.bias\n",
      "h.2.attn.c_proj.weight\n",
      "h.2.ln_1.bias\n",
      "h.2.ln_1.weight\n",
      "h.2.ln_2.bias\n",
      "h.2.ln_2.weight\n",
      "h.2.mlp.c_fc.bias\n",
      "h.2.mlp.c_fc.weight\n",
      "h.2.mlp.c_proj.bias\n",
      "h.2.mlp.c_proj.weight\n",
      "h.3.attn.bias\n",
      "h.3.attn.c_attn.bias\n",
      "h.3.attn.c_attn.weight\n",
      "h.3.attn.c_proj.bias\n",
      "h.3.attn.c_proj.weight\n",
      "h.3.ln_1.bias\n",
      "h.3.ln_1.weight\n",
      "h.3.ln_2.bias\n",
      "h.3.ln_2.weight\n",
      "h.3.mlp.c_fc.bias\n",
      "h.3.mlp.c_fc.weight\n",
      "h.3.mlp.c_proj.bias\n",
      "h.3.mlp.c_proj.weight\n",
      "h.4.attn.bias\n",
      "h.4.attn.c_attn.bias\n",
      "h.4.attn.c_attn.weight\n",
      "h.4.attn.c_proj.bias\n",
      "h.4.attn.c_proj.weight\n",
      "h.4.ln_1.bias\n",
      "h.4.ln_1.weight\n",
      "h.4.ln_2.bias\n",
      "h.4.ln_2.weight\n",
      "h.4.mlp.c_fc.bias\n",
      "h.4.mlp.c_fc.weight\n",
      "h.4.mlp.c_proj.bias\n",
      "h.4.mlp.c_proj.weight\n",
      "h.5.attn.bias\n",
      "h.5.attn.c_attn.bias\n",
      "h.5.attn.c_attn.weight\n",
      "h.5.attn.c_proj.bias\n",
      "h.5.attn.c_proj.weight\n",
      "h.5.ln_1.bias\n",
      "h.5.ln_1.weight\n",
      "h.5.ln_2.bias\n",
      "h.5.ln_2.weight\n",
      "h.5.mlp.c_fc.bias\n",
      "h.5.mlp.c_fc.weight\n",
      "h.5.mlp.c_proj.bias\n",
      "h.5.mlp.c_proj.weight\n",
      "h.6.attn.bias\n",
      "h.6.attn.c_attn.bias\n",
      "h.6.attn.c_attn.weight\n",
      "h.6.attn.c_proj.bias\n",
      "h.6.attn.c_proj.weight\n",
      "h.6.ln_1.bias\n",
      "h.6.ln_1.weight\n",
      "h.6.ln_2.bias\n",
      "h.6.ln_2.weight\n",
      "h.6.mlp.c_fc.bias\n",
      "h.6.mlp.c_fc.weight\n",
      "h.6.mlp.c_proj.bias\n",
      "h.6.mlp.c_proj.weight\n",
      "h.7.attn.bias\n",
      "h.7.attn.c_attn.bias\n",
      "h.7.attn.c_attn.weight\n",
      "h.7.attn.c_proj.bias\n",
      "h.7.attn.c_proj.weight\n",
      "h.7.ln_1.bias\n",
      "h.7.ln_1.weight\n",
      "h.7.ln_2.bias\n",
      "h.7.ln_2.weight\n",
      "h.7.mlp.c_fc.bias\n",
      "h.7.mlp.c_fc.weight\n",
      "h.7.mlp.c_proj.bias\n",
      "h.7.mlp.c_proj.weight\n",
      "h.8.attn.bias\n",
      "h.8.attn.c_attn.bias\n",
      "h.8.attn.c_attn.weight\n",
      "h.8.attn.c_proj.bias\n",
      "h.8.attn.c_proj.weight\n",
      "h.8.ln_1.bias\n",
      "h.8.ln_1.weight\n",
      "h.8.ln_2.bias\n",
      "h.8.ln_2.weight\n",
      "h.8.mlp.c_fc.bias\n",
      "h.8.mlp.c_fc.weight\n",
      "h.8.mlp.c_proj.bias\n",
      "h.8.mlp.c_proj.weight\n",
      "h.9.attn.bias\n",
      "h.9.attn.c_attn.bias\n",
      "h.9.attn.c_attn.weight\n",
      "h.9.attn.c_proj.bias\n",
      "h.9.attn.c_proj.weight\n",
      "h.9.ln_1.bias\n",
      "h.9.ln_1.weight\n",
      "h.9.ln_2.bias\n",
      "h.9.ln_2.weight\n",
      "h.9.mlp.c_fc.bias\n",
      "h.9.mlp.c_fc.weight\n",
      "h.9.mlp.c_proj.bias\n",
      "h.9.mlp.c_proj.weight\n",
      "ln_f.bias\n",
      "ln_f.weight\n",
      "wpe.weight\n",
      "wte.weight\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "stage_sd = {}\n",
    "owm_key = [model.transformer.h[0], model.transformer.h[1], model.transformer.ln_f]\n",
    "with safe_open(\"../../../data/model.safetensors\", framework=\"pt\") as f:\n",
    "    for k in f.keys():\n",
    "        print(k)\n",
    "        # if owns_key(k):\n",
    "        #     stage_sd[k] = f.get_tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f07bde17",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "for layer in model.transformer.h:\n",
    "            layers.append(layer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5543e53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6330b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_per_node = 6\n",
    "local_rank = 0\n",
    "out_layers = layers[layers_per_node * local_rank : ((layers_per_node * local_rank) + layers_per_node) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa1ea45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "513f39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "from typing import List\n",
    "import torch\n",
    "from safetensors import safe_open\n",
    "\n",
    "def get_model_per_node(config: AutoConfig, model, num_nodes: int, local_rank: int, model_name: str, weights_path: str) -> List:\n",
    "    \n",
    "    out_layers = {}\n",
    "    results = []\n",
    "    if model_name == 'causal_gpt2':\n",
    "        \n",
    "        total_layers = config.n_layer\n",
    "        \n",
    "        layers_per_node = total_layers // num_nodes\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        for layer in model.transformer.h:\n",
    "            layers.append(layer)     \n",
    "            \n",
    "        if local_rank == 0:\n",
    "            out_layers['model.transformer.wte'] = model.transformer.wte\n",
    "            out_layers['model.transformer.wpe'] = model.transformer.wpe\n",
    "            \n",
    "        \n",
    "        elif local_rank == num_nodes - 1:\n",
    "            selected_layers = layers[layers_per_node * local_rank : ((layers_per_node * local_rank) + layers_per_node) - 1]\n",
    "            \n",
    "            for layer in selected_layers:\n",
    "                out_layers[f'model.transformer.h.{layers.index(layer)}'] = layer\n",
    "                \n",
    "            out_layers['model.transformer.ln_f'] = model.transformer.ln_f   \n",
    "            \n",
    "            out_layers['model.lm_head'] = model.lm_head\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            selected_layers = layers[layers_per_node * local_rank : ((layers_per_node * local_rank) + layers_per_node) - 1]\n",
    "            \n",
    "            for layer in selected_layers:\n",
    "                out_layers[f'model.transformer.h.{layers.index(layer)}'] = layer\n",
    "        \n",
    "        for layer_name, layer in out_layers.items():\n",
    "            for i in layer.named_parameters():\n",
    "                if layer_name == 'model.lm_head':\n",
    "                    results.append(layer_name.split('model.')[1] + '.' + i[0])\n",
    "                else:\n",
    "                    results.append(layer_name.split('model.transformer.')[1] + '.' + i[0])\n",
    "        \n",
    "        \n",
    "                # When building the state dict, remap the keys to match ModuleList indexing\n",
    "       \n",
    "        stage_sd = {}\n",
    "        layer_mapping = {}  # Map original layer index to new ModuleList index\n",
    "\n",
    "        print(out_layers)\n",
    "        # Build mapping for layers\n",
    "        modulelist_idx = 0\n",
    "        for layer_name, layer in out_layers.items():\n",
    "            if 'h.' in layer_name:\n",
    "                # Extract original layer number (e.g., 'model.transformer.h.9' -> 9)\n",
    "                original_idx = int(layer_name.split('h.')[1])\n",
    "                layer_mapping[original_idx] = modulelist_idx\n",
    "                modulelist_idx += 1\n",
    "            elif 'ln_f' in layer_name:\n",
    "                # ln_f is the last layer in ModuleList\n",
    "                layer_mapping['ln_f'] = modulelist_idx\n",
    "                modulelist_idx += 1\n",
    "            elif 'wte' in layer_name:\n",
    "                layer_mapping['wte'] = modulelist_idx\n",
    "                modulelist_idx += 1\n",
    "            elif 'wpe' in layer_name:\n",
    "                layer_mapping['wpe'] = modulelist_idx\n",
    "                modulelist_idx += 1\n",
    "            elif 'lm_head' in layer_name:\n",
    "                layer_mapping['lm_head'] = modulelist_idx\n",
    "                modulelist_idx += 1\n",
    "        \n",
    "        # Load weights with remapped keys\n",
    "        with safe_open(weights_path, framework=\"pt\") as f:\n",
    "            for k in results:\n",
    "                for key in f.keys():\n",
    "                    if k == key:\n",
    "                        # Remap the key to match ModuleList indexing\n",
    "                        if 'h.' in k:\n",
    "                            original_idx = int(k.split('h.')[1].split('.')[0])\n",
    "                            new_idx = layer_mapping[original_idx]\n",
    "                            # Replace h.9 with 0, h.10 with 1, etc.\n",
    "                            new_key = k.replace(f'h.{original_idx}', str(new_idx))\n",
    "                        elif 'ln_f' in k:\n",
    "                            new_key = k.replace('ln_f', str(layer_mapping['ln_f']))\n",
    "                        elif 'wpe' in k:\n",
    "                            new_key = k.replace('wpe', str(layer_mapping['wpe']))\n",
    "                        elif 'wte' in k:\n",
    "                            new_key = k.replace('wte', str(layer_mapping['wte']))\n",
    "                        elif 'lm_head' in k:\n",
    "                            new_key = k.replace('lm_head', str(layer_mapping['lm_head']))\n",
    "                        else:\n",
    "                            new_key = k\n",
    "                        \n",
    "                        stage_sd[new_key] = f.get_tensor(k)\n",
    "\n",
    "        # Now load into ModuleList\n",
    "        final_layers = list(out_layers.values())\n",
    "        final_model = torch.nn.ModuleList(final_layers)\n",
    "        loaded_model = final_model.load_state_dict(stage_sd, strict=False)\n",
    "\n",
    "        # Return the model, not the load_state_dict result\n",
    "        return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "71a0b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model.transformer.h.9': GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "), 'model.transformer.h.10': GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "), 'model.transformer.ln_f': LayerNorm((768,), eps=1e-05, elementwise_affine=True), 'model.lm_head': Linear(in_features=768, out_features=50257, bias=False)}\n"
     ]
    }
   ],
   "source": [
    "modelA  = get_model_per_node(config, model, num_nodes=4, local_rank=3, model_name='causal_gpt2', weights_path=\"../../../data/model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e7d0b03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mout_layers\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_layers' is not defined"
     ]
    }
   ],
   "source": [
    "out_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13f48c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b369a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name, layer in out_layers.items():\n",
    "    for i in layer.named_parameters():\n",
    "        results.append(layer_name.split('model.transformer.')[1] + '.' + i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29f0213d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h.9.ln_1.weight',\n",
       " 'h.9.ln_1.bias',\n",
       " 'h.9.attn.c_attn.weight',\n",
       " 'h.9.attn.c_attn.bias',\n",
       " 'h.9.attn.c_proj.weight',\n",
       " 'h.9.attn.c_proj.bias',\n",
       " 'h.9.ln_2.weight',\n",
       " 'h.9.ln_2.bias',\n",
       " 'h.9.mlp.c_fc.weight',\n",
       " 'h.9.mlp.c_fc.bias',\n",
       " 'h.9.mlp.c_proj.weight',\n",
       " 'h.9.mlp.c_proj.bias',\n",
       " 'h.10.ln_1.weight',\n",
       " 'h.10.ln_1.bias',\n",
       " 'h.10.attn.c_attn.weight',\n",
       " 'h.10.attn.c_attn.bias',\n",
       " 'h.10.attn.c_proj.weight',\n",
       " 'h.10.attn.c_proj.bias',\n",
       " 'h.10.ln_2.weight',\n",
       " 'h.10.ln_2.bias',\n",
       " 'h.10.mlp.c_fc.weight',\n",
       " 'h.10.mlp.c_fc.bias',\n",
       " 'h.10.mlp.c_proj.weight',\n",
       " 'h.10.mlp.c_proj.bias',\n",
       " 'ln_f.weight',\n",
       " 'ln_f.bias',\n",
       " 'h.9.ln_1.weight',\n",
       " 'h.9.ln_1.bias',\n",
       " 'h.9.attn.c_attn.weight',\n",
       " 'h.9.attn.c_attn.bias',\n",
       " 'h.9.attn.c_proj.weight',\n",
       " 'h.9.attn.c_proj.bias',\n",
       " 'h.9.ln_2.weight',\n",
       " 'h.9.ln_2.bias',\n",
       " 'h.9.mlp.c_fc.weight',\n",
       " 'h.9.mlp.c_fc.bias',\n",
       " 'h.9.mlp.c_proj.weight',\n",
       " 'h.9.mlp.c_proj.bias',\n",
       " 'h.10.ln_1.weight',\n",
       " 'h.10.ln_1.bias',\n",
       " 'h.10.attn.c_attn.weight',\n",
       " 'h.10.attn.c_attn.bias',\n",
       " 'h.10.attn.c_proj.weight',\n",
       " 'h.10.attn.c_proj.bias',\n",
       " 'h.10.ln_2.weight',\n",
       " 'h.10.ln_2.bias',\n",
       " 'h.10.mlp.c_fc.weight',\n",
       " 'h.10.mlp.c_fc.bias',\n",
       " 'h.10.mlp.c_proj.weight',\n",
       " 'h.10.mlp.c_proj.bias',\n",
       " 'ln_f.weight',\n",
       " 'ln_f.bias']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73da9b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h.0.attn.bias\n",
      "h.0.attn.c_attn.bias\n",
      "h.0.attn.c_attn.weight\n",
      "h.0.attn.c_proj.bias\n",
      "h.0.attn.c_proj.weight\n",
      "h.0.ln_1.bias\n",
      "h.0.ln_1.weight\n",
      "h.0.ln_2.bias\n",
      "h.0.ln_2.weight\n",
      "h.0.mlp.c_fc.bias\n",
      "h.0.mlp.c_fc.weight\n",
      "h.0.mlp.c_proj.bias\n",
      "h.0.mlp.c_proj.weight\n",
      "h.1.attn.bias\n",
      "h.1.attn.c_attn.bias\n",
      "h.1.attn.c_attn.weight\n",
      "h.1.attn.c_proj.bias\n",
      "h.1.attn.c_proj.weight\n",
      "h.1.ln_1.bias\n",
      "h.1.ln_1.weight\n",
      "h.1.ln_2.bias\n",
      "h.1.ln_2.weight\n",
      "h.1.mlp.c_fc.bias\n",
      "h.1.mlp.c_fc.weight\n",
      "h.1.mlp.c_proj.bias\n",
      "h.1.mlp.c_proj.weight\n",
      "h.10.attn.bias\n",
      "h.10.attn.c_attn.bias\n",
      "h.10.attn.c_attn.weight\n",
      "h.10.attn.c_proj.bias\n",
      "h.10.attn.c_proj.weight\n",
      "h.10.ln_1.bias\n",
      "h.10.ln_1.weight\n",
      "h.10.ln_2.bias\n",
      "h.10.ln_2.weight\n",
      "h.10.mlp.c_fc.bias\n",
      "h.10.mlp.c_fc.weight\n",
      "h.10.mlp.c_proj.bias\n",
      "h.10.mlp.c_proj.weight\n",
      "h.11.attn.bias\n",
      "h.11.attn.c_attn.bias\n",
      "h.11.attn.c_attn.weight\n",
      "h.11.attn.c_proj.bias\n",
      "h.11.attn.c_proj.weight\n",
      "h.11.ln_1.bias\n",
      "h.11.ln_1.weight\n",
      "h.11.ln_2.bias\n",
      "h.11.ln_2.weight\n",
      "h.11.mlp.c_fc.bias\n",
      "h.11.mlp.c_fc.weight\n",
      "h.11.mlp.c_proj.bias\n",
      "h.11.mlp.c_proj.weight\n",
      "h.2.attn.bias\n",
      "h.2.attn.c_attn.bias\n",
      "h.2.attn.c_attn.weight\n",
      "h.2.attn.c_proj.bias\n",
      "h.2.attn.c_proj.weight\n",
      "h.2.ln_1.bias\n",
      "h.2.ln_1.weight\n",
      "h.2.ln_2.bias\n",
      "h.2.ln_2.weight\n",
      "h.2.mlp.c_fc.bias\n",
      "h.2.mlp.c_fc.weight\n",
      "h.2.mlp.c_proj.bias\n",
      "h.2.mlp.c_proj.weight\n",
      "h.3.attn.bias\n",
      "h.3.attn.c_attn.bias\n",
      "h.3.attn.c_attn.weight\n",
      "h.3.attn.c_proj.bias\n",
      "h.3.attn.c_proj.weight\n",
      "h.3.ln_1.bias\n",
      "h.3.ln_1.weight\n",
      "h.3.ln_2.bias\n",
      "h.3.ln_2.weight\n",
      "h.3.mlp.c_fc.bias\n",
      "h.3.mlp.c_fc.weight\n",
      "h.3.mlp.c_proj.bias\n",
      "h.3.mlp.c_proj.weight\n",
      "h.4.attn.bias\n",
      "h.4.attn.c_attn.bias\n",
      "h.4.attn.c_attn.weight\n",
      "h.4.attn.c_proj.bias\n",
      "h.4.attn.c_proj.weight\n",
      "h.4.ln_1.bias\n",
      "h.4.ln_1.weight\n",
      "h.4.ln_2.bias\n",
      "h.4.ln_2.weight\n",
      "h.4.mlp.c_fc.bias\n",
      "h.4.mlp.c_fc.weight\n",
      "h.4.mlp.c_proj.bias\n",
      "h.4.mlp.c_proj.weight\n",
      "h.5.attn.bias\n",
      "h.5.attn.c_attn.bias\n",
      "h.5.attn.c_attn.weight\n",
      "h.5.attn.c_proj.bias\n",
      "h.5.attn.c_proj.weight\n",
      "h.5.ln_1.bias\n",
      "h.5.ln_1.weight\n",
      "h.5.ln_2.bias\n",
      "h.5.ln_2.weight\n",
      "h.5.mlp.c_fc.bias\n",
      "h.5.mlp.c_fc.weight\n",
      "h.5.mlp.c_proj.bias\n",
      "h.5.mlp.c_proj.weight\n",
      "h.6.attn.bias\n",
      "h.6.attn.c_attn.bias\n",
      "h.6.attn.c_attn.weight\n",
      "h.6.attn.c_proj.bias\n",
      "h.6.attn.c_proj.weight\n",
      "h.6.ln_1.bias\n",
      "h.6.ln_1.weight\n",
      "h.6.ln_2.bias\n",
      "h.6.ln_2.weight\n",
      "h.6.mlp.c_fc.bias\n",
      "h.6.mlp.c_fc.weight\n",
      "h.6.mlp.c_proj.bias\n",
      "h.6.mlp.c_proj.weight\n",
      "h.7.attn.bias\n",
      "h.7.attn.c_attn.bias\n",
      "h.7.attn.c_attn.weight\n",
      "h.7.attn.c_proj.bias\n",
      "h.7.attn.c_proj.weight\n",
      "h.7.ln_1.bias\n",
      "h.7.ln_1.weight\n",
      "h.7.ln_2.bias\n",
      "h.7.ln_2.weight\n",
      "h.7.mlp.c_fc.bias\n",
      "h.7.mlp.c_fc.weight\n",
      "h.7.mlp.c_proj.bias\n",
      "h.7.mlp.c_proj.weight\n",
      "h.8.attn.bias\n",
      "h.8.attn.c_attn.bias\n",
      "h.8.attn.c_attn.weight\n",
      "h.8.attn.c_proj.bias\n",
      "h.8.attn.c_proj.weight\n",
      "h.8.ln_1.bias\n",
      "h.8.ln_1.weight\n",
      "h.8.ln_2.bias\n",
      "h.8.ln_2.weight\n",
      "h.8.mlp.c_fc.bias\n",
      "h.8.mlp.c_fc.weight\n",
      "h.8.mlp.c_proj.bias\n",
      "h.8.mlp.c_proj.weight\n",
      "h.9.attn.bias\n",
      "h.9.attn.c_attn.bias\n",
      "h.9.attn.c_attn.weight\n",
      "h.9.attn.c_proj.bias\n",
      "h.9.attn.c_proj.weight\n",
      "h.9.ln_1.bias\n",
      "h.9.ln_1.weight\n",
      "h.9.ln_2.bias\n",
      "h.9.ln_2.weight\n",
      "h.9.mlp.c_fc.bias\n",
      "h.9.mlp.c_fc.weight\n",
      "h.9.mlp.c_proj.bias\n",
      "h.9.mlp.c_proj.weight\n",
      "ln_f.bias\n",
      "ln_f.weight\n",
      "wpe.weight\n",
      "wte.weight\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "stage_sd = {}\n",
    "with safe_open(\"../../../data/model.safetensors\", framework=\"pt\") as f:\n",
    "    # for k in results:\n",
    "    for key in f.keys():\n",
    "        print(key)\n",
    "        # if k == key:\n",
    "            # if k in results:\n",
    "            # key = 'transformer.' + k\n",
    "            # stage_sd[key] = f.get_tensor(k)\n",
    "    #       stage_sd[k] = f.get_tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31a4314f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer.h.9.ln_1.weight': tensor([0.3815, 0.3605, 0.3697, 0.3585, 0.3653, 0.3277, 0.4366, 0.3190, 0.3760,\n",
       "         0.3174, 0.3975, 0.3641, 0.3470, 0.3779, 0.3925, 0.3663, 0.3564, 0.3584,\n",
       "         0.3682, 0.3501, 0.3349, 0.3449, 0.3698, 0.3721, 0.3585, 0.3598, 0.3786,\n",
       "         0.3364, 0.3586, 0.3547, 0.3510, 0.3606, 0.3541, 0.3366, 0.3623, 0.3904,\n",
       "         0.3035, 0.3562, 0.3467, 0.3565, 0.3333, 0.3324, 0.3350, 0.3506, 0.3571,\n",
       "         0.3667, 0.3467, 0.3370, 0.3564, 0.3545, 0.3442, 0.3410, 0.3603, 0.3587,\n",
       "         0.3565, 0.3505, 0.3562, 0.3838, 0.3350, 0.3870, 0.3623, 0.3577, 0.3859,\n",
       "         0.3485, 0.9022, 0.3349, 0.3387, 0.3671, 0.3486, 0.3438, 0.3759, 0.2744,\n",
       "         0.3469, 0.3436, 0.3389, 0.3589, 0.3936, 0.3936, 0.3719, 0.3413, 0.3468,\n",
       "         0.3408, 0.3602, 0.3486, 0.3457, 0.3838, 0.3643, 0.7337, 0.3350, 0.3663,\n",
       "         0.3487, 0.3469, 0.3343, 0.3448, 0.3369, 0.3408, 0.3642, 0.3808, 0.3825,\n",
       "         0.3819, 0.3486, 0.3291, 0.3740, 0.3694, 0.3543, 0.3478, 0.3838, 0.3876,\n",
       "         0.3389, 0.3592, 0.3662, 0.3660, 0.3552, 0.3615, 0.3657, 0.3683, 0.3649,\n",
       "         0.3624, 0.3414, 0.4054, 0.3696, 0.3387, 0.3447, 0.3508, 0.3739, 0.3779,\n",
       "         0.3221, 0.3697, 0.3671, 0.3530, 0.3603, 0.3469, 0.3868, 0.3623, 0.3456,\n",
       "         0.3430, 0.3506, 0.4079, 0.2555, 0.3272, 0.3617, 0.3630, 0.3604, 0.3369,\n",
       "         0.3874, 0.3484, 0.3665, 0.3837, 0.3565, 0.3447, 0.3538, 0.3683, 0.4010,\n",
       "         0.3994, 0.3744, 0.3564, 0.3624, 0.3584, 0.3365, 0.3858, 0.3955, 0.3488,\n",
       "         0.3622, 0.3767, 0.3660, 0.3565, 0.3539, 0.4371, 0.3588, 0.3669, 0.3506,\n",
       "         0.3650, 0.3585, 0.3670, 0.3701, 0.3445, 0.3613, 0.3428, 0.3722, 0.3489,\n",
       "         0.3406, 0.3330, 0.3401, 0.3828, 0.3367, 0.3369, 0.3565, 0.3564, 0.3532,\n",
       "         0.3642, 0.3508, 0.3213, 0.3459, 0.3510, 0.3545, 0.4010, 0.3243, 0.3330,\n",
       "         0.3585, 0.3825, 0.3651, 0.3838, 0.3554, 0.3588, 0.3278, 0.3603, 0.3389,\n",
       "         0.3115, 0.3885, 0.3493, 0.3467, 0.3863, 0.3818, 0.4068, 0.3487, 0.3373,\n",
       "         0.3763, 0.3447, 0.2666, 0.3466, 0.3838, 0.3509, 0.3541, 0.3745, 0.3486,\n",
       "         0.3332, 0.3441, 0.3486, 0.3428, 0.3447, 0.3190, 0.3577, 0.4276, 0.3402,\n",
       "         0.3552, 0.3756, 0.3780, 0.3321, 0.3682, 0.3641, 0.3956, 0.3625, 0.3700,\n",
       "         0.3506, 0.3231, 0.3559, 0.3381, 0.4075, 0.3448, 0.3510, 0.3291, 0.3699,\n",
       "         0.3368, 0.3709, 0.3460, 0.3701, 0.3466, 0.3564, 0.3480, 0.3545, 0.3552,\n",
       "         0.3561, 0.3705, 0.3431, 0.3274, 0.3257, 0.9450, 0.4037, 0.3624, 0.3708,\n",
       "         0.4143, 0.4372, 0.3331, 0.3467, 0.3819, 0.3389, 0.3721, 0.3365, 0.3564,\n",
       "         0.3526, 0.3429, 0.3174, 0.3507, 0.4689, 0.3877, 0.3799, 0.3668, 0.3406,\n",
       "         0.5056, 0.4012, 0.3700, 0.3611, 0.3396, 0.3256, 0.3797, 0.3545, 0.3282,\n",
       "         0.3525, 0.3468, 0.3598, 0.3465, 0.3683, 0.3759, 0.3486, 0.3423, 0.3311,\n",
       "         0.3408, 0.3502, 0.3556, 0.3252, 0.3406, 0.4091, 0.3538, 0.3552, 0.2097,\n",
       "         0.3390, 0.3916, 0.3664, 0.3680, 0.3651, 0.3425, 0.3427, 0.3624, 0.3733,\n",
       "         0.3558, 0.3662, 0.4126, 0.3366, 0.3603, 0.3429, 0.3389, 0.3412, 0.3674,\n",
       "         0.3389, 0.3333, 0.3720, 0.4006, 0.3489, 0.3447, 0.3940, 0.3479, 0.3368,\n",
       "         0.3680, 0.3870, 0.3555, 0.3406, 0.3567, 0.3406, 0.3565, 0.3478, 0.3429,\n",
       "         0.3595, 0.3624, 0.3468, 0.3542, 0.3603, 0.3574, 0.3644, 0.3643, 0.3524,\n",
       "         0.3735, 0.3467, 0.3385, 0.3533, 0.3346, 0.3666, 0.3604, 0.3526, 0.3604,\n",
       "         0.3460, 0.3625, 0.3351, 0.3556, 0.0780, 0.3381, 0.4179, 0.3800, 0.3751,\n",
       "         0.2844, 0.3681, 0.3375, 0.3481, 0.3484, 0.3811, 0.3545, 0.3812, 0.3936,\n",
       "         0.3408, 0.3507, 0.3513, 0.3448, 0.3290, 0.3536, 0.5866, 0.3418, 0.3365,\n",
       "         0.3817, 0.3318, 0.3313, 0.3485, 0.3341, 0.3552, 0.3681, 0.3603, 0.3373,\n",
       "         0.3615, 0.3640, 0.3290, 0.3252, 0.3378, 0.3311, 0.3416, 0.3273, 0.3428,\n",
       "         0.3601, 0.3526, 0.3350, 0.3782, 0.3857, 0.3357, 0.2720, 0.3899, 0.3408,\n",
       "         0.3605, 0.3521, 0.3213, 0.3623, 0.3506, 0.3332, 0.3364, 0.2724, 0.3419,\n",
       "         0.3228, 0.3912, 0.3351, 0.3780, 0.3214, 0.3801, 0.3550, 0.3854, 0.3181,\n",
       "         0.3565, 0.3681, 0.3362, 0.4030, 0.3581, 0.3371, 0.0696, 0.3506, 0.3514,\n",
       "         0.3572, 0.3447, 0.3311, 0.3566, 0.3430, 0.3897, 0.3528, 0.3544, 0.3532,\n",
       "         0.2775, 0.3450, 0.3899, 0.3232, 0.3721, 0.2646, 0.3682, 0.3729, 0.3506,\n",
       "         0.3234, 0.3334, 0.3252, 0.3711, 0.3682, 0.3624, 0.3174, 0.3540, 0.3379,\n",
       "         0.3330, 0.3490, 0.3623, 0.7363, 0.0733, 0.3589, 0.3309, 0.3545, 0.3339,\n",
       "         0.3466, 0.3369, 0.3686, 0.3589, 0.3507, 0.3740, 0.3547, 0.3467, 0.3759,\n",
       "         0.3364, 0.2742, 0.2803, 0.3714, 0.3544, 0.3592, 0.3527, 0.3550, 0.3838,\n",
       "         0.3801, 0.3408, 0.3448, 0.3532, 0.3855, 0.3215, 0.3228, 0.3642, 0.3507,\n",
       "         0.3681, 0.3586, 0.3863, 0.3740, 0.3482, 0.3277, 0.3486, 0.3489, 0.3509,\n",
       "         0.3720, 0.3611, 0.3512, 0.3419, 0.4053, 0.3779, 0.3730, 0.3442, 0.3429,\n",
       "         0.3666, 0.3508, 0.3447, 0.3334, 0.3758, 0.3427, 0.3603, 0.3745, 0.3589,\n",
       "         0.3682, 0.3699, 0.3388, 0.3660, 0.3426, 0.3556, 0.3793, 0.3452, 0.3408,\n",
       "         0.3903, 0.3449, 0.3797, 0.3525, 0.3647, 0.3727, 0.3624, 0.3504, 0.3681,\n",
       "         0.3704, 0.3369, 0.3613, 0.3631, 0.3350, 0.3546, 0.3524, 0.3721, 0.3780,\n",
       "         0.3527, 0.3878, 0.3737, 0.4132, 0.3779, 0.3334, 0.3481, 0.3469, 0.4131,\n",
       "         0.3431, 0.3369, 0.3986, 0.3505, 0.3502, 0.3241, 0.3837, 0.3545, 0.3506,\n",
       "         0.3781, 0.3294, 0.3884, 0.3534, 0.3603, 0.3389, 0.3566, 0.3413, 0.3624,\n",
       "         0.3430, 0.3481, 0.3701, 0.3349, 0.3499, 0.3552, 0.3487, 0.3505, 0.3545,\n",
       "         0.3680, 0.3510, 0.3370, 0.3685, 0.3565, 0.3878, 0.3740, 0.3543, 0.3623,\n",
       "         0.3802, 0.3466, 0.3500, 0.3467, 0.3566, 0.3499, 0.3756, 0.3593, 0.3545,\n",
       "         0.3432, 0.3623, 0.3694, 0.3556, 0.3389, 0.3519, 0.3432, 0.3565, 0.3630,\n",
       "         0.3701, 0.3545, 0.3507, 0.3350, 0.3486, 0.3878, 0.3604, 0.3272, 0.3336,\n",
       "         0.3994, 0.4226, 0.3667, 0.3428, 0.3672, 0.3860, 0.3682, 0.3408, 0.3858,\n",
       "         0.3584, 0.3839, 0.3669, 0.4028, 0.4092, 0.3525, 0.3369, 0.3623, 0.3428,\n",
       "         0.3565, 0.3370, 0.3992, 0.3566, 0.3937, 0.3557, 0.3523, 0.3682, 0.3760,\n",
       "         0.3387, 0.3584, 0.3310, 0.3530, 0.3936, 0.3291, 0.3566, 0.3493, 0.3098,\n",
       "         0.3291, 0.3213, 0.3349, 0.3802, 0.4131, 0.3428, 0.3386, 0.3705, 0.3483,\n",
       "         0.3408, 0.3427, 0.3760, 0.3176, 0.3419, 0.3477, 0.3638, 0.3332, 0.3506,\n",
       "         0.3705, 0.3350, 0.3603, 0.3470, 0.3428, 0.3368, 0.3940, 0.3294, 0.3897,\n",
       "         0.3529, 0.4248, 0.3460, 0.3528, 0.3837, 0.3935, 0.3436, 0.3525, 0.3829,\n",
       "         0.3629, 0.3619, 0.3381, 0.3447, 0.3502, 0.3420, 0.3525, 0.3818, 0.3328,\n",
       "         0.3291, 0.3409, 0.3616, 0.3506, 0.3232, 0.3534, 0.3804, 0.3760, 0.3486,\n",
       "         0.3585, 0.3571, 0.3488, 0.3408, 0.3543, 0.3678, 0.3691, 0.3465, 0.3447,\n",
       "         0.3809, 0.3848, 0.3842, 0.3472, 0.3439, 0.3760, 0.3740, 0.2471, 0.3974,\n",
       "         0.3565, 0.3870, 0.3537, 0.3526, 0.3455, 0.3397, 0.3350, 0.3818, 0.3760,\n",
       "         0.2291, 0.3341, 0.3382, 0.3782, 0.3344, 0.3584, 0.3575, 0.3291, 0.3358,\n",
       "         0.3428, 0.3293, 0.3525]),\n",
       " 'transformer.h.9.ln_1.bias': tensor([ 3.0492e-02,  1.0873e-02,  4.3270e-02,  1.7420e-02, -2.5693e-04,\n",
       "          1.3972e-02, -5.4081e-02,  2.8417e-02,  1.4311e-02,  6.1985e-03,\n",
       "          7.1668e-03,  7.2782e-03,  2.5299e-02,  1.9724e-02,  3.7934e-02,\n",
       "         -1.3185e-03,  3.1771e-02,  3.4832e-02,  6.9418e-03,  7.5766e-03,\n",
       "          2.5131e-02,  2.4309e-02,  1.7464e-02,  2.8942e-02,  2.0046e-02,\n",
       "          1.1927e-02,  4.9463e-03,  1.4933e-02,  3.1305e-02,  5.3658e-03,\n",
       "          8.7908e-03, -1.3974e-02, -1.1042e-02,  1.4675e-02,  2.2177e-02,\n",
       "          4.8724e-02, -3.8153e-03,  7.2784e-03,  2.8098e-02,  4.9011e-03,\n",
       "          3.8378e-03,  4.4482e-03, -4.7649e-03,  1.7485e-02,  3.1325e-02,\n",
       "          2.0469e-02,  1.5536e-02,  9.7983e-03,  5.5255e-03, -4.2110e-03,\n",
       "          2.0810e-02, -9.2583e-04,  1.2394e-02, -5.3090e-03,  1.3071e-02,\n",
       "         -1.4376e-02, -2.2310e-03,  2.1225e-02,  5.3781e-03,  1.9862e-02,\n",
       "          2.2096e-02,  1.6833e-02,  2.8913e-02,  8.3504e-03,  1.2640e+00,\n",
       "          1.1653e-02, -1.2745e-02, -6.7209e-03,  2.8282e-02,  1.9079e-02,\n",
       "          5.7522e-03,  2.3886e-02,  1.8771e-02,  2.0131e-02,  1.9840e-02,\n",
       "          2.2523e-02, -1.7576e-02,  1.6454e-02,  1.6718e-02,  2.6704e-02,\n",
       "          4.2290e-02,  1.6274e-02,  1.9184e-02,  1.7019e-02,  4.9366e-02,\n",
       "          1.6655e-02,  3.0581e-02, -4.8480e-03,  1.4291e-02,  1.7406e-02,\n",
       "          4.8399e-03,  1.4267e-02,  3.2760e-02, -9.3008e-04,  1.6378e-02,\n",
       "          9.3173e-03,  1.1932e-02,  2.2098e-02,  3.0984e-02,  4.8152e-02,\n",
       "          1.5879e-02, -2.4991e-02, -2.9359e-02,  2.0413e-02,  2.3619e-02,\n",
       "          1.5845e-02,  3.2071e-02,  1.5187e-02,  8.8350e-03,  1.6707e-02,\n",
       "          1.1934e-02,  2.7053e-02,  1.4257e-02,  3.5153e-02,  1.1276e-02,\n",
       "          2.8245e-04,  5.0559e-02,  1.4811e-02,  2.7672e-02,  3.8542e-02,\n",
       "          3.5771e-02,  1.2524e-02,  7.9735e-03, -1.6752e-03,  4.0489e-03,\n",
       "          3.3490e-02,  1.1014e-02,  4.2589e-02,  4.1177e-02,  2.3080e-02,\n",
       "          1.9257e-02,  1.4621e-02,  1.2663e-02,  1.1382e-02,  1.2189e-02,\n",
       "          1.4357e-02,  2.1875e-02,  3.8572e-02, -9.7851e-01,  1.8799e-04,\n",
       "          5.6949e-03, -6.7323e-03,  2.7129e-02,  2.1288e-02,  5.6009e-03,\n",
       "         -5.0546e-03, -1.0455e-02,  1.7738e-02,  9.5393e-03,  2.1756e-02,\n",
       "          4.5037e-02, -2.6835e-02,  2.0255e-02,  1.2796e-02,  8.0672e-03,\n",
       "          1.2271e-03,  1.1062e-02,  2.5293e-02,  9.0142e-03, -2.8360e-03,\n",
       "         -3.4980e-02,  2.5504e-02,  8.1569e-03,  2.3866e-02,  1.9978e-02,\n",
       "          4.5272e-02,  3.4002e-03,  1.1349e-01, -3.0909e-04,  2.4132e-02,\n",
       "          1.5031e-02,  1.4289e-02,  2.4586e-02,  1.6743e-02,  2.6241e-02,\n",
       "          1.8351e-02,  6.0749e-02,  1.3744e-02, -9.7299e-03,  8.2542e-03,\n",
       "          1.5036e-02, -2.2009e-03,  2.9051e-02,  2.0967e-02,  4.4107e-02,\n",
       "          1.0594e-02,  4.8096e-03,  1.3991e-02,  1.4999e-02, -5.2220e-03,\n",
       "          1.1884e-02,  3.6578e-02,  3.0015e-02,  2.0630e-02,  2.6151e-02,\n",
       "          8.1315e-02,  2.2292e-02,  3.0108e-02,  4.0327e-02,  1.6590e-02,\n",
       "          9.0357e-03,  8.5139e-03,  1.9155e-02,  2.3388e-02,  5.4928e-03,\n",
       "          1.1643e-02,  3.3528e-02,  1.9696e-02,  2.0762e-02,  6.7627e-03,\n",
       "         -5.3330e-04,  3.8859e-02,  2.8078e-02,  3.3113e-02,  2.9168e-02,\n",
       "          1.4322e-02,  1.4427e-02,  1.9223e-02,  3.2934e-02,  1.7911e-02,\n",
       "          1.4826e-02,  2.7489e-02,  3.4255e-03,  4.4369e-03, -5.8271e-03,\n",
       "          1.2655e-05,  9.8684e-03,  2.6706e-02,  3.1864e-02,  8.0583e-03,\n",
       "          1.7587e-02,  1.7766e-02, -1.5736e-02,  2.1030e-02,  8.9753e-03,\n",
       "          3.8633e-03,  1.6269e-02,  8.4637e-03,  1.9661e-02,  1.6015e-02,\n",
       "          3.1092e-02,  1.2668e-02,  2.3572e-02,  4.7969e-03,  1.8475e-02,\n",
       "          1.0278e-02, -3.5105e-03,  1.8962e-02,  1.6102e-02,  2.2042e-02,\n",
       "          2.7791e-02,  3.3593e-02,  2.7364e-03,  9.1344e-03,  3.4546e-02,\n",
       "         -2.0953e-02,  2.1569e-02,  2.2558e-02, -1.0549e-02,  2.4257e-02,\n",
       "          9.5191e-03,  2.1621e-02,  2.3205e-02, -1.9487e-03,  2.4744e-02,\n",
       "          1.5900e-02, -7.5825e-02, -7.0304e-03,  2.6699e-02,  1.7583e-02,\n",
       "          3.3506e-02,  4.2919e-03,  1.7947e-02, -1.0324e-02, -4.9267e-03,\n",
       "          1.7151e-02,  3.3310e-03,  2.4004e-02,  1.7828e-02,  4.2457e-03,\n",
       "          1.3460e-02,  1.5531e-02,  4.2796e-04,  7.9273e-02,  1.6549e-02,\n",
       "          1.1694e-02,  1.3224e-02,  2.4826e-02, -1.4099e-01,  5.9840e-02,\n",
       "          1.5161e-02,  4.9515e-03,  3.1367e-02,  2.2476e-02,  2.7255e-02,\n",
       "          1.9948e-02,  1.1058e-02,  2.1055e-02,  1.3075e-02,  2.7591e-03,\n",
       "          1.2312e-02,  1.4495e-02, -8.9776e-03,  2.8881e-02,  1.0944e-02,\n",
       "          4.6865e-03,  1.4001e-02,  1.5085e-02,  4.5588e-02,  3.0149e-02,\n",
       "          3.7736e-03,  6.7782e-02,  2.4625e-02,  1.8980e-02,  1.3088e-01,\n",
       "          1.1943e-02,  3.5017e-02, -2.8263e-03,  1.4576e-02,  1.9351e-02,\n",
       "          3.4526e-02,  1.7707e-02,  9.2545e-03,  1.0294e-02, -1.5073e-03,\n",
       "         -7.4645e-03, -2.1486e-01,  1.3212e-02,  1.6797e-02,  2.8523e-02,\n",
       "         -1.9194e-03,  2.9378e-03,  3.3162e-03,  9.9875e-03,  1.2589e-02,\n",
       "          1.8258e-02,  1.4405e-02,  2.0468e-02,  2.4215e-02,  8.1178e-03,\n",
       "          8.9394e-03,  8.3687e-03, -1.6169e-03, -1.9501e-03,  1.3940e-02,\n",
       "         -6.2043e-03, -9.2368e-03,  1.2015e-02, -4.0545e-03,  1.5354e-02,\n",
       "          1.7631e-02, -3.1877e-03,  9.2731e-03,  1.9466e-03, -1.2600e-02,\n",
       "          1.8434e-02,  3.5745e-02,  2.4432e-02,  3.5761e-02,  2.1524e-02,\n",
       "          5.5862e-03,  3.2582e-02, -1.6921e-02,  2.2361e-02,  1.1903e-02,\n",
       "          7.9036e-02,  1.3365e-02,  1.3526e-04, -8.3639e-04,  1.2128e-02,\n",
       "          2.8013e-02, -2.0960e-03,  4.4792e-02,  2.1588e-01,  5.1534e-02,\n",
       "          1.0282e-02,  3.5406e-02, -1.1957e-02,  6.3151e-02,  1.5547e-02,\n",
       "          3.4978e-02,  7.6248e-03,  2.0230e-02,  9.5394e-03,  2.1975e-02,\n",
       "         -2.1745e-02,  1.5206e-02,  2.4135e-02, -4.3635e-03,  3.2644e-02,\n",
       "          2.7837e-02,  2.4270e-02, -1.3464e-02, -2.5990e-01,  4.3669e-02,\n",
       "          1.1335e-02,  4.3247e-02,  1.0057e-02,  2.1309e-02,  1.0001e-02,\n",
       "          2.7655e-02, -1.8995e-02,  1.5746e-02,  6.3277e-03,  1.1677e-04,\n",
       "          2.3379e-02,  5.8150e-03,  2.5217e-02, -4.9475e-02,  1.8588e-02,\n",
       "          2.3623e-02,  1.5584e-02,  2.3759e-02,  1.3985e-02,  2.8896e-02,\n",
       "         -3.7939e-03,  1.8157e-02,  8.9940e-03,  1.9959e-02,  8.2681e-03,\n",
       "          2.1788e-02,  2.7793e-02,  2.8309e-02,  1.6599e-02,  1.2845e-02,\n",
       "          2.5146e-02,  1.4347e-02,  3.1225e-02,  7.0123e-03,  1.4993e-02,\n",
       "         -6.3596e-02,  1.6489e-02,  1.7804e-02,  2.0980e-02,  2.8874e-02,\n",
       "          1.1221e-02,  1.1360e-02,  1.4227e-02,  8.7227e-03, -1.2859e-03,\n",
       "         -4.8777e-03,  7.4109e-03, -2.2111e-02,  2.2965e-02, -6.7598e-03,\n",
       "          9.6770e-03,  3.7641e-02, -6.0150e-02,  3.3126e-02,  5.0289e-03,\n",
       "          9.8868e-03,  5.3616e-03,  2.1815e-02, -4.6418e-03, -6.1248e-03,\n",
       "          1.4572e-02,  3.7026e-02,  2.1172e-02,  1.0499e-02,  5.9143e-04,\n",
       "          1.7518e-02,  7.9348e-04,  2.1479e-02,  1.6420e-02, -1.2433e-02,\n",
       "          1.9114e-02,  1.3894e-02,  1.3655e-02,  1.8253e-02,  3.4881e-03,\n",
       "          4.6841e-02,  1.8069e-02,  1.7672e-02,  2.6934e-02,  2.5695e-02,\n",
       "          2.1822e-02,  2.6906e-02,  2.4229e-02,  2.0002e-02,  4.9879e-02,\n",
       "          2.7866e-01, -6.3525e-02,  2.0515e-02,  1.8086e-02,  4.9788e-03,\n",
       "          1.3468e-03,  2.1840e-02,  1.1516e-02, -1.6606e-02,  2.7777e-02,\n",
       "          1.0955e-03,  3.3796e-02,  1.9485e-02,  2.0462e-02,  9.7305e-03,\n",
       "          2.1445e-02, -5.0352e-02,  4.1499e-02,  1.0300e-02,  1.4353e-02,\n",
       "         -6.8805e-03,  2.0569e-02,  1.2843e-02,  7.1495e-02,  3.1187e-02,\n",
       "          3.4228e-02,  2.3727e-03, -1.0675e-02,  5.3816e-03,  1.1982e-02,\n",
       "          6.9884e-03,  9.1350e-03,  2.6571e-02,  2.1772e-02,  2.0681e-02,\n",
       "          3.1708e-02,  1.4879e-02,  2.2451e-02,  1.8890e-02,  6.7578e-03,\n",
       "          2.0082e-02,  4.8951e-02,  1.7292e-02,  6.5108e-03, -8.2309e-04,\n",
       "          2.0504e-02,  1.4999e-01,  5.3778e-02,  2.3666e-02,  2.1510e-02,\n",
       "          1.0187e-02, -1.3285e-02,  1.3953e-02,  2.2537e-02,  3.3802e-02,\n",
       "          2.6163e-02,  3.1887e-02,  1.0900e-03, -2.0444e-03,  4.8195e-02,\n",
       "         -9.0014e-03,  1.0960e-02, -6.7787e-03,  2.5145e-02,  1.8359e-02,\n",
       "          3.5667e-02,  1.9920e-02,  1.9106e-02,  2.1743e-02,  2.1916e-02,\n",
       "          2.4789e-02,  1.2540e-02,  8.1938e-03,  1.3269e-02,  7.7007e-02,\n",
       "          1.9964e-04,  2.1763e-02,  2.0351e-02,  2.2181e-02,  3.3092e-02,\n",
       "          3.5036e-02,  1.6261e-02,  1.4645e-02,  4.0753e-03,  1.1995e-02,\n",
       "          1.4290e-02,  4.7790e-03,  3.5958e-02,  1.4220e-02,  2.3047e-02,\n",
       "          4.0370e-02,  2.0986e-02,  7.3956e-03,  3.1470e-02,  2.8259e-02,\n",
       "         -2.3865e-02,  3.2087e-02,  1.3662e-02,  4.5868e-02, -8.7525e-03,\n",
       "         -9.3848e-03,  9.0696e-04,  1.7263e-02,  2.6611e-02,  1.3995e-02,\n",
       "         -1.1692e-02,  2.2815e-02,  1.4863e-02,  1.6093e-03,  1.1856e-02,\n",
       "          1.7830e-03,  4.2211e-02,  7.4831e-03,  2.3812e-02,  1.2525e-02,\n",
       "          3.4073e-03,  2.0428e-02, -1.1241e-03,  2.4105e-02,  1.4789e-02,\n",
       "          4.2384e-02,  2.2830e-02,  1.6747e-02,  2.2657e-02,  2.7260e-02,\n",
       "          6.4910e-03,  1.5120e-02,  5.6488e-03, -4.6249e-02, -7.4661e-04,\n",
       "          3.7826e-02,  1.7944e-04,  4.4868e-03,  2.4641e-02,  2.1288e-02,\n",
       "          2.9802e-02,  9.7515e-03,  3.2065e-02,  6.4750e-03,  2.2078e-02,\n",
       "          4.9191e-02,  1.5626e-02,  2.3219e-02,  2.2685e-02,  1.7696e-02,\n",
       "          1.8980e-02,  2.8285e-02,  7.6404e-02, -9.0878e-04,  2.8371e-02,\n",
       "          1.9977e-02,  3.2796e-02,  1.4536e-02,  3.0808e-02, -7.2076e-04,\n",
       "          3.3591e-02,  3.6848e-02,  1.1425e-02,  1.6014e-02,  3.4456e-02,\n",
       "         -1.2892e-01, -9.3180e-03,  2.5703e-02,  2.5299e-02,  2.6678e-02,\n",
       "          4.2309e-02,  2.0138e-02,  2.8523e-02,  5.0709e-03,  6.7703e-02,\n",
       "         -5.5278e-03,  5.0000e-03,  6.7978e-03, -1.3550e-03,  1.7543e-02,\n",
       "          1.5805e-02,  1.2147e-02,  1.3114e-02,  2.6474e-04,  7.2472e-03,\n",
       "          1.2037e-02,  2.9629e-02, -2.3053e-03,  2.7027e-02,  2.8881e-02,\n",
       "         -1.5761e-02,  1.3112e-02,  3.4166e-02,  7.2287e-03, -9.4476e-03,\n",
       "          1.3837e-02,  2.8369e-02,  2.5705e-02,  2.5138e-04,  4.7979e-02,\n",
       "          1.7487e-02,  3.9693e-03,  1.4923e-02,  6.3899e-03, -9.8940e-02,\n",
       "          3.3000e-02, -6.6347e-03,  1.9614e-02,  1.9170e-03,  2.9230e-02,\n",
       "          1.2570e-02,  9.5888e-03,  1.7076e-02,  2.9001e-03,  1.2286e-02,\n",
       "          2.8301e-02,  1.2213e-02,  2.1222e-02, -2.1216e-03,  3.9754e-02,\n",
       "          9.6394e-03,  1.1122e-03,  1.5532e-02, -5.7242e-03,  2.8465e-02,\n",
       "          4.0302e-03,  2.0632e-02,  2.4541e-02,  4.3192e-02,  2.6073e-02,\n",
       "          7.2233e-03,  9.4155e-03,  1.6505e-02,  1.8448e-02, -2.5170e-03,\n",
       "          1.2000e-02,  6.8031e-03,  3.7981e-02,  2.5705e-02,  2.5174e-02,\n",
       "         -7.0208e-03,  7.9762e-03,  1.8266e-02,  5.6669e-03,  1.4118e-02,\n",
       "          2.4259e-03,  1.6194e-02, -1.9699e-03,  3.2739e-03, -1.7505e-02,\n",
       "          1.3951e-02,  5.6820e-03,  1.2771e-03,  4.9013e-02,  2.9891e-02,\n",
       "          7.0213e-03,  3.9604e-02,  4.9489e-02,  1.8771e-02,  3.1523e-02,\n",
       "          3.4107e-02,  1.6705e-02,  6.5625e-03,  2.0344e-02,  5.2166e-02,\n",
       "         -2.3815e-03,  1.9008e-02,  2.4418e-02,  2.8172e-02,  2.1597e-02,\n",
       "          1.1870e-01,  4.4278e-02,  7.0442e-03,  2.6831e-02,  5.4814e-03,\n",
       "          1.6737e-02,  5.6836e-03, -2.3425e-03,  3.3303e-02,  1.6783e-02,\n",
       "          2.6404e-02,  6.4658e-02,  2.0041e-02,  2.8214e-02,  2.0244e-02,\n",
       "          2.8213e-02,  5.7425e-03, -5.8249e-02,  2.1254e-02,  2.6269e-02,\n",
       "          1.4840e-02,  4.4355e-03,  3.8794e-02]),\n",
       " 'transformer.h.9.attn.c_attn.weight': tensor([[ 0.0709, -0.1273,  0.1836,  ..., -0.0371,  0.0620,  0.0426],\n",
       "         [ 0.2491, -0.3088,  0.1739,  ...,  0.1014, -0.1325, -0.0619],\n",
       "         [ 0.1505,  0.0529, -0.1205,  ...,  0.0655, -0.1282,  0.0375],\n",
       "         ...,\n",
       "         [-0.0111, -0.0088,  0.0099,  ...,  0.0024, -0.0112, -0.0260],\n",
       "         [ 0.0894,  0.2280, -0.1021,  ...,  0.2506,  0.1025,  0.0781],\n",
       "         [-0.0792,  0.1721,  0.1188,  ...,  0.0140, -0.1682, -0.0827]]),\n",
       " 'transformer.h.9.attn.c_attn.bias': tensor([ 0.0571,  0.0355, -0.0991,  ...,  0.0075,  0.0219, -0.0241]),\n",
       " 'transformer.h.9.attn.c_proj.weight': tensor([[-0.1317, -0.1278,  0.0167,  ..., -0.0699, -0.0486, -0.1681],\n",
       "         [ 0.2071, -0.0122,  0.1067,  ...,  0.0010,  0.1674,  0.0475],\n",
       "         [-0.0347,  0.1099,  0.1898,  ..., -0.0567,  0.1566,  0.0080],\n",
       "         ...,\n",
       "         [ 0.2263,  0.0637, -0.2822,  ..., -0.0470, -0.1357, -0.1478],\n",
       "         [-0.0238, -0.2313, -0.1668,  ..., -0.2124, -0.0331,  0.1052],\n",
       "         [ 0.1676, -0.0393, -0.2488,  ..., -0.0979,  0.0018,  0.1445]]),\n",
       " 'transformer.h.9.attn.c_proj.bias': tensor([-7.2582e-02,  1.2333e-01,  2.8655e-02, -1.4709e-01,  1.2297e-01,\n",
       "          1.0360e-01,  1.9318e-01,  2.7430e-02, -8.0407e-02,  1.3491e-01,\n",
       "          1.6597e-01, -9.8994e-02,  1.4429e-01, -3.4759e-01, -2.6157e-02,\n",
       "          1.5271e-01, -1.7471e-01, -4.2044e-01, -1.9112e-01,  1.1450e-01,\n",
       "          1.2879e-01, -8.6428e-02, -9.9017e-03, -5.0103e-02,  1.1142e-01,\n",
       "         -5.7536e-02,  2.0482e-01, -2.1330e-01, -1.4227e-01,  5.6776e-02,\n",
       "          9.1843e-02, -9.0276e-02,  1.0440e-01, -4.2728e-02, -1.0183e-01,\n",
       "         -1.3650e-01,  2.9182e-01, -1.2173e-01, -2.1069e-01,  1.1081e-01,\n",
       "          3.7912e-02,  1.7296e-01, -5.7224e-02,  1.0815e-01,  9.0637e-02,\n",
       "          3.5315e-01, -1.2683e-03, -8.6961e-02, -9.5390e-04,  2.0565e-01,\n",
       "         -1.5350e-01,  6.8852e-02, -1.1461e-01,  4.5635e-02, -4.4251e-03,\n",
       "         -2.5045e-02,  3.6877e-01, -2.4420e-01,  3.1386e-01, -1.6493e-01,\n",
       "         -4.3503e-03,  2.1746e-03, -2.8118e-01,  1.5986e-01, -1.5257e-01,\n",
       "          1.2480e-01,  1.5877e-01,  1.5691e-01, -4.9848e-03, -1.8254e-02,\n",
       "         -2.5485e-01, -1.0861e-01, -3.5899e-01,  1.3636e-01, -1.4538e-01,\n",
       "          2.6181e-02,  2.3767e-02, -1.3899e-01,  9.5414e-02,  8.1398e-02,\n",
       "          1.0190e-01, -3.5130e-01, -5.5871e-02, -1.0570e-01, -2.1332e-02,\n",
       "          2.9707e-02, -3.7628e-01, -3.9169e-03, -7.0143e-02,  1.7879e-02,\n",
       "          6.7428e-02,  1.0428e-01, -1.3381e-01, -4.6145e-02, -1.4139e-01,\n",
       "         -1.2468e-01,  1.3649e-02, -1.6937e-01, -3.2049e-01,  2.5405e-01,\n",
       "         -6.0606e-02,  1.8595e-01,  8.4029e-03, -2.4493e-01,  2.0612e-02,\n",
       "          4.8730e-02, -9.4922e-02,  2.0362e-01,  3.8812e-01, -3.5726e-01,\n",
       "         -1.7082e-01, -3.5856e-01, -1.3767e-01, -3.8865e-01,  2.9592e-01,\n",
       "          8.4550e-03, -1.9436e-01,  2.6369e-01, -1.2150e-01, -5.2198e-02,\n",
       "         -2.5585e-01,  7.8323e-02,  1.8257e-01,  3.5808e-01,  7.9579e-02,\n",
       "         -3.4754e-01,  2.9658e-01, -7.7440e-02,  5.9255e-03,  2.2934e-01,\n",
       "          1.3805e-01, -3.2498e-02, -8.3373e-02, -1.1568e-01, -4.3460e-01,\n",
       "          1.6483e-01, -2.5075e-01, -2.3934e-02, -1.8328e-01,  1.0298e-01,\n",
       "          3.9654e-02,  1.8615e-01,  5.4399e-03, -1.8086e-01,  4.0006e-02,\n",
       "          1.5673e-01,  4.3272e-01, -5.3511e-02,  9.4684e-02,  1.0423e-01,\n",
       "          1.0536e-01, -6.1935e-02, -5.9507e-01, -8.4068e-02, -2.7222e-01,\n",
       "          6.1189e-02, -3.8298e-01, -2.6328e-02, -3.4219e-01,  2.6513e-01,\n",
       "          1.7629e-01, -2.5947e-01,  2.4820e-01,  2.0741e-01, -3.1521e-01,\n",
       "         -1.9298e-04, -2.0895e-01, -2.7534e-03, -1.7009e-01, -2.9840e-01,\n",
       "         -4.3972e-02,  2.2765e-01, -1.9341e-01,  8.0618e-02, -1.4889e-01,\n",
       "          3.2758e-01, -1.0059e-01,  2.6724e-02, -7.5339e-02,  9.9820e-02,\n",
       "         -9.0747e-02,  2.4045e-01, -1.2516e-01,  2.3814e-01, -1.5999e-01,\n",
       "         -2.6570e-02,  1.7729e-01,  5.4848e-02,  5.5183e-02,  1.1633e-01,\n",
       "         -1.4299e-01,  1.7240e-01,  7.5010e-02, -2.4480e-02, -7.8126e-02,\n",
       "         -1.7807e-01,  1.4222e-01, -7.3769e-02, -5.1434e-01,  4.1174e-02,\n",
       "         -2.5488e-02,  3.9995e-01, -7.0598e-02,  8.6793e-02,  1.7540e-01,\n",
       "         -8.6186e-02, -5.7478e-02,  1.7088e-02, -2.9647e-01,  5.7965e-01,\n",
       "          3.4527e-01, -1.3753e-01, -9.3619e-02, -1.8603e-01,  4.9500e-02,\n",
       "         -4.8004e-02, -1.2622e-01,  7.6320e-02, -1.2143e-01, -8.4210e-02,\n",
       "         -1.7826e-01, -1.5353e-01,  4.6875e-01,  8.2457e-02,  4.7191e-02,\n",
       "         -2.2331e-02, -1.2948e-01,  3.1494e-02, -2.2708e-01,  2.7506e-01,\n",
       "          2.1028e-01, -4.2907e-01,  2.7319e-01,  7.8624e-02,  4.7490e-03,\n",
       "         -3.9839e-02, -1.8274e-01,  7.6817e-02, -8.6005e-02, -3.1789e-02,\n",
       "         -3.3738e-01,  2.0633e-01, -2.5299e-01,  2.8418e-01, -3.9967e-02,\n",
       "          1.2312e-02,  3.0567e-01, -1.6734e-01,  3.0201e-01, -1.4562e-01,\n",
       "         -2.5893e-01, -4.0441e-01,  2.1004e-01, -1.9088e-01, -4.4706e-01,\n",
       "         -4.8109e-02,  2.4074e-01,  1.6077e-01, -1.0616e-01, -1.0369e-01,\n",
       "          8.3294e-02, -9.8596e-02,  1.9898e-02,  3.3308e-01, -1.7890e-01,\n",
       "         -1.6054e-01,  2.7205e-01, -4.4192e-02, -1.8612e-01, -2.0514e-02,\n",
       "          4.4122e-01, -1.8845e-01,  1.1628e-01,  5.7577e-01,  2.2291e-01,\n",
       "          2.9327e-02, -1.9365e-02, -6.8789e-02, -1.1927e-01, -1.1662e-01,\n",
       "          6.9607e-02,  1.1029e-01, -6.4581e-02,  2.5300e-01, -2.1321e-01,\n",
       "          2.2804e-01,  6.1241e-02, -2.0946e-01, -3.1081e-02,  1.3172e-01,\n",
       "          1.4633e-01, -4.3557e-03, -4.1042e-01, -1.3529e-01,  3.5641e-01,\n",
       "         -4.7902e-01,  7.6922e-02,  3.7034e-02, -2.1489e-02, -7.3138e-02,\n",
       "         -1.6353e-01,  1.2939e-01,  9.0771e-02,  2.7906e-02,  1.1994e-01,\n",
       "          1.4856e-01,  4.0957e-02, -2.3865e-01, -2.0723e-01, -1.4019e-01,\n",
       "          5.5312e-02,  2.6332e-01,  3.9310e-01,  9.4735e-04,  1.9945e-01,\n",
       "         -8.4685e-02, -2.5907e-01,  1.6888e-01, -1.7934e-01,  2.7250e-01,\n",
       "         -1.3600e-01,  2.5097e-03, -2.9313e-02, -4.2383e-01,  4.5375e-01,\n",
       "          9.3841e-02, -1.6904e-01,  1.1403e-01,  1.7574e-01, -2.7260e-01,\n",
       "         -5.3225e-02, -1.0723e-02,  2.0617e-01,  1.2079e-01,  2.8689e-01,\n",
       "         -1.1203e-01,  5.9329e-01, -1.1035e-01, -4.9653e-02, -9.9564e-02,\n",
       "          3.0658e-02, -2.5835e-01,  1.6313e-01,  1.1079e-01,  3.3007e-01,\n",
       "          1.5820e-01,  1.5292e-01, -3.0356e-01, -2.1154e-03, -1.3553e-01,\n",
       "         -2.9228e-02,  1.6440e-01, -3.7829e-02,  1.6930e-01,  2.2069e-01,\n",
       "         -2.8537e-02,  2.2643e-01, -1.1836e-01, -1.5986e-01,  1.1055e-01,\n",
       "          6.6317e-02, -6.9830e-02,  2.5148e-02, -2.4418e-01, -9.7998e-02,\n",
       "         -4.6249e-01,  3.3248e-02, -1.6814e-01,  2.3202e-01,  7.4325e-02,\n",
       "          1.2920e-01, -5.4154e-02,  2.6575e-01, -9.5751e-01,  4.3125e-03,\n",
       "          1.7597e-01, -1.5825e-01,  3.8594e-02,  2.0799e-01,  1.3188e-01,\n",
       "         -3.2550e-02,  6.4002e-02, -1.8732e-01, -1.6767e-01,  1.5610e-01,\n",
       "          2.6330e-01, -6.4303e-02, -1.0053e-01, -1.8622e-01,  3.6739e-01,\n",
       "          2.6449e-01, -4.7900e-02,  2.8793e-01,  4.9124e-02, -2.2609e-01,\n",
       "          1.4921e-01, -3.0876e-01,  6.8332e-02,  8.0398e-03,  1.8035e-01,\n",
       "         -3.6048e-02, -1.8860e-01, -2.3582e-01, -1.3736e-01,  2.6523e-01,\n",
       "         -1.4961e-01,  1.4595e-01, -1.8878e-01, -1.2570e-01, -9.3814e-03,\n",
       "         -1.2001e-02, -3.0174e-01,  9.2240e-02, -3.2615e-01, -2.5251e-01,\n",
       "         -3.1612e-02, -1.0016e-02, -1.0123e-01, -3.6769e-01,  2.0974e-01,\n",
       "         -8.3324e-02, -2.5057e-02,  2.6294e-01,  1.3470e-01,  2.0690e-02,\n",
       "         -9.4960e-02,  9.9417e-04,  1.2161e-02, -8.9170e-02,  5.7202e-02,\n",
       "          1.2006e-01,  6.5831e-02,  1.1391e-01, -2.7984e-01, -3.3339e-01,\n",
       "          2.2723e-01,  2.2217e-02,  1.1084e-01, -7.7017e-02,  3.8592e-02,\n",
       "         -4.2657e-03,  8.2022e-02,  2.5028e-01, -4.7155e-02,  1.7490e-01,\n",
       "          2.1388e-01, -2.1352e-01,  8.2533e-01, -1.3389e-01, -5.2927e-03,\n",
       "         -1.5137e-01, -9.8322e-02,  1.1863e-01,  3.2154e-01,  2.0622e-01,\n",
       "         -7.3974e-02, -8.8198e-02,  7.1076e-02,  1.2843e-01,  1.9721e-01,\n",
       "          2.0284e-01,  4.1599e-01,  1.1078e-01, -2.7617e-01, -2.0180e-01,\n",
       "         -1.9556e-01, -1.8509e-01,  2.1627e-02,  6.1560e-02,  3.3491e-01,\n",
       "         -3.0759e-02,  3.3320e-01,  1.7917e-01,  2.6364e-01,  7.4063e-02,\n",
       "         -1.6097e-01, -1.6222e-03, -1.8502e-01,  8.3832e-02, -1.4935e-01,\n",
       "         -1.2756e-02,  1.8960e+00, -6.1804e-02,  2.1688e-01,  3.1798e-01,\n",
       "          2.4531e-02,  3.0034e-01, -1.2046e-02,  5.0720e-02, -4.0127e-01,\n",
       "          1.7256e-01,  7.2096e-02, -8.3101e-02, -1.6690e-01,  5.5889e-02,\n",
       "         -1.5849e-01,  4.5735e-01,  6.8728e-03, -1.6987e-02, -6.1253e-02,\n",
       "          2.2300e-01, -8.7095e-02,  8.5334e-02,  2.9894e-01, -6.4813e-02,\n",
       "         -2.1675e-01,  3.4731e-02, -7.7392e-02, -2.7102e-01, -1.4837e-01,\n",
       "          3.1070e-02, -2.0642e-01, -3.8448e-01, -9.8276e-02, -3.9507e-02,\n",
       "         -2.9132e-01, -5.8726e-02, -1.8349e-01, -1.0942e-01,  7.8167e-02,\n",
       "          5.4706e-02, -2.4470e-02,  2.2829e-01, -5.2339e-02,  8.8932e-02,\n",
       "         -1.7800e-01, -9.9355e-03, -2.3819e-01,  6.5233e-02,  1.0456e-02,\n",
       "          7.4113e-02,  2.6345e-01, -1.0453e-01,  1.4335e-01, -2.5574e-01,\n",
       "          8.9668e-02, -2.2641e-01,  1.4558e-01,  1.2365e-01, -4.1289e-01,\n",
       "          2.7779e-01, -1.6031e-03,  7.2360e-02,  1.2593e-01, -4.7774e-02,\n",
       "         -1.2488e-01,  3.7846e-01, -1.4120e-01, -2.0961e-01, -3.4676e-03,\n",
       "          1.2119e-01,  2.0153e-01, -2.7351e-01,  2.7658e-01, -2.7737e-02,\n",
       "          1.6752e-01, -2.1243e-01,  2.6044e-01, -4.3969e-01, -1.4857e-01,\n",
       "         -2.2593e-01,  2.6583e-01,  3.0389e-01, -1.5674e-01,  2.4919e-01,\n",
       "         -1.6794e-01,  3.2951e-01, -3.8312e-02, -2.9395e-03, -2.7837e-01,\n",
       "          4.0952e-01,  3.3941e-02, -6.4792e-02, -6.7091e-02, -9.0760e-02,\n",
       "         -6.4835e-02, -1.3073e-01,  1.8162e-02, -5.4516e-03,  2.0615e-01,\n",
       "          1.8802e-01,  8.5607e-02,  1.1948e-01,  2.7826e-02,  2.1157e-02,\n",
       "          9.6056e-02, -1.9561e-03, -2.3848e-01,  3.8019e-01,  2.8292e-02,\n",
       "          5.0453e-02, -1.7199e-01,  2.1993e-01, -4.6297e-02, -2.3680e-01,\n",
       "          3.9732e-01, -1.7611e-01,  2.6092e-01,  6.9326e-03,  3.1778e-01,\n",
       "         -1.0844e-01,  2.3931e-01, -3.1969e-02, -3.4376e-01, -6.1327e-03,\n",
       "          2.4782e-02, -1.9971e-01,  1.5537e-01,  1.8409e-01, -1.2900e-01,\n",
       "          1.8141e-01,  1.3682e-01,  9.8880e-02,  5.8535e-02, -9.2043e-02,\n",
       "         -2.5285e-01, -5.9150e-02, -1.8252e-01, -1.3434e-01, -1.9270e-01,\n",
       "          2.4093e-01,  1.2572e-02,  4.4026e-01,  2.6148e-01, -1.5636e-01,\n",
       "          5.6859e-02,  3.2430e-02,  3.3654e-02,  1.1619e-01,  4.8457e-02,\n",
       "          1.3353e-02, -1.9359e-01, -3.6033e-01, -5.3994e-02,  1.4229e-01,\n",
       "          9.8678e-02, -2.4496e-01, -1.4659e-01,  3.9761e-02, -2.2433e-01,\n",
       "         -2.1915e-01, -6.1113e-02, -1.3699e-01, -1.0832e-01, -1.8463e-03,\n",
       "         -3.5420e-01,  1.9485e-01, -3.8159e-03, -6.5736e-02,  1.0037e-01,\n",
       "         -8.2021e-02, -3.5587e-01, -1.4579e-01, -1.6898e-01,  2.4015e-02,\n",
       "          1.5522e-02,  1.0084e-01, -1.2487e-01,  5.5025e-02,  1.5983e-01,\n",
       "         -5.4141e-02, -5.1730e-02, -1.8102e-01,  8.9865e-02, -2.7888e-01,\n",
       "          4.1144e-02,  1.3101e-01, -3.0309e-01,  3.4312e-02,  5.9587e-04,\n",
       "         -1.2222e-01, -3.5272e-01, -1.8859e-01,  3.2265e-01, -5.5297e-01,\n",
       "          1.1963e-01, -1.0999e-01, -8.8375e-02, -2.8935e-01, -1.0679e-01,\n",
       "          8.2204e-02,  3.5643e-01, -3.7549e-01,  1.7318e-01, -5.9275e-02,\n",
       "          1.7280e-02,  3.8903e-01, -4.8613e-02,  1.5226e-01,  1.1535e-01,\n",
       "         -2.3330e-01,  1.8418e-01,  2.9204e-01,  1.4199e-01,  6.4192e-03,\n",
       "          1.1666e-01,  1.7977e-01,  2.8533e-01,  1.2447e-01, -1.3508e-01,\n",
       "          1.1889e-01, -1.2423e-01,  1.1914e-01, -4.0550e-01, -2.8780e-01,\n",
       "         -2.0044e-01,  3.1167e-01, -7.7323e-02, -2.0660e-01, -1.1877e-01,\n",
       "         -2.2504e-01,  3.3371e-01, -1.7259e-01,  8.4072e-03, -1.5548e-01,\n",
       "         -4.8197e-02,  1.8988e-01, -1.2562e-01, -5.1470e-02,  2.5204e-01,\n",
       "         -4.8313e-02, -7.7400e-02,  1.9910e-01,  1.2332e-01, -1.6818e-01,\n",
       "          1.4431e-01,  3.5765e-01,  4.4448e-01,  2.0250e-02, -6.6882e-02,\n",
       "         -2.4438e-01,  2.1984e-01, -3.9160e-01,  1.9891e-01, -2.9174e-01,\n",
       "          2.6813e-01,  5.7291e-01,  7.3188e-02,  6.0889e-02,  2.7293e-02,\n",
       "          3.5861e-01, -1.1161e-01, -3.5285e-02,  3.3066e-01, -5.8972e-02,\n",
       "         -5.6296e-02,  2.5291e-01, -2.0486e-01,  1.3822e-01,  2.1362e-01,\n",
       "         -9.1453e-02, -1.3040e-01, -2.7130e-01,  1.8752e-01, -2.5978e-02,\n",
       "          2.2344e-01, -1.9172e-01,  9.6422e-02, -1.7468e-01, -3.7927e-02,\n",
       "         -2.3515e-01,  6.0950e-02,  1.5816e-01, -1.6884e-01,  1.7189e-01,\n",
       "          9.7592e-02, -1.0862e-02, -2.6864e-01]),\n",
       " 'transformer.h.9.ln_2.weight': tensor([0.2713, 0.2568, 0.2734, 0.2627, 0.2627, 0.2588, 0.4197, 0.2268, 0.2705,\n",
       "         0.2372, 0.2862, 0.2605, 0.2665, 0.2684, 0.2941, 0.2588, 0.2888, 0.2640,\n",
       "         0.2666, 0.2755, 0.2319, 0.2568, 0.2588, 0.2529, 0.2618, 0.2575, 0.2686,\n",
       "         0.2502, 0.2529, 0.2549, 0.2451, 0.2907, 0.2563, 0.2529, 0.2686, 0.3057,\n",
       "         0.2409, 0.2465, 0.2368, 0.2626, 0.2446, 0.2475, 0.2397, 0.2612, 0.2686,\n",
       "         0.2744, 0.2627, 0.2340, 0.2883, 0.2588, 0.2549, 0.2588, 0.2666, 0.2657,\n",
       "         0.2666, 0.2969, 0.2744, 0.2803, 0.2466, 0.2800, 0.2803, 0.2549, 0.2642,\n",
       "         0.2744, 0.1744, 0.2506, 0.2510, 0.2977, 0.3018, 0.2461, 0.2773, 0.1973,\n",
       "         0.2532, 0.2666, 0.2387, 0.2725, 0.2822, 0.3336, 0.2763, 0.2626, 0.2822,\n",
       "         0.2588, 0.2636, 0.2920, 0.2667, 0.2822, 0.2919, 0.0195, 0.2627, 0.2588,\n",
       "         0.2622, 0.2588, 0.2694, 0.2568, 0.2588, 0.2465, 0.2744, 0.2666, 0.2500,\n",
       "         0.2705, 0.2407, 0.2187, 0.3148, 0.2842, 0.2627, 0.2529, 0.2783, 0.3115,\n",
       "         0.2517, 0.2495, 0.2646, 0.2529, 0.2623, 0.2705, 0.2667, 0.2713, 0.2861,\n",
       "         0.2727, 0.2427, 0.2979, 0.2734, 0.2624, 0.2530, 0.2666, 0.2727, 0.2627,\n",
       "         0.2607, 0.2718, 0.2880, 0.2560, 0.2666, 0.2421, 0.2783, 0.2580, 0.2568,\n",
       "         0.2475, 0.2608, 0.3036, 0.9476, 0.2521, 0.2588, 0.2644, 0.3192, 0.2456,\n",
       "         0.2839, 0.2832, 0.2626, 0.2803, 0.2588, 0.2607, 0.2666, 0.2703, 0.2879,\n",
       "         0.2783, 0.2687, 0.2529, 0.2645, 0.2625, 0.2389, 0.2959, 0.3253, 0.2647,\n",
       "         0.2805, 0.2764, 0.2745, 0.2646, 0.2700, 0.3496, 0.2510, 0.2764, 0.2627,\n",
       "         0.2517, 0.2548, 0.2686, 0.2744, 0.2666, 0.2627, 0.2479, 0.2744, 0.2530,\n",
       "         0.2529, 0.2488, 0.2577, 0.2822, 0.2483, 0.2459, 0.2447, 0.2686, 0.2607,\n",
       "         0.2764, 0.2666, 0.2842, 0.2559, 0.2686, 0.2474, 0.3271, 0.2435, 0.2724,\n",
       "         0.2646, 0.2869, 0.2764, 0.2918, 0.2568, 0.2647, 0.2494, 0.2685, 0.2588,\n",
       "         0.2276, 0.2958, 0.2674, 0.2510, 0.2940, 0.2646, 0.2723, 0.2646, 0.2627,\n",
       "         0.2979, 0.2645, 0.1781, 0.2585, 0.2665, 0.2679, 0.2414, 0.2811, 0.2803,\n",
       "         0.2627, 0.2466, 0.2510, 0.2615, 0.2397, 0.2427, 0.2666, 0.3604, 0.2544,\n",
       "         0.2485, 0.2700, 0.2700, 0.2510, 0.2844, 0.2678, 0.2900, 0.2936, 0.2607,\n",
       "         0.2587, 0.2479, 0.2646, 0.2449, 0.2900, 0.2530, 0.2618, 0.2509, 0.2561,\n",
       "         0.2529, 0.2723, 0.2586, 0.3070, 0.2724, 0.2688, 0.2587, 0.2659, 0.2584,\n",
       "         0.2920, 0.2548, 0.2666, 0.2645, 0.2530, 0.0723, 0.2861, 0.2646, 0.2666,\n",
       "         0.3213, 0.3172, 0.2456, 0.2626, 0.2968, 0.2417, 0.2549, 0.2514, 0.2456,\n",
       "         0.2666, 0.2355, 0.2400, 0.2601, 0.3272, 0.2959, 0.2830, 0.2747, 0.2618,\n",
       "         0.5215, 0.2717, 0.2647, 0.2588, 0.2549, 0.2446, 0.2802, 0.2454, 0.2416,\n",
       "         0.2647, 0.2607, 0.2760, 0.2676, 0.2686, 0.2685, 0.2445, 0.2322, 0.2533,\n",
       "         0.2666, 0.2446, 0.2685, 0.2369, 0.2549, 0.3267, 0.2705, 0.2585, 0.2052,\n",
       "         0.2607, 0.2823, 0.2666, 0.2543, 0.2768, 0.2861, 0.2583, 0.2607, 0.2721,\n",
       "         0.2529, 0.2607, 0.4808, 0.2510, 0.2612, 0.2549, 0.2646, 0.2495, 0.2705,\n",
       "         0.2495, 0.2359, 0.2685, 0.2881, 0.2502, 0.2704, 0.2686, 0.2666, 0.2496,\n",
       "         0.2744, 0.2803, 0.2720, 0.2686, 0.2800, 0.2597, 0.2705, 0.2524, 0.2588,\n",
       "         0.2114, 0.2561, 0.2763, 0.2666, 0.2646, 0.2803, 0.2694, 0.2627, 0.2713,\n",
       "         0.2744, 0.2435, 0.3374, 0.2549, 0.2466, 0.2842, 0.2702, 0.2531, 0.2507,\n",
       "         0.2665, 0.2666, 0.2490, 0.2642, 0.0598, 0.2605, 0.2894, 0.2783, 0.2764,\n",
       "         0.2261, 0.2744, 0.2510, 0.2568, 0.2493, 0.2974, 0.2744, 0.2725, 0.2795,\n",
       "         0.2593, 0.2685, 0.2912, 0.2705, 0.2479, 0.2782, 0.4970, 0.2816, 0.2568,\n",
       "         0.2727, 0.2476, 0.2568, 0.2469, 0.2547, 0.2744, 0.2803, 0.2627, 0.2354,\n",
       "         0.2764, 0.2684, 0.2428, 0.2686, 0.2529, 0.2495, 0.2425, 0.2529, 0.2441,\n",
       "         0.2588, 0.2661, 0.2476, 0.2668, 0.2568, 0.2686, 0.1892, 0.2842, 0.2588,\n",
       "         0.2745, 0.2466, 0.2437, 0.2673, 0.2666, 0.2548, 0.2509, 0.2250, 0.2585,\n",
       "         0.2476, 0.2684, 0.2495, 0.2979, 0.2510, 0.2744, 0.2701, 0.2920, 0.2932,\n",
       "         0.2813, 0.2961, 0.2529, 0.2794, 0.2607, 0.2535, 0.0681, 0.2607, 0.2814,\n",
       "         0.2627, 0.2559, 0.2452, 0.2666, 0.2685, 0.2978, 0.2764, 0.2485, 0.2444,\n",
       "         0.1587, 0.2607, 0.2686, 0.2686, 0.2549, 0.1431, 0.2627, 0.2769, 0.2567,\n",
       "         0.2510, 0.2549, 0.2417, 0.2764, 0.2783, 0.2549, 0.2290, 0.2646, 0.2464,\n",
       "         0.2510, 0.2397, 0.3236, 0.0177, 0.0570, 0.2647, 0.2495, 0.2688, 0.2397,\n",
       "         0.2529, 0.2646, 0.2778, 0.2510, 0.2606, 0.2856, 0.2446, 0.2568, 0.2680,\n",
       "         0.2509, 0.1938, 0.1880, 0.2685, 0.2588, 0.2745, 0.2562, 0.2717, 0.3135,\n",
       "         0.2779, 0.2438, 0.2485, 0.2861, 0.2764, 0.2475, 0.2399, 0.2705, 0.2548,\n",
       "         0.2646, 0.2646, 0.2842, 0.2456, 0.2581, 0.2548, 0.2588, 0.2464, 0.2568,\n",
       "         0.2686, 0.2645, 0.2622, 0.2647, 0.3784, 0.2762, 0.2869, 0.2463, 0.2646,\n",
       "         0.2817, 0.2385, 0.2453, 0.2588, 0.2760, 0.2495, 0.2549, 0.2764, 0.2705,\n",
       "         0.2897, 0.2666, 0.2666, 0.2979, 0.2549, 0.2725, 0.2646, 0.2607, 0.2493,\n",
       "         0.3017, 0.2646, 0.2959, 0.2685, 0.2686, 0.3037, 0.2822, 0.2494, 0.2646,\n",
       "         0.2627, 0.2530, 0.2762, 0.2744, 0.2627, 0.2549, 0.2568, 0.2607, 0.3076,\n",
       "         0.2735, 0.2725, 0.2668, 0.2832, 0.2764, 0.2678, 0.2711, 0.2549, 0.2880,\n",
       "         0.2549, 0.2596, 0.3005, 0.2607, 0.2495, 0.2405, 0.2881, 0.2529, 0.2510,\n",
       "         0.2657, 0.2439, 0.2861, 0.2634, 0.2713, 0.2783, 0.2660, 0.2468, 0.2584,\n",
       "         0.2602, 0.2532, 0.2706, 0.2479, 0.2549, 0.2491, 0.2679, 0.2607, 0.2704,\n",
       "         0.2744, 0.2710, 0.2526, 0.2764, 0.2881, 0.3460, 0.2556, 0.2664, 0.2568,\n",
       "         0.2665, 0.2512, 0.2660, 0.2822, 0.2860, 0.2568, 0.2641, 0.2721, 0.2610,\n",
       "         0.2470, 0.2636, 0.2588, 0.2832, 0.2568, 0.2561, 0.2821, 0.2714, 0.2495,\n",
       "         0.2526, 0.2601, 0.2446, 0.2510, 0.2594, 0.2917, 0.2627, 0.2472, 0.2599,\n",
       "         0.2764, 0.4425, 0.2654, 0.2106, 0.2795, 0.2783, 0.2737, 0.2607, 0.2900,\n",
       "         0.2627, 0.3018, 0.2376, 0.2936, 0.2476, 0.2744, 0.2510, 0.2705, 0.2579,\n",
       "         0.2648, 0.2392, 0.3037, 0.2464, 0.2743, 0.2447, 0.2666, 0.2569, 0.2920,\n",
       "         0.2510, 0.2555, 0.2568, 0.2801, 0.2705, 0.2586, 0.2705, 0.2548, 0.2414,\n",
       "         0.2436, 0.2510, 0.2595, 0.2763, 0.3428, 0.2920, 0.2548, 0.2685, 0.2588,\n",
       "         0.2410, 0.2560, 0.2803, 0.2398, 0.2626, 0.2623, 0.2529, 0.2495, 0.2646,\n",
       "         0.2803, 0.2529, 0.2508, 0.2561, 0.2468, 0.2666, 0.2643, 0.2510, 0.2862,\n",
       "         0.2588, 0.3344, 0.2591, 0.2761, 0.2927, 0.2825, 0.2476, 0.2818, 0.2800,\n",
       "         0.2398, 0.2607, 0.2685, 0.2685, 0.2646, 0.2547, 0.2486, 0.2803, 0.2549,\n",
       "         0.2398, 0.3056, 0.2446, 0.2568, 0.2627, 0.2764, 0.2783, 0.2803, 0.2777,\n",
       "         0.2705, 0.2607, 0.2642, 0.2517, 0.2722, 0.2647, 0.2628, 0.2618, 0.2435,\n",
       "         0.2685, 0.3240, 0.2783, 0.2529, 0.2549, 0.2744, 0.2763, 0.2075, 0.3051,\n",
       "         0.2616, 0.2764, 0.2744, 0.2591, 0.2649, 0.2457, 0.2522, 0.2801, 0.2846,\n",
       "         0.1321, 0.2588, 0.2510, 0.2782, 0.2372, 0.2744, 0.2854, 0.2475, 0.2445,\n",
       "         0.2575, 0.2455, 0.2607]),\n",
       " 'transformer.h.9.ln_2.bias': tensor([ 4.6359e-02,  1.3956e-02,  4.1969e-02,  5.9464e-02, -3.2730e-03,\n",
       "         -1.5924e-02,  2.0831e-02,  4.2198e-02,  4.6790e-03, -2.2352e-03,\n",
       "         -1.5116e-03,  3.8837e-02,  4.2359e-02,  4.3516e-04, -2.0616e-02,\n",
       "          2.9114e-02, -1.4773e-02,  7.2373e-02,  2.4280e-02, -2.5719e-02,\n",
       "          2.6464e-02,  2.5266e-03, -2.5735e-02,  5.4931e-02,  8.6198e-03,\n",
       "          9.1083e-03, -9.7662e-03,  3.2609e-02,  7.6199e-03, -1.2238e-02,\n",
       "         -3.5628e-03, -1.5776e-02, -8.7988e-03,  8.9751e-03,  3.6059e-04,\n",
       "         -1.9238e-02, -1.6577e-02, -1.3442e-02, -9.9734e-03,  3.3466e-03,\n",
       "          1.2651e-02, -1.7199e-03, -1.9708e-02,  5.0742e-02, -2.9713e-02,\n",
       "         -1.1055e-02,  4.3423e-02, -6.5405e-03, -6.0137e-03, -1.8037e-02,\n",
       "          3.8510e-02,  9.4927e-03,  4.7670e-03, -3.2339e-03,  3.0884e-02,\n",
       "         -2.1922e-02, -2.6174e-02, -1.6103e-02,  6.0524e-03,  1.2656e-02,\n",
       "          4.3455e-02,  1.0686e-02,  1.2142e-02, -2.0499e-02, -2.1240e-01,\n",
       "          3.2852e-02, -2.6814e-02, -8.6224e-04,  1.9907e-02,  4.8420e-03,\n",
       "          1.4650e-02,  5.9070e-03,  3.0817e-02,  2.5065e-03,  1.6111e-02,\n",
       "          2.4625e-02, -1.6990e-02, -2.1809e-02,  3.2874e-02, -9.5611e-03,\n",
       "         -3.5267e-02,  2.7005e-02,  1.9234e-02, -6.9227e-03,  7.1713e-02,\n",
       "          3.7310e-02,  5.4099e-02, -2.0350e-02, -1.4198e-03,  1.2337e-02,\n",
       "         -2.5822e-02,  2.3218e-02, -2.0248e-02,  3.6099e-02, -1.6097e-02,\n",
       "         -9.4947e-04, -3.0887e-03,  5.2009e-03, -1.5644e-02,  3.4826e-02,\n",
       "         -2.1911e-04, -5.9407e-02,  4.8287e-03,  4.3837e-02,  3.2372e-02,\n",
       "         -1.4633e-02,  7.6709e-03,  2.9655e-02, -3.9969e-03,  3.3355e-03,\n",
       "         -3.8935e-02,  1.8390e-02,  4.4255e-02,  5.0225e-02,  1.7208e-02,\n",
       "          4.6327e-02,  5.5122e-02,  3.2269e-02,  2.0172e-02, -1.4916e-02,\n",
       "          2.7309e-02,  5.0541e-03, -1.0247e-02,  2.0149e-02,  2.5397e-02,\n",
       "          2.5361e-02, -1.5364e-02, -2.4828e-02, -1.7092e-02,  5.0636e-03,\n",
       "          2.5888e-02,  2.0438e-02,  8.2908e-03,  1.6948e-02,  4.1886e-02,\n",
       "          1.2966e-02,  1.2470e-03,  1.5099e-02,  1.9378e-01,  8.2823e-03,\n",
       "         -4.7962e-03,  1.3489e-02,  4.3567e-03,  6.4663e-03, -3.8445e-02,\n",
       "          9.7321e-04,  1.9274e-02,  2.6011e-02, -2.7832e-02,  1.3927e-02,\n",
       "         -2.6986e-02, -2.0381e-02, -8.8528e-03,  4.6666e-02,  1.6820e-02,\n",
       "         -1.0759e-02,  3.2214e-02, -2.7836e-02, -7.5690e-03, -3.1338e-02,\n",
       "         -1.8618e-02,  3.8666e-02, -2.3154e-02,  3.3513e-02, -9.1068e-03,\n",
       "          5.1771e-02, -2.4427e-02,  1.6266e-02, -5.2176e-03,  2.1431e-02,\n",
       "         -2.6429e-02, -1.3502e-03, -1.5157e-02,  3.3783e-02, -1.2742e-03,\n",
       "         -9.1661e-03,  5.5032e-02, -2.0955e-02,  4.3506e-02, -3.2580e-02,\n",
       "         -5.1832e-03,  2.5456e-02,  4.8346e-02,  9.8867e-03,  1.5130e-02,\n",
       "          2.2179e-02,  3.2472e-03, -2.4789e-02,  1.3605e-03,  3.0614e-02,\n",
       "          2.8012e-02, -2.5684e-02,  2.1680e-02,  2.6460e-02,  2.0087e-03,\n",
       "          6.1622e-03, -1.9493e-02, -1.3897e-02,  1.1777e-02, -2.8853e-02,\n",
       "          3.4451e-02, -2.6946e-02,  3.0851e-02,  6.5116e-02,  1.1722e-02,\n",
       "          4.3605e-02, -2.1370e-02,  2.4930e-02,  1.3708e-02, -3.7338e-02,\n",
       "          1.9752e-02,  5.3699e-02,  2.7069e-02,  3.3175e-02,  6.1775e-03,\n",
       "         -7.0276e-03, -9.9095e-03, -1.5216e-02, -3.3901e-02,  1.0711e-02,\n",
       "          3.9820e-02, -3.4286e-02,  2.4851e-02,  2.6422e-02,  4.4120e-02,\n",
       "          1.8298e-02,  3.0423e-03,  4.8683e-02,  4.1800e-02,  1.8543e-02,\n",
       "          2.9380e-02,  2.0182e-02,  7.5888e-02, -1.3803e-02,  3.7292e-03,\n",
       "          7.8018e-03,  2.4379e-02, -2.2781e-02,  1.7691e-02,  7.8380e-03,\n",
       "          4.8310e-02,  1.2099e-02,  1.0327e-02, -4.3469e-02, -4.7232e-02,\n",
       "         -1.0782e-02, -4.3969e-03,  3.5032e-02, -1.1166e-02,  9.2256e-03,\n",
       "         -6.7484e-03,  2.3821e-02, -2.3077e-02, -1.0305e-02,  2.4358e-02,\n",
       "          1.0538e-01, -1.2543e-02,  2.3935e-02, -1.5297e-02,  5.1612e-02,\n",
       "          6.8340e-03,  9.5482e-02,  4.4886e-03, -1.3280e-02, -9.4018e-03,\n",
       "         -1.9276e-02,  1.2387e-02,  4.0241e-02,  1.0192e-02,  8.8142e-03,\n",
       "         -1.7780e-02, -8.2222e-03,  1.0885e-02, -2.4470e-02, -6.7068e-03,\n",
       "          1.7433e-02, -5.6699e-03,  7.6062e-03,  2.3800e-02,  1.3672e-02,\n",
       "          2.3269e-02, -1.4779e-02,  1.0775e-02,  4.6934e-02,  8.1263e-03,\n",
       "          2.1176e-02,  1.1527e-02,  2.0063e-02, -1.1815e-01,  3.6538e-02,\n",
       "          2.3737e-02,  1.3567e-02,  4.9459e-02,  2.9661e-02,  3.4450e-02,\n",
       "          1.0566e-02,  2.0714e-02,  1.6877e-02, -5.5296e-02,  5.4029e-03,\n",
       "          3.0143e-03, -2.0687e-02,  1.5221e-02,  2.2572e-02, -6.8964e-04,\n",
       "         -4.0363e-03,  2.2592e-02,  1.1445e-02,  2.9604e-02,  2.5694e-02,\n",
       "         -4.2649e-02,  8.3323e-03,  5.1442e-02, -3.5837e-02, -5.9444e-02,\n",
       "          1.7270e-02,  7.4314e-02, -6.5124e-03,  1.6511e-02,  1.0761e-02,\n",
       "          6.7955e-03, -6.8050e-03,  3.0290e-02, -2.0315e-02, -2.3744e-02,\n",
       "          4.4000e-03, -2.7915e-01, -8.3837e-03, -6.0874e-03,  3.4702e-03,\n",
       "          2.7941e-02, -3.7527e-02, -4.3679e-02, -4.5477e-03,  1.0540e-02,\n",
       "         -1.9555e-02,  2.7929e-02,  2.4295e-03,  8.8084e-04,  1.1129e-02,\n",
       "         -4.4063e-02,  1.8228e-02,  2.6457e-02, -6.1199e-03,  1.8750e-02,\n",
       "          7.2018e-03,  3.1757e-02, -1.1687e-02,  1.0006e-02,  2.8961e-02,\n",
       "          3.8352e-02,  2.2461e-03,  3.6023e-02, -3.1655e-02,  3.1976e-02,\n",
       "          2.2143e-02, -1.8267e-02,  3.5434e-02, -2.9472e-02,  3.6890e-02,\n",
       "         -5.0324e-02,  2.0068e-02,  1.9135e-02,  4.2284e-02,  3.8479e-02,\n",
       "          1.8943e-02,  1.6805e-03,  4.3020e-02,  4.3138e-04,  6.2916e-02,\n",
       "          1.4258e-02, -1.5524e-02, -4.3297e-03,  5.1373e-01,  5.3498e-04,\n",
       "         -1.4394e-02, -3.6367e-02, -1.6451e-02, -5.1973e-02,  3.4127e-02,\n",
       "         -2.0742e-02,  1.0771e-02,  1.1353e-02,  1.6064e-02,  1.9150e-02,\n",
       "         -4.7783e-03,  2.6506e-02, -1.8528e-02,  2.5603e-02,  8.8883e-03,\n",
       "          4.8920e-02,  1.7394e-02,  7.8051e-03, -1.2286e-01,  1.0118e-02,\n",
       "          4.1234e-04,  2.7605e-02,  2.2310e-03,  3.0696e-02,  3.0611e-02,\n",
       "         -3.3815e-02,  2.8696e-02,  2.0536e-02, -2.6363e-03,  5.5335e-03,\n",
       "         -2.3168e-02,  9.2917e-03, -6.2566e-03, -5.5252e-02,  4.1969e-02,\n",
       "         -1.3232e-02,  1.2184e-02, -1.4690e-02, -2.7277e-02,  3.4491e-02,\n",
       "          3.8440e-02,  3.2278e-02,  2.2802e-02, -1.6364e-02,  4.9551e-02,\n",
       "          7.3260e-03,  4.5073e-03,  3.3260e-02, -3.7166e-03,  1.0038e-02,\n",
       "          3.6014e-02,  5.5558e-02,  3.7811e-04, -3.2413e-02, -2.9892e-02,\n",
       "         -5.1771e-02,  3.2636e-02,  3.0849e-02,  9.7354e-03,  1.0504e-02,\n",
       "          5.2117e-02, -1.8205e-02,  1.2379e-02,  1.2672e-02,  2.9560e-02,\n",
       "          8.3178e-02,  2.9484e-02,  1.2231e-03,  2.3327e-02, -8.8367e-03,\n",
       "         -4.9888e-02,  1.3511e-02, -1.6073e-01,  4.6437e-02,  6.8955e-02,\n",
       "          6.5771e-03,  6.5913e-03,  1.0505e-02,  3.6031e-03,  3.5611e-03,\n",
       "          3.4305e-02,  3.4872e-02,  1.1346e-02, -6.3544e-03,  6.1326e-03,\n",
       "         -3.3602e-03, -4.5979e-04,  5.8058e-02,  1.2235e-02, -2.7755e-02,\n",
       "          2.8681e-02,  3.5192e-02,  4.1441e-02, -3.7633e-03,  1.8175e-02,\n",
       "          3.5060e-03,  1.7460e-02,  7.9820e-03,  3.2582e-02,  1.8512e-02,\n",
       "          3.2931e-03,  2.3816e-02,  5.2062e-02,  1.4304e-03,  6.1383e-02,\n",
       "         -5.1155e-01, -5.6101e-01,  1.1739e-02, -8.4377e-04, -3.0972e-02,\n",
       "          4.3411e-03,  1.4292e-02,  1.2945e-02,  7.9660e-03,  1.6286e-02,\n",
       "          4.8398e-03,  6.6507e-03,  1.1928e-02,  3.5266e-02,  2.1217e-03,\n",
       "          4.0883e-02, -5.5675e-02,  5.2391e-02, -1.4916e-02,  2.3761e-03,\n",
       "          6.1236e-03, -1.9336e-03,  4.3250e-03,  4.6581e-03,  4.3954e-03,\n",
       "          5.3100e-03,  1.0387e-02,  7.5576e-03,  3.0202e-02,  2.0950e-02,\n",
       "         -7.2719e-03, -3.3016e-02,  4.1409e-02,  2.4662e-02,  3.6624e-03,\n",
       "          2.4028e-03, -1.4737e-03,  1.8640e-02, -1.7179e-02,  2.0110e-02,\n",
       "          5.7687e-03,  4.1670e-02,  3.4698e-02,  7.0371e-03,  5.4823e-04,\n",
       "         -3.2601e-02,  3.4001e-03,  5.9596e-02, -6.3127e-03, -9.3709e-03,\n",
       "          3.9789e-02, -1.8381e-04, -1.3319e-02,  9.9240e-03, -1.3092e-03,\n",
       "          4.8258e-03, -2.9932e-02, -2.5621e-02,  3.2499e-02,  1.8507e-02,\n",
       "         -5.5692e-03, -1.5296e-02, -6.7538e-03, -1.1611e-02,  4.0821e-03,\n",
       "          4.7750e-02,  2.5824e-02,  7.3968e-02,  1.0912e-02,  3.9996e-03,\n",
       "         -1.2011e-02,  1.7074e-02, -1.3931e-03, -2.9334e-03,  3.4197e-02,\n",
       "          3.2622e-03,  3.6016e-02,  2.5633e-02,  4.2825e-02,  4.8809e-03,\n",
       "          7.3719e-03, -5.1014e-04,  1.6190e-02,  3.1836e-02,  1.3149e-02,\n",
       "         -5.7841e-03, -7.2479e-03, -2.2626e-02,  2.7774e-02, -2.4598e-02,\n",
       "         -7.7737e-03, -1.4708e-02,  2.2259e-02, -2.7018e-02,  1.2423e-03,\n",
       "         -5.0729e-03, -7.2550e-03,  3.9393e-02, -1.6036e-02, -5.8190e-03,\n",
       "          7.7902e-03,  2.7560e-03,  6.1637e-02,  5.5939e-04,  1.6815e-02,\n",
       "         -3.7384e-02, -9.2474e-03, -2.3087e-02,  2.9745e-02,  3.5519e-02,\n",
       "         -7.7708e-02,  1.2476e-02,  3.5081e-02,  4.4762e-03,  4.2720e-02,\n",
       "         -2.6004e-02, -2.7662e-02, -1.0111e-02,  3.1815e-02, -6.0336e-03,\n",
       "          1.0363e-02,  1.8858e-02,  5.2575e-03,  3.5614e-02,  2.9272e-02,\n",
       "         -4.3823e-04,  2.4112e-02, -7.6850e-02, -2.0872e-02, -1.8476e-02,\n",
       "         -6.7624e-03, -5.4782e-03, -2.2909e-02, -7.7881e-03, -2.6471e-02,\n",
       "         -2.7177e-02, -7.7965e-03,  1.7534e-02, -1.0759e-02,  4.0409e-02,\n",
       "          1.1255e-02,  9.2884e-03,  3.6359e-02, -5.9741e-03, -3.7481e-02,\n",
       "          2.2945e-02, -4.8389e-03,  3.3000e-02,  3.6377e-02,  2.2267e-02,\n",
       "          3.9006e-02,  2.3546e-02,  1.0590e-02, -6.7668e-03,  2.2654e-02,\n",
       "          3.7816e-02,  3.3985e-02,  1.4320e-02, -2.0268e-02,  1.6213e-02,\n",
       "         -7.5056e-02, -4.3580e-02, -1.1980e-02, -3.0683e-02,  4.1441e-02,\n",
       "         -1.4618e-02, -8.9411e-03,  1.1536e-02,  1.9782e-02,  3.3240e-02,\n",
       "          5.1114e-03,  1.0002e-02,  1.9953e-02, -3.9657e-02, -1.1193e-02,\n",
       "          6.0912e-02, -2.4026e-02, -2.0804e-02,  7.9830e-03,  2.9038e-02,\n",
       "          1.9761e-02,  6.9239e-03,  5.6124e-03,  6.1296e-02,  4.1832e-03,\n",
       "          2.5818e-02,  2.2119e-03,  1.8062e-02,  6.6215e-02,  2.6332e-02,\n",
       "          5.3421e-02, -1.4268e-02, -2.6278e-02, -6.9822e-03, -3.7129e-02,\n",
       "         -2.2895e-03, -1.2351e-02,  5.5560e-03,  2.6927e-02, -1.1412e-03,\n",
       "         -6.4117e-02, -2.3565e-02,  1.4585e-02,  3.2187e-02,  1.1488e-03,\n",
       "          2.0908e-02, -1.3280e-02, -1.3430e-02,  1.4151e-02,  2.8581e-02,\n",
       "          3.0495e-02,  2.7602e-02,  1.0433e-03,  5.2023e-03,  3.5873e-04,\n",
       "          3.4250e-03,  2.4565e-02,  4.7433e-02, -1.8419e-03,  2.6846e-02,\n",
       "         -3.3163e-03,  2.6491e-02, -1.6620e-02, -2.9514e-03,  4.6517e-02,\n",
       "         -2.0178e-02, -3.7113e-02, -1.0680e-02, -2.5775e-03, -9.1360e-03,\n",
       "          2.2367e-02, -3.3729e-02,  3.8603e-02,  4.2028e-02, -1.6116e-02,\n",
       "          4.1367e-02, -5.0171e-02, -1.2311e-03, -1.4618e-02,  3.5920e-02,\n",
       "         -3.0468e-03, -4.0911e-03,  1.6406e-02, -3.1169e-02,  2.4372e-02,\n",
       "          2.9812e-02, -3.5397e-03, -2.5877e-02, -1.5602e-02, -6.3380e-03,\n",
       "          3.1120e-03,  8.5625e-03,  3.9640e-02,  3.4653e-02, -2.0379e-03,\n",
       "          1.5056e-02, -3.8181e-02,  1.2543e-02,  2.2661e-02, -1.5966e-02,\n",
       "         -2.6374e-02,  1.2523e-02,  1.3684e-02,  2.1154e-02,  1.4626e-02,\n",
       "          1.4217e-01, -2.0984e-03,  5.2391e-02,  7.0815e-03,  1.1418e-02,\n",
       "          1.8310e-02, -2.7533e-02,  2.7060e-03,  3.7722e-03,  1.4289e-02,\n",
       "          4.8819e-03,  7.8974e-02,  6.2292e-02,  1.1453e-02,  6.4543e-02,\n",
       "         -8.8402e-04,  2.3291e-02, -2.1248e-02, -3.4555e-02, -2.6052e-02,\n",
       "          7.3395e-03, -1.8713e-02,  9.1007e-03]),\n",
       " 'transformer.h.9.mlp.c_fc.weight': tensor([[-0.1263,  0.1003,  0.0432,  ...,  0.2170,  0.0198, -0.1404],\n",
       "         [-0.0915,  0.0872,  0.0615,  ...,  0.0048, -0.1113, -0.2263],\n",
       "         [ 0.1290,  0.0250,  0.1792,  ..., -0.1480,  0.2844,  0.1908],\n",
       "         ...,\n",
       "         [ 0.1656,  0.1988, -0.1999,  ..., -0.0282, -0.0565,  0.1884],\n",
       "         [-0.0513, -0.0398,  0.3159,  ..., -0.0569,  0.1251,  0.1349],\n",
       "         [ 0.0052, -0.0937, -0.2332,  ...,  0.0320, -0.0762, -0.1115]]),\n",
       " 'transformer.h.9.mlp.c_fc.bias': tensor([-0.1567, -0.0586, -0.1862,  ..., -0.0808, -0.1747,  0.0605]),\n",
       " 'transformer.h.9.mlp.c_proj.weight': tensor([[ 0.2813, -0.0430, -0.1807,  ..., -0.0268, -0.0099,  0.1054],\n",
       "         [-0.1153, -0.1000, -0.1819,  ..., -0.5141, -0.0151, -0.3968],\n",
       "         [-0.0404,  0.1570, -0.1183,  ..., -0.2827,  0.1967, -0.1631],\n",
       "         ...,\n",
       "         [-0.1986, -0.0699,  0.0277,  ..., -0.1114,  0.0991, -0.1837],\n",
       "         [-0.0446,  0.1790, -0.0538,  ...,  0.1366, -0.1700, -0.0059],\n",
       "         [ 0.1810,  0.1191, -0.1690,  ..., -0.1463, -0.1032,  0.0144]]),\n",
       " 'transformer.h.9.mlp.c_proj.bias': tensor([-4.6645e-02, -1.0990e-01, -2.7257e-01,  1.5499e-01,  9.7615e-02,\n",
       "         -2.4267e-01,  1.6664e-01,  1.7415e-01,  1.8233e-01,  7.1084e-02,\n",
       "         -1.8766e-01, -4.9556e-02,  1.0335e-01,  2.1693e-01, -1.6183e-01,\n",
       "          3.8626e-02, -3.9116e-02,  2.3063e-01,  1.5293e-01, -1.0322e-01,\n",
       "          8.1140e-02,  1.3819e-02, -1.8062e-03, -2.9647e-02, -2.4134e-01,\n",
       "         -1.3232e-02, -2.0712e-01,  9.7280e-02, -4.8264e-03,  1.3334e-02,\n",
       "          2.5184e-02, -1.3851e-02,  1.5864e-01, -1.7938e-01,  4.9989e-03,\n",
       "         -4.4017e-02,  2.1377e-01, -2.7572e-02,  2.3475e-02,  1.6258e-02,\n",
       "          8.5390e-02, -1.3142e-01,  3.6655e-02,  6.3542e-02, -1.7329e-01,\n",
       "         -3.1277e-01,  6.0763e-02,  1.5423e-01, -6.6386e-02,  1.4715e-01,\n",
       "          2.4128e-01,  3.6907e-02, -6.8389e-02, -1.0475e-01,  1.4493e-01,\n",
       "          8.3119e-02, -2.1339e-01,  3.3495e-02, -6.9378e-02, -6.9432e-02,\n",
       "         -7.5200e-02, -1.0936e-02,  1.8573e-01, -2.1191e-01, -3.9096e-01,\n",
       "          8.4828e-02, -1.5332e-01,  1.1962e-01, -1.9299e-01, -7.5922e-02,\n",
       "          2.8689e-01, -1.0406e-01,  4.3814e-02, -8.8036e-02,  1.0242e-01,\n",
       "          1.3584e-01,  1.9973e-02, -2.2582e-01, -1.9397e-01, -3.7615e-02,\n",
       "         -4.3179e-03,  2.0579e-01,  3.5219e-02, -1.0143e-01,  1.6486e-02,\n",
       "          6.2673e-02,  2.5071e-01, -1.5815e-02, -1.5148e-01, -2.1676e-03,\n",
       "          7.3065e-03,  1.0322e-01, -7.1201e-02,  4.8543e-02, -7.6900e-02,\n",
       "          6.1005e-03, -4.4881e-02,  1.0420e-01,  2.7540e-01, -1.3834e-01,\n",
       "         -1.5979e-01,  2.1070e-02,  1.5638e-01,  1.5513e-01, -1.8610e-02,\n",
       "          5.9736e-02,  2.6548e-01, -5.1591e-02, -1.9993e-01,  2.3214e-01,\n",
       "          4.4893e-02,  4.5724e-02,  9.2505e-02,  1.7909e-01, -5.0144e-02,\n",
       "          1.5815e-01,  2.4626e-02, -1.1860e-01,  1.0602e-01, -1.6652e-01,\n",
       "          2.6053e-01,  1.2638e-01,  1.9932e-01,  1.7970e-01,  2.7137e-01,\n",
       "          1.3657e-01, -2.9675e-02, -1.8606e-01, -1.2305e-01,  8.8590e-02,\n",
       "         -2.4939e-02,  1.3136e-01, -5.0992e-02,  8.7640e-02,  2.7342e-01,\n",
       "          1.5242e-02,  1.4187e-01, -1.2874e-01, -2.3542e-01,  1.0312e-02,\n",
       "          1.2333e-01,  5.5724e-02,  7.8074e-02, -1.3216e-01, -2.8968e-01,\n",
       "          6.1413e-02, -5.1442e-03,  1.4312e-01, -2.2536e-01, -1.4487e-01,\n",
       "         -1.3377e-01,  1.2375e-01,  2.0242e-01,  1.8884e-01,  7.4498e-02,\n",
       "         -3.0417e-02,  1.0066e-01, -1.4598e-02,  1.6901e-01, -1.9318e-01,\n",
       "          3.1864e-02,  8.5186e-02, -4.9956e-02,  8.5447e-02,  6.0868e-02,\n",
       "          5.8474e-02, -5.4050e-02, -1.4979e-01,  3.8467e-02,  9.8465e-02,\n",
       "         -2.3694e-01,  1.1825e-02,  5.2717e-02, -1.8730e-02,  1.2019e-02,\n",
       "         -9.4906e-02, -1.5321e-01,  5.6207e-02,  2.0627e-02, -5.7167e-02,\n",
       "         -1.5878e-02, -3.7366e-02,  7.0670e-02, -1.9443e-02, -1.2266e-01,\n",
       "         -4.2204e-02, -1.3531e-01, -9.4064e-02, -9.0040e-02,  2.9191e-02,\n",
       "          2.0907e-01, -2.3428e-01, -1.2359e-01, -1.4506e-01,  1.8681e-01,\n",
       "         -8.5629e-02, -2.9228e-01, -6.9232e-03,  1.5759e-01,  5.3033e-02,\n",
       "          1.5142e-01, -8.3449e-02,  1.7208e-02,  1.3312e-01,  1.2606e-01,\n",
       "          5.0882e-02, -2.2798e-01, -1.9043e-03,  5.1293e-02, -1.7704e-01,\n",
       "         -5.4751e-02,  3.8875e-03,  5.6078e-02,  7.9638e-02,  7.3502e-02,\n",
       "         -1.3192e-01,  6.5902e-02, -6.1788e-02,  2.0751e-01,  2.9838e-02,\n",
       "          5.9709e-02, -5.8736e-02,  9.6689e-02,  6.3798e-02,  1.1788e-01,\n",
       "         -3.5596e-03,  1.1808e-01,  5.4177e-03,  1.5647e-01, -1.2298e-01,\n",
       "          2.0457e-01,  2.7301e-02,  2.1531e-01, -1.1098e-01,  1.2113e-01,\n",
       "          1.8815e-02,  1.4313e-01, -3.5198e-02,  1.4577e-01,  1.2122e-02,\n",
       "          2.0972e-01, -7.5843e-03,  1.2801e-01, -1.8500e-01, -9.0361e-02,\n",
       "          1.1041e-01,  8.3758e-02,  1.7638e-01, -1.4093e-01, -4.4593e-02,\n",
       "         -8.7552e-03,  2.0834e-01,  1.5022e-01, -8.1232e-02, -6.9706e-02,\n",
       "          1.5197e-01, -1.3750e-01, -8.6779e-02,  2.3159e-01, -7.7275e-02,\n",
       "          2.2492e-02,  1.7563e-01, -1.5183e-01, -1.1455e-01, -2.8734e-01,\n",
       "         -1.2182e-01,  1.4882e-01,  1.0653e-01, -1.2947e-01,  1.1363e-01,\n",
       "         -3.6037e-01,  8.9070e-02,  1.1562e-02, -1.0585e-01,  1.1428e-01,\n",
       "          2.8572e-02,  1.7015e-01, -5.6327e-02,  4.8283e-02,  1.6017e-01,\n",
       "         -7.6671e-02, -1.1675e-01,  1.5664e-01, -2.1910e-01,  1.1274e-01,\n",
       "         -2.0155e-02, -1.4090e-01,  2.3459e-01,  6.4530e-02, -6.0280e-02,\n",
       "         -1.2191e-01, -6.3197e-02,  6.2332e-02,  1.1732e-03, -3.3251e-01,\n",
       "          1.3410e-01,  1.0073e-01,  2.4873e-01, -1.4790e-01, -1.2361e-01,\n",
       "          1.2249e-01, -2.4586e-01,  7.7483e-02,  1.1315e-02, -9.8362e-02,\n",
       "         -2.0711e-01, -6.6671e-02,  1.7929e-01, -2.8183e-01,  7.2839e-02,\n",
       "         -1.8233e-01, -2.0555e-01,  1.1689e-01, -7.1077e-02, -4.5069e-01,\n",
       "         -1.8665e-01,  2.2080e-01,  1.2884e-01,  3.5437e-02, -7.1610e-02,\n",
       "         -3.2340e-01, -4.6526e-02,  1.4190e-01,  9.2176e-02,  4.4605e-02,\n",
       "          9.8919e-02,  1.8468e-01,  8.4106e-02, -1.7906e-02,  3.9992e-02,\n",
       "          1.4725e-01,  8.5672e-02, -1.4753e-02,  6.3064e-03,  7.6518e-03,\n",
       "         -1.2123e-02, -2.3181e-01, -3.4100e-02, -2.1264e-02,  7.2029e-03,\n",
       "         -2.2954e-01, -4.0891e-02, -8.7613e-03, -6.9527e-02,  4.1800e-02,\n",
       "         -1.3394e-01, -1.5761e-02,  9.2174e-02, -9.0727e-04, -2.1286e-01,\n",
       "          9.6180e-02,  3.4437e-02,  1.0252e-01, -2.6328e-01, -6.3576e-02,\n",
       "          1.6987e-02, -3.2421e-01,  2.8497e-01, -2.2376e-01,  5.3744e-02,\n",
       "         -2.1846e-01,  7.2129e-02,  2.6935e-01,  2.3953e-01,  2.6346e-01,\n",
       "          5.1689e-02,  3.1074e-02,  1.9459e-02, -3.6945e-02, -1.5042e-02,\n",
       "         -1.7358e-01,  1.3155e-01, -1.4216e-01, -1.2830e+00, -1.8172e-01,\n",
       "         -2.1910e-01, -1.4435e-01,  1.3411e-01,  2.6381e-01,  8.8686e-02,\n",
       "         -1.3577e-01, -3.0493e-04, -1.3565e-01,  2.2613e-01, -1.7768e-01,\n",
       "         -1.1167e-01,  2.5651e-02,  8.4247e-02,  4.7100e-02, -1.4081e-01,\n",
       "          2.8840e-03, -1.9117e-01,  6.2996e-02,  2.0388e-01, -2.1876e-02,\n",
       "         -1.2601e-01, -2.1485e-02, -7.1363e-02,  2.0348e-01, -1.2332e-01,\n",
       "          7.6071e-02,  1.9128e-01,  2.7049e-01,  6.0912e-02,  7.4316e-02,\n",
       "          1.5869e-02, -8.8610e-02,  3.8557e-02,  4.3029e-01,  1.5355e-02,\n",
       "         -1.1744e-01,  2.2373e-01, -5.0764e-02,  1.6264e-01,  1.5239e-02,\n",
       "          2.1836e-02, -1.3108e-01, -3.0124e-02, -4.8933e-03,  2.2778e-01,\n",
       "         -1.1355e-01,  6.0990e-02, -9.9982e-02, -1.5382e-01,  7.5107e-02,\n",
       "          3.0128e-01,  3.1461e-02,  5.1018e-02, -1.5052e-01, -2.4927e-01,\n",
       "          2.1779e-01,  1.7069e-02, -1.9073e-01,  8.2023e-02,  1.7980e-01,\n",
       "          5.8830e-02, -7.8000e-02,  1.5013e-02,  1.1365e-01,  1.3778e-02,\n",
       "          1.4144e-01,  6.3252e-02, -1.2104e-01, -8.6013e-02, -3.5023e-02,\n",
       "         -3.0819e-02,  7.0698e-02,  1.1305e+00,  6.6620e-02,  1.2980e-02,\n",
       "          1.5430e-01,  1.1084e-01, -3.1931e-02, -2.2845e-01,  1.5752e-01,\n",
       "          3.1179e-01,  1.1690e-02, -1.1666e-01,  6.6314e-02, -1.4804e-02,\n",
       "         -1.0173e-01, -2.0323e-01,  3.8088e-02,  1.5078e-01,  4.4971e-02,\n",
       "         -2.7317e-01,  3.9841e-02,  3.8331e-02,  4.6648e-02, -8.5646e-02,\n",
       "         -1.1726e-01, -8.1172e-02, -1.3430e-01, -2.2710e-01, -1.2536e-01,\n",
       "         -7.4126e-02,  1.5675e-02,  1.3557e-01, -1.4051e-01, -1.5143e-01,\n",
       "         -4.9571e-02,  1.4896e+00,  4.2735e-02, -4.1363e-02, -2.0904e-02,\n",
       "          6.3417e-02, -1.4033e-01, -6.3794e-02,  1.7028e-01,  3.8541e-02,\n",
       "         -1.2516e-01, -9.4359e-02,  8.2163e-02,  1.2015e-01,  1.7628e-01,\n",
       "          9.5908e-02,  1.2566e-01, -1.9221e-01,  1.1375e-01,  5.1612e-02,\n",
       "          1.2616e-01,  3.8993e-02,  8.8228e-02, -1.0839e-01, -1.4850e-01,\n",
       "          6.6314e-05, -7.7564e-02, -6.3030e-03,  1.5601e-01,  1.8852e-01,\n",
       "         -1.6829e-01, -8.9566e-02,  2.7002e-01, -1.1344e-01, -5.9498e-02,\n",
       "          8.8728e-02,  4.1073e-02,  1.1490e-01,  1.0474e-01, -3.9621e-02,\n",
       "          4.2453e-02, -1.3514e-01,  1.4181e-01,  5.7557e-02,  4.7732e-02,\n",
       "         -1.8116e-01, -1.6362e-01, -2.6371e-01,  1.0961e-01, -1.2800e-01,\n",
       "          4.5317e-02,  3.7697e-02,  3.9600e-03, -3.5139e-02, -1.5755e-01,\n",
       "          8.7411e-03, -9.2033e-02, -5.7770e-02,  1.2038e-02, -1.2095e-02,\n",
       "          1.9991e-01,  1.2894e-01, -1.0110e-01, -2.2756e-01, -1.5150e-01,\n",
       "          1.7469e-01, -2.8941e-02,  7.0995e-02, -1.7859e-01, -1.4882e-01,\n",
       "         -1.8845e-01,  1.6607e-01,  3.2358e-02, -1.8974e-01, -2.4711e-01,\n",
       "          1.0224e-01, -3.4859e-02, -4.4967e-02,  1.4403e-01,  1.6580e-02,\n",
       "          8.2170e-02, -9.8024e-02, -2.9623e-01,  1.5860e-01,  7.1731e-02,\n",
       "          2.8512e-02,  1.8698e-02, -2.0622e-02, -7.5021e-02,  2.5783e-02,\n",
       "         -7.0775e-02,  2.1523e-02,  2.2910e-01, -8.6382e-02, -1.2866e-01,\n",
       "          1.1657e-01, -1.9386e-01,  1.1100e-01, -5.9276e-02, -1.6057e-01,\n",
       "          1.7637e-02,  1.6796e-02, -4.7407e-02, -1.0866e-01,  1.8590e-01,\n",
       "         -7.7290e-02, -6.0036e-02,  1.3764e-02, -2.3848e-02,  1.2234e-01,\n",
       "         -1.6364e-01, -1.1911e-01, -3.4663e-02, -9.7506e-02,  3.1605e-01,\n",
       "         -1.6558e-01,  3.2261e-02, -1.0310e-01, -8.4768e-02, -1.9401e-01,\n",
       "         -2.0051e-02, -2.2758e-01, -1.2467e-01,  1.8934e-01,  1.5265e-01,\n",
       "         -1.2989e-01,  3.5823e-02, -2.3359e-01,  2.1274e-01,  1.4823e-01,\n",
       "         -1.5298e-01, -2.4177e-02, -1.2925e-01, -2.5155e-02, -8.6855e-02,\n",
       "          1.7696e-02,  1.9299e-01, -2.6344e-01, -8.2949e-02,  1.9863e-01,\n",
       "         -2.5698e-01, -9.6519e-02, -1.8943e-01, -2.2586e-01, -1.2087e-01,\n",
       "         -1.3587e-01, -1.5572e-01, -1.5387e-01,  1.3237e-01,  1.3065e-01,\n",
       "         -1.7808e-01,  1.9847e-01,  1.2240e-01, -9.0830e-02,  7.8478e-03,\n",
       "         -6.0225e-02, -1.4847e-01,  2.2021e-01,  3.8675e-02,  1.0557e-01,\n",
       "          2.0231e-01,  1.0333e-02, -3.9311e-02, -2.5853e-01, -5.2108e-03,\n",
       "         -8.4177e-02, -9.7600e-02,  5.6339e-02,  2.3896e-01, -9.7650e-02,\n",
       "         -7.5705e-02,  2.6809e-01, -3.0667e-02, -2.0390e-01, -1.5002e-01,\n",
       "          1.1131e-01, -6.1663e-02,  9.7560e-02, -2.2336e-02,  5.3332e-02,\n",
       "          1.3491e-01,  3.6292e-02,  3.3832e-02,  7.0793e-02, -2.2014e-03,\n",
       "          2.5348e-01,  1.7549e-02, -9.4112e-02,  1.4941e-01,  2.5454e-01,\n",
       "         -7.3731e-02, -5.2944e-02, -2.0348e-01, -7.6453e-03,  8.4055e-02,\n",
       "         -5.7725e-02,  1.9312e-01,  3.9951e-01,  1.0299e-01,  2.2905e-01,\n",
       "         -1.0512e-01, -1.7754e-01,  1.2691e-01, -3.4129e-02, -3.1649e-01,\n",
       "         -1.3639e-01, -7.3219e-02, -2.7001e-02,  4.1069e-02,  1.1430e-02,\n",
       "          2.0258e-01,  1.6231e-01, -7.7365e-02,  3.0301e-01, -5.8596e-02,\n",
       "         -5.9156e-02,  4.5032e-02, -2.9409e-02,  9.6740e-02, -8.4039e-02,\n",
       "          1.5169e-01,  5.2729e-02, -6.4264e-02, -1.3393e-01,  1.3587e-01,\n",
       "          1.7235e-02, -1.4441e-01,  3.5125e-02,  3.2920e-02,  8.8476e-03,\n",
       "          8.5842e-02, -1.7053e-01, -1.0479e-01, -3.4624e-02, -3.5924e-02,\n",
       "          5.6040e-02, -1.7124e-01, -4.1189e-02,  2.0853e-01,  1.0226e-01,\n",
       "          1.5869e-01, -1.5678e-01, -9.4734e-02, -5.8940e-02,  2.2240e-01,\n",
       "          2.2156e-01, -1.9327e-02, -1.2897e-01, -2.2394e-01, -4.4447e-02,\n",
       "          7.5848e-02, -2.4911e-01,  1.3489e-01, -1.3736e-01,  8.6539e-02,\n",
       "          5.9652e-03, -1.8353e-01, -5.8970e-02, -7.3803e-02, -3.1374e-01,\n",
       "         -1.7683e-01,  8.5927e-02,  1.8984e-02, -1.9906e-01, -2.5258e-02,\n",
       "         -1.9547e-01, -1.4445e-01, -4.0224e-02, -5.2308e-02,  1.1811e-02,\n",
       "          1.2978e-01, -5.4838e-02,  1.8505e-01,  1.0740e-01, -1.0936e-02,\n",
       "         -7.7379e-02,  1.4461e-03, -1.2349e-01,  2.4152e-02,  2.1144e-01,\n",
       "         -1.5100e-01,  1.2033e-01,  2.1154e-01, -7.1171e-02,  5.5354e-02,\n",
       "          1.4147e-02,  4.3370e-02, -1.8958e-01]),\n",
       " 'transformer.h.10.ln_1.weight': tensor([0.4269, 0.3799, 0.3893, 0.3629, 0.3722, 0.3487, 0.5020, 0.3584, 0.3821,\n",
       "         0.3207, 0.4149, 0.3587, 0.3574, 0.3838, 0.4463, 0.3977, 0.3977, 0.3702,\n",
       "         0.3779, 0.3975, 0.3311, 0.3544, 0.3800, 0.4131, 0.3798, 0.3877, 0.4171,\n",
       "         0.3595, 0.3612, 0.3603, 0.3588, 0.4113, 0.3604, 0.3545, 0.3667, 0.4339,\n",
       "         0.3249, 0.3704, 0.3545, 0.3721, 0.3368, 0.3487, 0.3353, 0.3564, 0.3506,\n",
       "         0.3993, 0.3607, 0.3410, 0.4021, 0.3760, 0.3486, 0.3444, 0.3885, 0.3701,\n",
       "         0.3740, 0.3779, 0.3729, 0.4284, 0.3385, 0.4539, 0.3883, 0.3629, 0.4170,\n",
       "         0.3713, 0.9214, 0.3348, 0.3570, 0.4068, 0.4061, 0.3641, 0.3857, 0.3037,\n",
       "         0.3584, 0.3480, 0.3252, 0.3683, 0.4444, 0.4629, 0.3827, 0.3628, 0.3694,\n",
       "         0.3467, 0.3526, 0.3801, 0.3851, 0.4228, 0.4093, 0.7403, 0.3598, 0.3877,\n",
       "         0.3584, 0.3423, 0.3475, 0.3584, 0.3424, 0.3330, 0.3847, 0.4186, 0.4209,\n",
       "         0.4701, 0.3586, 0.3724, 0.4209, 0.3873, 0.3735, 0.3428, 0.4019, 0.3808,\n",
       "         0.3334, 0.3721, 0.3839, 0.3805, 0.3675, 0.3779, 0.3794, 0.3740, 0.4325,\n",
       "         0.3949, 0.3448, 0.4574, 0.3780, 0.3578, 0.3412, 0.3506, 0.4140, 0.3799,\n",
       "         0.3388, 0.4181, 0.3878, 0.3740, 0.3879, 0.3373, 0.4092, 0.3597, 0.3545,\n",
       "         0.3415, 0.3582, 0.4604, 0.2745, 0.3591, 0.3707, 0.3878, 0.4010, 0.3506,\n",
       "         0.4058, 0.3760, 0.3916, 0.3913, 0.3663, 0.3670, 0.3782, 0.3946, 0.4417,\n",
       "         0.4209, 0.3869, 0.3525, 0.3730, 0.3864, 0.3505, 0.4150, 0.4600, 0.3799,\n",
       "         0.3870, 0.4170, 0.3722, 0.3547, 0.3877, 0.5442, 0.3619, 0.3896, 0.3617,\n",
       "         0.3643, 0.3731, 0.3980, 0.3877, 0.3663, 0.3780, 0.3408, 0.4256, 0.3529,\n",
       "         0.3271, 0.3438, 0.3584, 0.4188, 0.3390, 0.3503, 0.3532, 0.3881, 0.3629,\n",
       "         0.3963, 0.3746, 0.3604, 0.3701, 0.3977, 0.3623, 0.4951, 0.3287, 0.3498,\n",
       "         0.3665, 0.4218, 0.3889, 0.4014, 0.3759, 0.3662, 0.3255, 0.3897, 0.3525,\n",
       "         0.3092, 0.4251, 0.3579, 0.3555, 0.4457, 0.3956, 0.4703, 0.3759, 0.3488,\n",
       "         0.4288, 0.3623, 0.2928, 0.3678, 0.3938, 0.3628, 0.3643, 0.4017, 0.3761,\n",
       "         0.3565, 0.3459, 0.3525, 0.3604, 0.3486, 0.3274, 0.3842, 0.4756, 0.3351,\n",
       "         0.3486, 0.3936, 0.3776, 0.3408, 0.4105, 0.3850, 0.4303, 0.4073, 0.3716,\n",
       "         0.3623, 0.3284, 0.3761, 0.3558, 0.4561, 0.3662, 0.3891, 0.3492, 0.3952,\n",
       "         0.3525, 0.4122, 0.3604, 0.4110, 0.3520, 0.3603, 0.3528, 0.3653, 0.3701,\n",
       "         0.3705, 0.3632, 0.3702, 0.3464, 0.3315, 0.9082, 0.4844, 0.3878, 0.4224,\n",
       "         0.4873, 0.5058, 0.3504, 0.3468, 0.4508, 0.3556, 0.4170, 0.3428, 0.3680,\n",
       "         0.3494, 0.3252, 0.3216, 0.3488, 0.5176, 0.4359, 0.4386, 0.4021, 0.3604,\n",
       "         0.6687, 0.4509, 0.3995, 0.3760, 0.3447, 0.3291, 0.4286, 0.3506, 0.3464,\n",
       "         0.3728, 0.3721, 0.3877, 0.3631, 0.3889, 0.4053, 0.3542, 0.3467, 0.3470,\n",
       "         0.3740, 0.3438, 0.3880, 0.3232, 0.3345, 0.4736, 0.3486, 0.3643, 0.2282,\n",
       "         0.3596, 0.4405, 0.3682, 0.3545, 0.4109, 0.3877, 0.3549, 0.3821, 0.4138,\n",
       "         0.3649, 0.3937, 0.4467, 0.3380, 0.3823, 0.3390, 0.3613, 0.3486, 0.3947,\n",
       "         0.3479, 0.3369, 0.3642, 0.4576, 0.3565, 0.3604, 0.4678, 0.3507, 0.3409,\n",
       "         0.3938, 0.4287, 0.3874, 0.3395, 0.3938, 0.3597, 0.3819, 0.3784, 0.3355,\n",
       "         0.4237, 0.3854, 0.3697, 0.3742, 0.3560, 0.4006, 0.3878, 0.3462, 0.3679,\n",
       "         0.4106, 0.3858, 0.4077, 0.3658, 0.3292, 0.4183, 0.3876, 0.3637, 0.3541,\n",
       "         0.3504, 0.3995, 0.3469, 0.3624, 0.0751, 0.3525, 0.4702, 0.3971, 0.4287,\n",
       "         0.2670, 0.3829, 0.3473, 0.3740, 0.3528, 0.4322, 0.3682, 0.4757, 0.4069,\n",
       "         0.3330, 0.3643, 0.3799, 0.3565, 0.3373, 0.3736, 0.7194, 0.3672, 0.3409,\n",
       "         0.3674, 0.3385, 0.3377, 0.3506, 0.3413, 0.3721, 0.4098, 0.3594, 0.3478,\n",
       "         0.3721, 0.4006, 0.3331, 0.3447, 0.3565, 0.3330, 0.3424, 0.3428, 0.3373,\n",
       "         0.3643, 0.3677, 0.3486, 0.4034, 0.4038, 0.3532, 0.3037, 0.4288, 0.3565,\n",
       "         0.3787, 0.3585, 0.3193, 0.3662, 0.3684, 0.3512, 0.3473, 0.2831, 0.3468,\n",
       "         0.3501, 0.3975, 0.3371, 0.4131, 0.3237, 0.3936, 0.3959, 0.4275, 0.3546,\n",
       "         0.3813, 0.3963, 0.3406, 0.4351, 0.3786, 0.3426, 0.0793, 0.3633, 0.3564,\n",
       "         0.3762, 0.3504, 0.3385, 0.4036, 0.3662, 0.4053, 0.3807, 0.3608, 0.3440,\n",
       "         0.3097, 0.3402, 0.4296, 0.3451, 0.3604, 0.2707, 0.3778, 0.3840, 0.3506,\n",
       "         0.3514, 0.3593, 0.3371, 0.4033, 0.3897, 0.3751, 0.3271, 0.3663, 0.3678,\n",
       "         0.3529, 0.3464, 0.4229, 0.7445, 0.0817, 0.3701, 0.3506, 0.4114, 0.3385,\n",
       "         0.3502, 0.3604, 0.3820, 0.3760, 0.3740, 0.4229, 0.3527, 0.3547, 0.3826,\n",
       "         0.3491, 0.2555, 0.3135, 0.3976, 0.3545, 0.3741, 0.3881, 0.3794, 0.4218,\n",
       "         0.4206, 0.3507, 0.3447, 0.3866, 0.4392, 0.3490, 0.3339, 0.3701, 0.3780,\n",
       "         0.3899, 0.3635, 0.4133, 0.3878, 0.3506, 0.3316, 0.3702, 0.3428, 0.3724,\n",
       "         0.3866, 0.3740, 0.3621, 0.3695, 0.5004, 0.4188, 0.4083, 0.3567, 0.3604,\n",
       "         0.3875, 0.3604, 0.3508, 0.3427, 0.4058, 0.3494, 0.3581, 0.3841, 0.3709,\n",
       "         0.3975, 0.3938, 0.3547, 0.3913, 0.3528, 0.3857, 0.4092, 0.3637, 0.3604,\n",
       "         0.4512, 0.3335, 0.4250, 0.3740, 0.3817, 0.4403, 0.3930, 0.3623, 0.3752,\n",
       "         0.3800, 0.3534, 0.3797, 0.3926, 0.3470, 0.3711, 0.3545, 0.3976, 0.4579,\n",
       "         0.3926, 0.3929, 0.4056, 0.4692, 0.4213, 0.3706, 0.3444, 0.3660, 0.4895,\n",
       "         0.3365, 0.3584, 0.4805, 0.3617, 0.3545, 0.3374, 0.4227, 0.3780, 0.3525,\n",
       "         0.4015, 0.3311, 0.4190, 0.3645, 0.3760, 0.3750, 0.3546, 0.3500, 0.3741,\n",
       "         0.3622, 0.3557, 0.3994, 0.3468, 0.3529, 0.3643, 0.3603, 0.3565, 0.3712,\n",
       "         0.3629, 0.3825, 0.3493, 0.3762, 0.3700, 0.4971, 0.3995, 0.3662, 0.3802,\n",
       "         0.3957, 0.3652, 0.3694, 0.3959, 0.4159, 0.3516, 0.4100, 0.3723, 0.3806,\n",
       "         0.3580, 0.3900, 0.3955, 0.3956, 0.3434, 0.3506, 0.3741, 0.3774, 0.3721,\n",
       "         0.3769, 0.3700, 0.3580, 0.3467, 0.3721, 0.4273, 0.3748, 0.3468, 0.3407,\n",
       "         0.4152, 0.5294, 0.3857, 0.3896, 0.4077, 0.4439, 0.3799, 0.3541, 0.4308,\n",
       "         0.3727, 0.4526, 0.3488, 0.4519, 0.4253, 0.3896, 0.3559, 0.3797, 0.3531,\n",
       "         0.3832, 0.3592, 0.4759, 0.3464, 0.4093, 0.3818, 0.3389, 0.3770, 0.4151,\n",
       "         0.3417, 0.3628, 0.3565, 0.3741, 0.4168, 0.3625, 0.3644, 0.3720, 0.3192,\n",
       "         0.3486, 0.3301, 0.3642, 0.4055, 0.5101, 0.3756, 0.3604, 0.3867, 0.3780,\n",
       "         0.3490, 0.3807, 0.4044, 0.3124, 0.3692, 0.3579, 0.3563, 0.3252, 0.3525,\n",
       "         0.3859, 0.3624, 0.3754, 0.3485, 0.3446, 0.3584, 0.4422, 0.3619, 0.4193,\n",
       "         0.3468, 0.4541, 0.3491, 0.3587, 0.4319, 0.4347, 0.3656, 0.4070, 0.4190,\n",
       "         0.3837, 0.3899, 0.3525, 0.3579, 0.3858, 0.3467, 0.3527, 0.4534, 0.3567,\n",
       "         0.3506, 0.4093, 0.3447, 0.3662, 0.3467, 0.3721, 0.4247, 0.4153, 0.4012,\n",
       "         0.3857, 0.3780, 0.3708, 0.3316, 0.3564, 0.3564, 0.3896, 0.3534, 0.3613,\n",
       "         0.4041, 0.4477, 0.4032, 0.3485, 0.3692, 0.4135, 0.3936, 0.2861, 0.4619,\n",
       "         0.3525, 0.4006, 0.3798, 0.3356, 0.3679, 0.3562, 0.3254, 0.3975, 0.4228,\n",
       "         0.2575, 0.3506, 0.3588, 0.3804, 0.3326, 0.3760, 0.4110, 0.3343, 0.3214,\n",
       "         0.3534, 0.3275, 0.3462]),\n",
       " 'transformer.h.10.ln_1.bias': tensor([ 3.0510e-02,  6.0018e-03,  4.8768e-02,  1.1650e-02,  5.8796e-03,\n",
       "          1.0598e-02, -6.7249e-02,  2.5557e-02,  1.3905e-02,  6.4351e-04,\n",
       "          7.5819e-03,  1.2247e-02,  2.6726e-02,  2.7891e-02,  4.7979e-02,\n",
       "         -4.1496e-03,  4.0992e-02,  3.4726e-02, -1.0701e-03,  1.3254e-02,\n",
       "          3.3631e-02,  2.3287e-02,  2.1054e-02,  2.5587e-02,  2.0324e-02,\n",
       "          6.3015e-03, -1.6431e-03,  1.5146e-02,  2.8475e-02,  6.5443e-03,\n",
       "          1.0149e-02, -6.4570e-03, -9.9454e-03,  2.3009e-02,  2.5093e-02,\n",
       "          5.7307e-02, -2.3542e-02,  5.4855e-03,  3.6255e-02,  6.7605e-05,\n",
       "          3.6737e-03, -2.2789e-03, -6.6622e-03,  1.3133e-02,  3.4681e-02,\n",
       "          1.6549e-02,  1.7798e-02,  9.1896e-03,  7.5546e-03,  5.7225e-03,\n",
       "          3.0501e-02, -7.7824e-03,  1.6269e-02, -1.4698e-02,  1.7723e-02,\n",
       "         -1.2181e-02, -3.4919e-03,  2.8184e-02,  5.7460e-04,  1.9307e-02,\n",
       "          2.8484e-02,  2.0697e-02,  3.4364e-02,  5.2619e-03,  1.0895e+00,\n",
       "          8.9252e-03, -1.7973e-02, -2.6218e-02,  4.1295e-02,  1.5583e-02,\n",
       "          4.8572e-03,  2.7360e-02,  2.5208e-02,  2.6618e-02,  2.2383e-02,\n",
       "          3.0180e-02, -2.0396e-02,  1.3613e-02,  1.3994e-02,  3.2356e-02,\n",
       "          4.5118e-02,  1.0150e-02,  1.5576e-02,  2.3248e-02,  6.8681e-02,\n",
       "          2.1442e-02,  3.6212e-02, -1.7378e-03,  1.6896e-02,  2.0278e-02,\n",
       "          1.5742e-03,  1.2599e-02,  4.4826e-02, -8.9105e-04,  1.5220e-02,\n",
       "          1.0788e-02,  6.8030e-03,  2.6381e-02,  3.6601e-02,  6.5487e-02,\n",
       "          3.1313e-03, -2.7101e-02, -3.9119e-02,  1.7792e-02,  2.0577e-02,\n",
       "          2.1596e-02,  3.7847e-02,  1.0212e-02,  7.9026e-03,  1.4136e-02,\n",
       "          1.0731e-02,  2.6045e-02,  1.9629e-02,  5.3064e-02,  1.7490e-02,\n",
       "         -7.8047e-03,  5.6762e-02,  1.0151e-02,  3.9767e-02,  4.1502e-02,\n",
       "          2.9220e-02,  1.8263e-02,  3.7876e-03, -2.8561e-03,  4.4087e-03,\n",
       "          3.1142e-02,  1.5206e-02,  4.4540e-02,  4.8803e-02,  2.2513e-02,\n",
       "          1.9234e-02,  2.6071e-02,  1.8358e-02,  1.0985e-02,  1.7072e-02,\n",
       "          1.1037e-02,  2.7748e-02,  4.3213e-02, -6.5276e-01, -1.0676e-03,\n",
       "          4.7908e-03, -5.9358e-03,  4.9437e-02,  2.0611e-02,  1.2362e-02,\n",
       "         -1.6437e-02, -1.2943e-02,  7.8778e-03,  7.7959e-03,  2.8179e-02,\n",
       "          4.6312e-02, -3.7110e-02,  1.7228e-02,  2.0611e-02,  2.1190e-03,\n",
       "          6.7950e-04,  1.7173e-02,  2.7729e-02,  9.7434e-03, -1.8524e-02,\n",
       "         -4.4523e-02,  1.8437e-02,  1.0640e-02,  2.7398e-02,  2.5514e-02,\n",
       "          4.5742e-02,  1.2592e-03,  1.3448e-01,  1.7151e-03,  3.0443e-02,\n",
       "          1.3813e-02,  2.7351e-02,  3.7165e-02,  2.1619e-02,  3.5051e-02,\n",
       "          3.2485e-02,  7.6267e-02,  1.8186e-02, -6.8216e-03,  1.6186e-02,\n",
       "          2.4216e-02, -2.9053e-03,  3.0967e-02,  3.0941e-02,  4.1112e-02,\n",
       "          1.6433e-02,  6.9999e-03,  1.0342e-02,  1.1311e-02, -1.0954e-02,\n",
       "          1.7435e-02,  4.8904e-02,  2.9742e-02,  1.6672e-02,  3.0743e-02,\n",
       "          9.5988e-02,  2.1865e-02,  4.1136e-02,  4.5287e-02,  2.8203e-02,\n",
       "          6.6434e-03,  7.2262e-03,  2.5223e-02,  2.5595e-02,  1.0206e-02,\n",
       "          1.4698e-02,  3.6713e-02,  2.1287e-02,  2.7897e-02,  8.4845e-03,\n",
       "         -3.1251e-03,  4.7961e-02,  3.6884e-02,  4.4813e-02,  3.6081e-02,\n",
       "          2.1300e-02,  1.9595e-02,  1.8230e-02,  4.9084e-02,  1.8052e-02,\n",
       "          8.8896e-03,  2.7559e-02,  3.0454e-03,  8.2039e-03, -1.0471e-02,\n",
       "         -2.6374e-04,  5.2323e-03,  2.1517e-02,  3.4661e-02,  5.8228e-03,\n",
       "          2.0718e-02,  6.4387e-03, -2.5122e-02,  1.8809e-02,  7.2337e-03,\n",
       "          7.7876e-03,  1.5827e-02,  1.1656e-02,  2.1921e-02,  1.4640e-02,\n",
       "          3.8638e-02,  1.1814e-02,  2.4043e-02,  1.2504e-02,  2.3457e-02,\n",
       "          8.9652e-04,  4.5214e-03,  2.9194e-02,  2.6070e-02,  2.9030e-02,\n",
       "          3.8022e-02,  4.5631e-02,  5.0841e-03,  8.6518e-03,  3.4771e-02,\n",
       "         -2.9929e-02,  2.8767e-02,  2.6812e-02, -6.3973e-03,  2.6378e-02,\n",
       "          1.7356e-02,  2.4563e-02,  2.6616e-02, -1.5714e-03,  3.1854e-02,\n",
       "          1.7033e-02, -9.0867e-02, -8.8382e-03,  3.5924e-02,  2.0487e-02,\n",
       "          3.1361e-02, -6.6589e-03,  2.1889e-02, -8.9931e-03,  1.0533e-03,\n",
       "          2.1037e-02,  5.5251e-03,  2.7291e-02,  1.7257e-02,  4.9234e-03,\n",
       "          1.4868e-02,  1.6623e-02,  2.9330e-03,  1.0793e-01,  1.2949e-02,\n",
       "          1.7930e-02,  1.3331e-02,  2.7704e-02, -1.5497e-01,  6.9195e-02,\n",
       "          1.6382e-02,  3.6435e-03,  3.6038e-02,  2.4597e-02,  2.9102e-02,\n",
       "          2.8022e-02,  1.9410e-02,  2.1548e-02,  2.6269e-02,  4.4157e-03,\n",
       "          1.2594e-02,  1.5880e-02, -1.2743e-02,  3.1621e-02,  5.0564e-03,\n",
       "          3.8002e-03,  1.7110e-02,  2.5296e-02,  4.4084e-02,  2.9926e-02,\n",
       "          8.9388e-03,  8.0685e-02,  2.9842e-02,  2.0275e-02,  1.8288e-01,\n",
       "          1.2359e-02,  4.6401e-02, -2.3895e-03,  4.8557e-03,  1.7429e-02,\n",
       "          4.1916e-02,  1.8273e-02,  2.0372e-02,  2.2133e-02,  3.2574e-03,\n",
       "         -1.3338e-02, -1.8723e-01,  1.0802e-02,  1.8939e-02,  2.5256e-02,\n",
       "          3.1490e-03,  9.3702e-03,  4.4415e-03,  7.3213e-03,  7.3003e-03,\n",
       "          2.9991e-02,  1.6974e-02,  2.8924e-02,  2.9901e-02, -5.3843e-04,\n",
       "          6.7884e-03,  1.4092e-02, -1.5407e-03, -4.1260e-03,  1.0127e-02,\n",
       "         -3.5204e-03, -5.3762e-03,  2.0368e-02,  1.2082e-03,  2.2934e-02,\n",
       "          1.5206e-02, -1.4959e-02,  1.2037e-02,  1.2362e-02, -1.2875e-02,\n",
       "          1.6643e-02,  4.5399e-02,  3.3174e-02,  4.1726e-02,  2.6364e-02,\n",
       "          1.2428e-02,  4.2257e-02, -3.1136e-02,  2.2604e-02,  8.6213e-03,\n",
       "          9.7748e-02,  6.5618e-03, -2.5439e-03,  2.5821e-03,  1.2533e-02,\n",
       "          3.2014e-02, -5.8792e-03,  3.8993e-02,  2.9207e-01,  6.5573e-02,\n",
       "          3.7718e-03,  3.6122e-02, -8.5052e-03,  3.5195e-02,  1.1074e-02,\n",
       "          4.3378e-02,  3.2003e-03,  2.5859e-02,  1.2299e-02,  2.2928e-02,\n",
       "         -2.3925e-02,  1.5934e-02,  2.9323e-02, -3.9099e-03,  5.1672e-02,\n",
       "          3.0027e-02,  2.3198e-02, -1.1945e-02, -2.1119e-01,  5.8699e-02,\n",
       "          1.6626e-02,  4.8430e-02,  1.1477e-02,  2.9299e-02,  1.2431e-02,\n",
       "          3.2892e-02, -2.4925e-02,  1.2931e-02,  6.6905e-03,  5.6148e-03,\n",
       "          3.2051e-02, -3.6190e-03,  2.8784e-02, -7.4883e-02,  1.3950e-02,\n",
       "          2.6382e-02,  1.3927e-02,  3.2732e-02,  1.0389e-02,  3.6522e-02,\n",
       "          3.8695e-03,  1.8970e-02,  8.8188e-03,  2.5616e-02,  1.8713e-02,\n",
       "          2.5290e-02,  3.0087e-02,  3.5146e-02,  1.6163e-02,  1.6035e-02,\n",
       "          3.4702e-02,  1.7713e-02,  4.2986e-02,  1.5878e-02,  1.5618e-02,\n",
       "         -6.7364e-02,  1.6589e-02,  2.3507e-02,  2.9140e-02,  3.2753e-02,\n",
       "         -3.6422e-03,  1.5391e-02,  8.8451e-03,  1.6420e-02, -2.5854e-03,\n",
       "         -1.1436e-02,  4.4180e-03, -3.5285e-02,  3.6272e-02, -1.3829e-02,\n",
       "          1.0876e-02,  4.2532e-02, -3.6222e-02,  3.4925e-02,  1.0801e-03,\n",
       "          1.1326e-02,  1.0099e-02,  3.1453e-02, -6.8046e-03,  3.5503e-03,\n",
       "          1.5443e-02,  4.0166e-02,  2.1864e-02,  4.5181e-05,  5.6395e-03,\n",
       "          2.1827e-02, -1.5863e-03,  1.7870e-02,  1.5306e-02, -1.4041e-02,\n",
       "          2.0903e-02,  1.7877e-02,  1.4547e-02,  1.1389e-02,  5.7616e-03,\n",
       "          5.5374e-02,  2.1508e-02,  2.7936e-02,  3.7233e-02,  3.0709e-02,\n",
       "          2.0045e-02,  2.4502e-02,  3.2306e-02,  2.4381e-02,  5.7804e-02,\n",
       "          2.6354e-01, -3.4994e-02,  1.7011e-02,  1.8178e-02,  1.3185e-02,\n",
       "          1.8638e-03,  1.6515e-02,  7.2046e-03, -2.0771e-02,  3.0423e-02,\n",
       "         -1.0573e-02,  4.3190e-02,  2.9087e-02,  2.3918e-02,  1.8108e-02,\n",
       "          2.2516e-02, -7.7928e-02,  4.8908e-02,  1.2752e-02,  9.5487e-03,\n",
       "         -1.3659e-02,  1.6999e-02,  1.3089e-02,  1.0188e-01,  3.1624e-02,\n",
       "          4.4236e-02,  2.6660e-03, -2.2002e-02,  9.4993e-03,  1.6732e-02,\n",
       "          6.7471e-03,  1.0948e-02,  3.9674e-02,  2.4001e-02,  2.6092e-02,\n",
       "          4.9369e-02,  1.8497e-02,  3.0572e-02,  3.1680e-02,  1.5310e-02,\n",
       "          1.7420e-02,  5.5267e-02,  2.0003e-02,  9.6060e-03, -6.1582e-04,\n",
       "          1.8077e-02,  1.8408e-01,  6.8998e-02,  3.1370e-02,  1.9246e-02,\n",
       "          1.1786e-02, -1.2548e-02,  9.0407e-03,  2.3702e-02,  4.8123e-02,\n",
       "          2.7501e-02,  3.3255e-02,  7.5798e-03, -1.2386e-03,  4.6698e-02,\n",
       "         -6.0752e-03,  6.5236e-03, -4.5752e-03,  3.1878e-02,  2.2800e-02,\n",
       "          4.0039e-02,  1.9241e-02,  1.9338e-02,  3.4379e-02,  3.2265e-02,\n",
       "          2.6210e-02,  1.1994e-02,  1.2377e-02,  2.0400e-02,  8.6980e-02,\n",
       "          2.9149e-03,  2.9756e-02,  2.5734e-02,  3.5196e-02,  5.1832e-02,\n",
       "          3.8598e-02,  1.5860e-02,  9.6417e-03,  6.9731e-03,  1.0494e-02,\n",
       "          7.7392e-03,  1.3177e-02,  4.7104e-02,  2.4319e-02,  3.4188e-02,\n",
       "          5.6501e-02,  3.2135e-02,  1.6710e-02,  3.8981e-02,  3.1749e-02,\n",
       "         -2.5556e-02,  2.8888e-02,  1.9070e-02,  5.1650e-02, -1.5914e-02,\n",
       "         -1.2977e-02,  6.6083e-03,  1.7860e-02,  3.1013e-02,  1.8371e-02,\n",
       "         -2.1300e-02,  2.5543e-02,  1.6410e-02, -6.5174e-03,  1.3495e-02,\n",
       "          8.7851e-03,  4.6246e-02,  1.8821e-03,  2.9014e-02,  1.1800e-02,\n",
       "          5.9435e-04,  3.8069e-02, -1.1412e-03,  2.3119e-02,  1.1591e-02,\n",
       "          4.3060e-02,  3.3098e-02,  2.1665e-02,  1.8575e-02,  3.6334e-02,\n",
       "          4.9192e-03,  1.9173e-02,  5.5739e-03, -4.8481e-02, -3.4651e-03,\n",
       "          4.6214e-02, -9.8203e-03,  1.5743e-02,  3.0009e-02,  1.9906e-02,\n",
       "          4.1677e-02,  8.9290e-03,  3.6726e-02,  1.1614e-02,  3.5722e-02,\n",
       "          5.2057e-02,  1.4911e-02,  1.7501e-02,  2.3691e-02,  2.0107e-02,\n",
       "          1.6700e-02,  3.2877e-02,  9.7055e-02,  7.1827e-04,  3.3868e-02,\n",
       "          2.0839e-02,  3.9532e-02,  1.3293e-02,  3.6185e-02,  2.6945e-03,\n",
       "          5.1187e-02,  5.1772e-02,  1.7860e-02,  1.9585e-02,  3.2763e-02,\n",
       "         -1.5987e-01, -1.0280e-02,  2.8637e-02,  2.1631e-02,  3.6269e-02,\n",
       "          4.1857e-02,  1.4414e-02,  3.6165e-02,  9.4467e-03,  7.0197e-02,\n",
       "         -1.2440e-02,  2.1275e-03,  1.5799e-03, -1.6614e-04,  1.1726e-02,\n",
       "          1.7327e-02,  1.7329e-02,  2.2099e-02, -4.4030e-03,  1.4518e-02,\n",
       "          1.3263e-02,  3.3477e-02,  4.7591e-04,  3.0322e-02,  2.9178e-02,\n",
       "         -1.4136e-02,  1.3277e-02,  3.4933e-02, -1.6847e-03, -2.2079e-03,\n",
       "          1.9391e-02,  3.5811e-02,  3.1967e-02,  3.7433e-03,  4.5169e-02,\n",
       "          2.0756e-02,  7.0152e-03,  2.5443e-02,  3.5833e-03, -1.0657e-01,\n",
       "          4.4172e-02, -9.5086e-04,  1.4159e-02, -3.8349e-03,  3.2159e-02,\n",
       "          1.5454e-02,  1.0590e-02,  1.9344e-02,  7.1228e-03,  1.7016e-02,\n",
       "          2.7252e-02,  1.0541e-02,  2.8562e-02, -7.8883e-03,  4.8528e-02,\n",
       "          9.2735e-03, -4.7732e-04,  1.3732e-02, -1.8557e-03,  2.5011e-02,\n",
       "          9.9024e-04,  2.0201e-02,  1.6506e-02,  5.9075e-02,  4.0285e-02,\n",
       "          6.5056e-03,  2.1686e-02,  1.7892e-02,  2.1786e-02,  3.1710e-03,\n",
       "          1.0477e-02,  1.5669e-03,  4.0309e-02,  2.2216e-02,  3.4789e-02,\n",
       "         -3.0456e-03,  6.2019e-03,  2.2039e-02,  9.4936e-03,  2.4101e-02,\n",
       "          1.6185e-03,  1.7310e-02, -5.9819e-03,  7.8453e-03, -2.8414e-03,\n",
       "          7.8690e-03,  4.5540e-03,  3.1039e-03,  4.9698e-02,  3.7590e-02,\n",
       "         -8.4337e-04,  5.3732e-02,  5.3245e-02,  2.3421e-02,  3.3265e-02,\n",
       "          3.5699e-02,  1.9311e-02, -7.2357e-05,  9.5435e-03,  7.3847e-02,\n",
       "          2.7004e-04,  2.7659e-02,  2.8465e-02,  2.6450e-02,  2.4385e-02,\n",
       "          1.3997e-01,  5.8820e-02,  1.8040e-03,  2.9881e-02,  9.1413e-03,\n",
       "          1.3223e-02,  1.0460e-02,  2.1818e-03,  4.4793e-02,  2.0962e-02,\n",
       "          3.1776e-02,  6.9040e-02,  1.6514e-02,  3.4750e-02,  1.9679e-02,\n",
       "          3.2600e-02,  1.8007e-03, -4.3986e-02,  2.1791e-02,  3.6372e-02,\n",
       "          2.4327e-02,  5.0891e-03,  3.7223e-02]),\n",
       " 'transformer.h.10.attn.c_attn.weight': tensor([[ 0.2200,  0.2637,  0.0422,  ...,  0.1725,  0.3419,  0.0662],\n",
       "         [-0.1269, -0.0215, -0.0951,  ..., -0.0543, -0.2407, -0.0239],\n",
       "         [ 0.0709, -0.0726, -0.0253,  ...,  0.2005, -0.0454,  0.0693],\n",
       "         ...,\n",
       "         [ 0.0642, -0.0317,  0.1332,  ..., -0.1037,  0.2958,  0.0867],\n",
       "         [-0.1892, -0.1039,  0.0752,  ..., -0.0223,  0.0835, -0.0417],\n",
       "         [ 0.1380,  0.1194, -0.1244,  ..., -0.2325, -0.0402, -0.0117]]),\n",
       " 'transformer.h.10.attn.c_attn.bias': tensor([-0.0301,  0.1360, -0.3842,  ..., -0.0599,  0.1059,  0.0276]),\n",
       " 'transformer.h.10.attn.c_proj.weight': tensor([[-0.0077, -0.5188,  0.0783,  ..., -0.0935, -0.1252,  0.1297],\n",
       "         [-0.3012,  0.2455, -0.0883,  ...,  0.0785,  0.2385, -0.1301],\n",
       "         [-0.3693,  0.1506,  0.2052,  ..., -0.0831, -0.2656, -0.1792],\n",
       "         ...,\n",
       "         [ 0.2251,  0.0240, -0.0106,  ..., -0.1443, -0.0599, -0.1167],\n",
       "         [ 0.0778, -0.1356,  0.0710,  ...,  0.1302,  0.1659,  0.0141],\n",
       "         [ 0.0468,  0.1248,  0.0349,  ...,  0.2004,  0.0141, -0.1468]]),\n",
       " 'transformer.h.10.attn.c_proj.bias': tensor([-1.2379e-02,  1.4348e-02, -4.4527e-03, -4.5073e-02, -1.2405e-02,\n",
       "          8.0911e-02,  1.5559e-01,  5.4038e-02,  6.7509e-02,  3.0687e-02,\n",
       "          3.0247e-01, -9.8182e-03,  8.1174e-02, -1.7205e-01,  5.2295e-02,\n",
       "          1.3546e-01, -2.1004e-01, -2.1952e-01,  4.9703e-02,  2.3138e-02,\n",
       "          2.2932e-02,  2.2249e-03, -7.0906e-02, -3.5156e-02,  2.0411e-01,\n",
       "         -1.2486e-01,  1.3384e-01, -1.9214e-01,  1.9044e-02,  5.3139e-02,\n",
       "          4.9103e-02, -1.6615e-01, -7.5499e-02, -5.3073e-02, -2.0856e-02,\n",
       "         -1.9295e-01,  2.2115e-01, -1.9902e-01, -1.3765e-01,  1.6515e-01,\n",
       "          1.0707e-02, -7.1831e-02, -1.4753e-01, -5.0490e-03,  1.0966e-01,\n",
       "          2.3185e-01,  1.3112e-02, -3.1720e-02, -2.3691e-02,  1.8010e-01,\n",
       "          1.8339e-02,  9.8531e-02, -1.4694e-01,  2.2167e-01,  1.2269e-01,\n",
       "          9.8755e-02,  2.4772e-01, -1.0158e-01,  1.1977e-01,  3.5989e-02,\n",
       "         -2.9133e-02,  1.5159e-01, -1.1415e-01,  1.8912e-01, -3.2423e-01,\n",
       "         -6.3471e-03,  1.6377e-01,  1.2220e-01, -8.6118e-02, -1.3037e-02,\n",
       "         -5.2970e-02, -1.0829e-01, -1.8177e-01,  4.8571e-03, -6.8857e-02,\n",
       "          1.1943e-02, -5.5937e-02,  7.0200e-03,  1.0460e-01,  1.6986e-01,\n",
       "          3.8501e-02, -9.4758e-02, -1.2970e-01, -6.8998e-02,  2.8991e-02,\n",
       "         -1.7656e-02, -2.3231e-01, -8.2934e-01,  1.1315e-01, -1.6878e-01,\n",
       "         -3.1707e-02,  1.0165e-01, -3.6213e-02,  6.3447e-02, -8.6974e-02,\n",
       "         -6.0940e-03,  1.4906e-01, -5.0091e-02, -2.1105e-01,  6.6510e-02,\n",
       "          2.8093e-02,  1.1587e-01,  1.9580e-01, -1.6246e-01,  1.3696e-01,\n",
       "          1.2521e-01,  3.3358e-02,  1.4560e-01,  1.2057e-01, -2.6127e-01,\n",
       "         -1.1684e-01, -1.4144e-01,  6.9537e-02, -2.9555e-01,  7.2843e-02,\n",
       "          6.6022e-02, -2.3665e-02,  2.7204e-01, -1.1845e-01,  1.0308e-01,\n",
       "         -7.6212e-02,  7.3581e-02,  1.7829e-01,  3.0658e-01,  7.5543e-02,\n",
       "         -2.3775e-01,  1.6170e-01,  2.6796e-03,  7.2205e-02,  3.4932e-02,\n",
       "          8.4839e-02, -3.6620e-02, -5.3438e-02,  5.1749e-02, -1.1686e-01,\n",
       "          1.7398e-01, -2.4470e-01, -8.3547e-02, -3.4163e-01,  1.8377e-02,\n",
       "         -5.8818e-02,  4.8629e-02, -2.3429e-01, -9.5695e-02, -4.4188e-02,\n",
       "          2.9766e-02,  2.6909e-01, -2.1946e-03,  1.6594e-01,  6.6815e-02,\n",
       "         -1.6380e-02,  6.0249e-02, -3.1730e-01, -1.3451e-01, -1.0723e-01,\n",
       "          1.1293e-01, -1.7714e-01, -5.2138e-02, -2.5410e-01,  1.0667e-01,\n",
       "          3.1836e-01, -9.3654e-02,  1.2745e-01,  1.7573e-02, -2.3658e-01,\n",
       "         -7.7755e-02, -9.6747e-02, -1.2382e-01, -2.3488e-01, -2.1386e-01,\n",
       "         -1.1236e-01,  1.6579e-02, -4.6551e-02,  2.0709e-01, -2.9475e-02,\n",
       "          9.7892e-02, -6.1209e-02,  3.5287e-02,  3.5706e-02,  1.8173e-01,\n",
       "         -1.1351e-01,  1.9125e-01, -3.7715e-02,  3.8817e-02,  1.3485e-01,\n",
       "          9.9754e-02,  7.3885e-02,  5.5447e-02,  4.0234e-03,  1.6806e-01,\n",
       "          3.4928e-02,  7.2623e-02, -8.7083e-02, -8.3372e-02, -1.8134e-01,\n",
       "         -5.7460e-02,  1.2240e-01, -1.8635e-01, -2.3672e-01, -1.9521e-01,\n",
       "         -6.1426e-02,  2.4562e-01, -6.4236e-02, -5.1840e-02,  9.9109e-02,\n",
       "         -1.0095e-01, -6.6365e-02,  3.0682e-02, -1.1143e-01,  2.7270e-01,\n",
       "          1.6731e-01,  4.0085e-02, -8.9662e-02, -2.2507e-01, -1.5903e-01,\n",
       "         -1.1118e-01, -3.7577e-02, -4.5636e-03, -1.0169e-01,  2.2616e-02,\n",
       "         -6.4782e-02, -5.8231e-02,  1.8412e-01,  1.5927e-01,  7.2231e-02,\n",
       "         -8.2410e-03,  6.3502e-02, -6.5254e-03, -1.5480e-01,  1.2239e-01,\n",
       "          1.3907e-01, -1.0959e-01,  2.1398e-01,  2.8403e-02,  1.3976e-01,\n",
       "         -1.1511e-02,  4.8689e-02, -4.7400e-02, -3.5375e-02,  8.7291e-02,\n",
       "         -1.8668e-01,  8.7162e-03, -1.9849e-01,  3.6719e-02, -1.1307e-01,\n",
       "          6.4984e-03, -1.0104e-01, -1.4648e-01,  1.6499e-01, -3.4259e-02,\n",
       "         -1.7418e-01, -1.7965e-01, -4.7325e-03, -1.2874e-02, -8.9389e-02,\n",
       "          1.1376e-01,  3.0038e-01,  1.0216e-01, -7.3336e-02,  6.5745e-02,\n",
       "          1.2904e-01, -1.9826e-02,  4.9556e-02,  1.8150e-01, -2.7042e-01,\n",
       "         -1.3421e-01,  6.5607e-01, -3.2256e-02, -3.9979e-03,  9.1274e-02,\n",
       "          2.6122e-01, -1.3429e-01,  1.9112e-01,  1.4294e-01,  1.2402e-01,\n",
       "         -3.2374e-02, -7.0890e-02, -7.6397e-02,  1.8777e-01,  8.0358e-03,\n",
       "          5.5245e-02,  1.3889e-01, -7.8599e-02,  1.7570e-01, -9.1254e-02,\n",
       "          1.2744e-01, -9.5908e-02, -1.7724e-01, -8.9019e-03, -2.7369e-02,\n",
       "          9.9424e-02,  1.1946e-01, -2.7375e-01, -4.3034e-02,  2.9473e-01,\n",
       "         -2.6759e-01,  8.6330e-02, -1.5584e-01,  5.6866e-02, -7.5608e-02,\n",
       "         -2.4506e-02,  8.9672e-02,  3.6124e-02,  4.0310e-03,  2.1819e-01,\n",
       "          4.2471e-02,  1.1455e-01, -1.6826e-01, -5.9011e-02, -1.1176e-01,\n",
       "          4.5981e-02, -4.7308e-03,  4.8670e-01, -3.9340e-02, -2.2350e-01,\n",
       "         -1.1150e-02, -2.9153e-01,  7.9229e-02, -7.2109e-02,  2.1014e-01,\n",
       "         -8.0384e-02,  9.5033e-02,  3.4228e-02, -1.3234e-01,  2.3086e-01,\n",
       "          5.0849e-02, -2.0079e-01,  1.9656e-01,  2.7933e-02, -1.2391e-01,\n",
       "         -7.4246e-02, -1.7753e-02,  1.6751e-01, -1.5976e-02,  1.3733e-01,\n",
       "         -1.5928e-01,  3.8927e-01, -4.2314e-03,  1.7543e-02, -4.4693e-02,\n",
       "          8.8815e-04, -1.1453e-01,  2.5587e-01, -8.0434e-02,  3.5012e-01,\n",
       "          1.7482e-01,  2.1464e-02, -2.6677e-01, -2.0562e-01,  1.5906e-02,\n",
       "         -1.2838e-01,  1.7999e-01, -8.8452e-02, -2.4351e-02,  1.3537e-01,\n",
       "          8.5065e-03,  1.1358e-01, -1.2907e-01, -1.0531e-01,  5.6472e-02,\n",
       "          2.4469e-02, -6.0273e-02,  2.8088e-02, -1.2912e-01,  1.4083e-02,\n",
       "         -3.4086e-01, -1.8941e-02, -5.0269e-02,  1.2974e-01,  1.2473e-02,\n",
       "          2.0904e-01, -7.4330e-02,  2.1350e-01, -2.9879e+00, -5.1382e-02,\n",
       "          1.4264e-01, -7.9323e-02, -6.7639e-02,  2.5396e-01,  1.8843e-01,\n",
       "          9.9903e-03,  1.8879e-01, -1.1036e-02, -6.2546e-02,  8.2697e-02,\n",
       "          1.0746e-01, -2.6098e-02, -3.2315e-01,  4.2068e-02,  5.8130e-02,\n",
       "          2.9191e-01,  3.3065e-02,  1.6791e-01,  2.9781e-03, -2.0477e-01,\n",
       "          9.5641e-02, -1.3596e-01,  1.7567e-01, -3.0255e-02,  4.8722e-02,\n",
       "         -3.3768e-02, -9.5191e-02, -1.0229e-01, -8.7678e-02,  1.7230e-02,\n",
       "         -5.7168e-02,  1.4702e-01, -1.5486e-01,  1.0167e-01, -4.2474e-02,\n",
       "         -1.1334e-01, -1.4780e-01, -9.4148e-02, -2.7555e-01, -2.1301e-01,\n",
       "          3.0041e-02,  1.4375e-01,  5.2278e-02, -2.4965e-01,  1.3375e-01,\n",
       "         -2.1917e-01, -9.1171e-03,  2.6620e-01,  1.1913e-01,  2.1140e-02,\n",
       "         -8.6450e-02,  1.2354e-02,  2.9133e-02, -5.8175e-02,  1.7748e-02,\n",
       "          1.4167e-01,  1.7459e-01,  1.3773e-01, -1.8140e-01,  1.5937e-02,\n",
       "          2.0348e-01,  6.6218e-02,  1.4351e-01,  4.2973e-02,  7.4120e-02,\n",
       "         -2.5265e-02, -1.3975e-01,  2.0339e-01, -1.1828e-01,  1.5121e-01,\n",
       "          1.1890e-01, -2.7605e-01,  1.6106e+00,  3.2741e-02,  1.5666e-01,\n",
       "         -1.6812e-01,  8.7540e-02,  1.4451e-01,  2.2068e-01,  7.4422e-02,\n",
       "          1.4012e-02, -1.4879e-01,  2.2443e-02,  1.6478e-01,  4.7355e-02,\n",
       "          2.0962e-01,  3.0320e-01, -2.9832e-02, -1.3447e-01, -1.9306e-01,\n",
       "         -7.2619e-02, -1.4449e-01, -1.2948e-01, -3.4933e-03,  2.8817e-01,\n",
       "          8.8448e-02,  4.4275e-02,  1.1327e-02,  1.4317e-01, -9.3672e-02,\n",
       "         -4.8162e-02, -9.6565e-02, -1.9665e-01, -5.8748e-02, -1.8242e-01,\n",
       "         -3.6885e-01,  3.8491e+00, -9.8925e-02, -3.5064e-02,  4.9440e-02,\n",
       "          8.3612e-02,  2.5126e-01, -1.0279e-01,  9.6826e-02, -2.9162e-01,\n",
       "          7.8400e-02, -9.0043e-02, -6.3061e-02, -1.3142e-01, -7.6966e-04,\n",
       "         -6.6267e-02,  3.6277e-01, -4.1938e-02,  1.0638e-02, -1.1431e-01,\n",
       "          1.3131e-01, -7.7928e-02,  7.3319e-02, -4.6778e-02, -4.3071e-03,\n",
       "         -1.1415e-01,  4.7491e-02,  4.3709e-02, -1.5840e-01, -8.2766e-02,\n",
       "          6.3536e-02, -4.7262e-02, -8.8036e-02, -6.6898e-02, -4.9939e-02,\n",
       "         -2.1676e-01, -4.5011e-02, -7.7135e-02, -1.2026e-03, -6.2871e-02,\n",
       "          2.4192e-02, -5.8020e-02,  6.1375e-02,  1.0589e-01,  1.9872e-02,\n",
       "         -1.0491e-01, -1.3099e-01, -2.6912e-01,  4.5072e-02, -3.6764e-02,\n",
       "          7.5673e-02,  1.2889e-01, -9.2520e-02,  1.3375e-02, -1.2862e-01,\n",
       "         -1.1480e-01, -1.2475e-01, -1.0492e-01, -4.6326e-02, -3.0426e-01,\n",
       "          3.5528e-02, -1.1242e-01, -7.5240e-02,  8.1291e-03, -2.5517e-01,\n",
       "          3.0017e-02,  2.3827e-01, -1.7993e-01, -1.0315e-01, -2.3549e-02,\n",
       "          1.4136e-02,  2.0478e-01, -1.7341e-01,  1.5418e-01,  4.8663e-02,\n",
       "         -7.9738e-02, -7.5500e-03,  2.5583e-01, -2.0869e-01, -1.5328e-01,\n",
       "         -8.1470e-02,  2.5862e-01,  3.6970e-01, -1.7248e-01,  1.4724e-01,\n",
       "         -1.4826e-02,  8.1561e-02, -2.9888e-02, -1.1907e-01, -1.9521e-02,\n",
       "          1.3730e-01, -8.7003e-02, -4.3825e-02, -2.9017e-01, -1.5796e-01,\n",
       "          4.7715e-03,  2.9769e-02,  6.3667e-04,  8.6675e-02,  1.3762e-01,\n",
       "          4.7474e-02, -8.9161e-02,  1.4309e-01, -1.1020e-01, -7.4191e-02,\n",
       "          8.4554e-02, -7.8401e-02, -1.4910e-02,  2.4917e-01,  9.8512e-02,\n",
       "         -1.3347e-02, -1.3149e-01,  1.4435e-01,  4.7064e-02, -1.1919e-01,\n",
       "          2.2155e-01, -1.4150e-01,  1.5482e-01,  2.8138e-02,  2.7679e-01,\n",
       "         -5.6556e-02,  2.9770e-01, -1.5242e-01, -1.4212e-01,  4.8245e-02,\n",
       "          5.1145e-02, -2.4877e-01,  1.4711e-01, -3.6850e-02,  3.4200e-02,\n",
       "          3.4856e-02,  9.6491e-02, -2.9448e-03,  1.0233e-03, -1.1796e-01,\n",
       "         -3.0176e-01, -1.0404e-01, -8.7887e-02, -7.9003e-02, -1.2622e-01,\n",
       "          1.4097e-01, -1.7600e-02,  2.4899e-01,  1.0704e-01, -8.2967e-02,\n",
       "         -6.7200e-02,  1.0821e-01, -8.9861e-02,  1.2028e-01, -6.8952e-02,\n",
       "          1.1850e-01, -1.8197e-01, -1.1319e-01, -2.6780e-02,  7.9156e-02,\n",
       "         -4.5832e-02, -5.2018e-02, -7.9909e-02, -2.2927e-03, -1.3758e-01,\n",
       "         -2.5597e-02, -1.3735e-01, -1.2317e-01,  2.6385e-02,  1.2720e-01,\n",
       "         -2.2807e-02,  9.6982e-02, -7.3102e-03, -5.6895e-03, -4.9237e-02,\n",
       "          3.2314e-02, -1.9534e-01, -4.7456e-02, -1.7260e-01,  1.0746e-01,\n",
       "         -5.2415e-02,  1.0207e-01, -2.6180e-02, -2.9488e-02,  2.5588e-01,\n",
       "         -1.1691e-01, -1.7254e-02, -5.3564e-02,  1.0267e-01, -8.4233e-02,\n",
       "          2.6397e-02,  1.1934e-01, -9.6089e-02,  2.0718e-02, -1.3928e-01,\n",
       "         -2.2855e-01, -2.5989e-01, -2.5050e-01,  1.2405e-01, -1.3548e-01,\n",
       "         -6.2826e-03, -2.8458e-01, -1.2420e-01, -2.9676e-02,  4.5543e-02,\n",
       "          5.3763e-03,  1.6633e-01, -1.4238e-01,  2.0877e-02, -1.2927e-01,\n",
       "          1.5561e-02,  1.7643e-01, -2.1712e-01,  9.7189e-02,  9.8672e-02,\n",
       "         -1.0300e-01,  1.5900e-01,  1.8163e-01,  2.4923e-01, -1.9131e-02,\n",
       "          7.6086e-02,  9.9275e-02,  1.6313e-01,  1.0650e-01,  8.4541e-02,\n",
       "          7.1349e-02, -1.9356e-03, -5.1919e-02, -1.7568e-01, -3.6663e-02,\n",
       "         -5.9383e-02,  1.1216e-01,  1.3886e-01, -1.3169e-01,  1.7795e-02,\n",
       "         -7.5414e-02,  2.3237e-01, -8.1315e-02,  1.1739e-02, -1.7310e-01,\n",
       "         -1.1895e-01,  3.2130e-02, -7.2317e-02,  9.5463e-02,  9.6840e-03,\n",
       "          2.2047e-03,  2.4560e-02,  1.3156e-01,  1.4928e-01, -6.8467e-02,\n",
       "          7.2495e-02,  2.0334e-01,  1.9862e-01,  8.6380e-02, -3.2466e-02,\n",
       "         -1.3583e-01,  4.2324e-02, -3.4869e-01,  2.3828e-01, -2.2848e-01,\n",
       "          1.3376e-01,  2.7762e-01, -3.1245e-02,  5.4983e-02,  7.5708e-02,\n",
       "          2.6616e-01, -6.6431e-02,  4.6051e-02,  2.8558e-01, -9.8300e-02,\n",
       "         -5.1377e-02, -2.8476e-02, -5.9318e-02,  9.7747e-03,  6.6608e-02,\n",
       "         -1.5685e-01, -1.5462e-01, -2.4600e-01,  8.7477e-02, -4.8798e-02,\n",
       "          1.0550e-01,  5.3802e-02,  3.2799e-02, -1.0552e-01, -4.6069e-04,\n",
       "         -1.8872e-01,  1.1710e-01,  5.2023e-02, -5.3095e-02, -5.5921e-03,\n",
       "          3.3713e-02, -5.2039e-02, -1.5190e-01]),\n",
       " 'transformer.h.10.ln_2.weight': tensor([0.2976, 0.2666, 0.2978, 0.2740, 0.3013, 0.2871, 0.5526, 0.2613, 0.2840,\n",
       "         0.2607, 0.2947, 0.2736, 0.2764, 0.2916, 0.3057, 0.2851, 0.3029, 0.2802,\n",
       "         0.2998, 0.3194, 0.2549, 0.2699, 0.2869, 0.2764, 0.2822, 0.2803, 0.2859,\n",
       "         0.2704, 0.2784, 0.2747, 0.2725, 0.3135, 0.2933, 0.2725, 0.2881, 0.3330,\n",
       "         0.2535, 0.2802, 0.2626, 0.2842, 0.2744, 0.2588, 0.2627, 0.2859, 0.2897,\n",
       "         0.2822, 0.2789, 0.2646, 0.3172, 0.2881, 0.2787, 0.2839, 0.2794, 0.2920,\n",
       "         0.2900, 0.3467, 0.2915, 0.3166, 0.2666, 0.3272, 0.3092, 0.2781, 0.2900,\n",
       "         0.3012, 0.1870, 0.2705, 0.2763, 0.3206, 0.3549, 0.2705, 0.2959, 0.2180,\n",
       "         0.2725, 0.2929, 0.2627, 0.2920, 0.2958, 0.3896, 0.3016, 0.2939, 0.2998,\n",
       "         0.2686, 0.2780, 0.3057, 0.3236, 0.3111, 0.3226, 0.0201, 0.2874, 0.2666,\n",
       "         0.2783, 0.2679, 0.2900, 0.2904, 0.2789, 0.2607, 0.2795, 0.2881, 0.2705,\n",
       "         0.2946, 0.2607, 0.2395, 0.3780, 0.3029, 0.2822, 0.2788, 0.3033, 0.3589,\n",
       "         0.2764, 0.2685, 0.2932, 0.2761, 0.2814, 0.2951, 0.2826, 0.2872, 0.3173,\n",
       "         0.2856, 0.2469, 0.3256, 0.2900, 0.2794, 0.2705, 0.2959, 0.3114, 0.2873,\n",
       "         0.2725, 0.2822, 0.3213, 0.2803, 0.2837, 0.2725, 0.2956, 0.2833, 0.2898,\n",
       "         0.2704, 0.2822, 0.3363, 1.0951, 0.2872, 0.2915, 0.2899, 0.3654, 0.2666,\n",
       "         0.2900, 0.3300, 0.2971, 0.2979, 0.2725, 0.2896, 0.2921, 0.2955, 0.3170,\n",
       "         0.3057, 0.2888, 0.2728, 0.2887, 0.2931, 0.2737, 0.3213, 0.3665, 0.2842,\n",
       "         0.3056, 0.3076, 0.2900, 0.2894, 0.2917, 0.4131, 0.2704, 0.3154, 0.2783,\n",
       "         0.2791, 0.2780, 0.3042, 0.2998, 0.2739, 0.3017, 0.2607, 0.3018, 0.2835,\n",
       "         0.2820, 0.2705, 0.2744, 0.2998, 0.2588, 0.2607, 0.2686, 0.2822, 0.2801,\n",
       "         0.2939, 0.2725, 0.3172, 0.2822, 0.2959, 0.2686, 0.3595, 0.2616, 0.2958,\n",
       "         0.2777, 0.3174, 0.3146, 0.2980, 0.2783, 0.2823, 0.2764, 0.2897, 0.2725,\n",
       "         0.2407, 0.3135, 0.2763, 0.2816, 0.3184, 0.2839, 0.3071, 0.2881, 0.2760,\n",
       "         0.3230, 0.2842, 0.1939, 0.2666, 0.2752, 0.2725, 0.2586, 0.3012, 0.3156,\n",
       "         0.2803, 0.2705, 0.2705, 0.2829, 0.2608, 0.2645, 0.2968, 0.4358, 0.2705,\n",
       "         0.2750, 0.3017, 0.2955, 0.2705, 0.2968, 0.3001, 0.3099, 0.3223, 0.2822,\n",
       "         0.2664, 0.2646, 0.2881, 0.2762, 0.3076, 0.2840, 0.2921, 0.2861, 0.2764,\n",
       "         0.2744, 0.2861, 0.2761, 0.3478, 0.3037, 0.2957, 0.2861, 0.2859, 0.2815,\n",
       "         0.2979, 0.2784, 0.2958, 0.2824, 0.2595, 0.0720, 0.3310, 0.2822, 0.2901,\n",
       "         0.3643, 0.3545, 0.2743, 0.2810, 0.3217, 0.2705, 0.2782, 0.2666, 0.2621,\n",
       "         0.2715, 0.2568, 0.2526, 0.2979, 0.3584, 0.3213, 0.2979, 0.2950, 0.2666,\n",
       "         0.5094, 0.3096, 0.2885, 0.2807, 0.2761, 0.2607, 0.3096, 0.2600, 0.2646,\n",
       "         0.2920, 0.2725, 0.2979, 0.2900, 0.2920, 0.2978, 0.2646, 0.2588, 0.2782,\n",
       "         0.2800, 0.2641, 0.3124, 0.2627, 0.2646, 0.3487, 0.2858, 0.2798, 0.2509,\n",
       "         0.2780, 0.3033, 0.2900, 0.2724, 0.3086, 0.3528, 0.2744, 0.2687, 0.2897,\n",
       "         0.2719, 0.2822, 0.5527, 0.2822, 0.2822, 0.2803, 0.2920, 0.2781, 0.2862,\n",
       "         0.2842, 0.2666, 0.2972, 0.3071, 0.2764, 0.2861, 0.3059, 0.2752, 0.2685,\n",
       "         0.3044, 0.3034, 0.3036, 0.3057, 0.2822, 0.2863, 0.2959, 0.2689, 0.2803,\n",
       "         0.2529, 0.2737, 0.2979, 0.3076, 0.2822, 0.2975, 0.2810, 0.2822, 0.2822,\n",
       "         0.2930, 0.2706, 0.4616, 0.2686, 0.2659, 0.3373, 0.2996, 0.2702, 0.2659,\n",
       "         0.3018, 0.2951, 0.2725, 0.2783, 0.0522, 0.2702, 0.3266, 0.2979, 0.3172,\n",
       "         0.2367, 0.2881, 0.2851, 0.2697, 0.2802, 0.3057, 0.3096, 0.3252, 0.3017,\n",
       "         0.2763, 0.2801, 0.3233, 0.2890, 0.2574, 0.3055, 0.6621, 0.3052, 0.2707,\n",
       "         0.2900, 0.2734, 0.2735, 0.2657, 0.2707, 0.2920, 0.3076, 0.2959, 0.2631,\n",
       "         0.3017, 0.3112, 0.2585, 0.3474, 0.2744, 0.2567, 0.2625, 0.2796, 0.2646,\n",
       "         0.2978, 0.2822, 0.2654, 0.2978, 0.2847, 0.2861, 0.2133, 0.3018, 0.2741,\n",
       "         0.2998, 0.2704, 0.2604, 0.2847, 0.2862, 0.2805, 0.2554, 0.2232, 0.2705,\n",
       "         0.2806, 0.2833, 0.2666, 0.3174, 0.2666, 0.2900, 0.2901, 0.3153, 0.3271,\n",
       "         0.3017, 0.3501, 0.2744, 0.3037, 0.2783, 0.2694, 0.0606, 0.2783, 0.2876,\n",
       "         0.2889, 0.2801, 0.2744, 0.3054, 0.3021, 0.3090, 0.2940, 0.2783, 0.2687,\n",
       "         0.1821, 0.2900, 0.2822, 0.2867, 0.2744, 0.1579, 0.2822, 0.2959, 0.2722,\n",
       "         0.2702, 0.2863, 0.2749, 0.2895, 0.2939, 0.2764, 0.2575, 0.2992, 0.2686,\n",
       "         0.2705, 0.2685, 0.3664, 0.0253, 0.0485, 0.2920, 0.2743, 0.2920, 0.2666,\n",
       "         0.2803, 0.2817, 0.3225, 0.2725, 0.2842, 0.3001, 0.2606, 0.2725, 0.2751,\n",
       "         0.2722, 0.1523, 0.2143, 0.2899, 0.2790, 0.2978, 0.2764, 0.2939, 0.3815,\n",
       "         0.3144, 0.2643, 0.2773, 0.3252, 0.3054, 0.2705, 0.2705, 0.2969, 0.2782,\n",
       "         0.2811, 0.2828, 0.3013, 0.2744, 0.2783, 0.2795, 0.2665, 0.2525, 0.2822,\n",
       "         0.2998, 0.2939, 0.2803, 0.2842, 0.4467, 0.3174, 0.3037, 0.2666, 0.2981,\n",
       "         0.2963, 0.2602, 0.2685, 0.2859, 0.2900, 0.2744, 0.2861, 0.3075, 0.2900,\n",
       "         0.3075, 0.2861, 0.2830, 0.3485, 0.2764, 0.2959, 0.3012, 0.2761, 0.2744,\n",
       "         0.3428, 0.2783, 0.3252, 0.2939, 0.2919, 0.3531, 0.2986, 0.2744, 0.2910,\n",
       "         0.2782, 0.2803, 0.2978, 0.2854, 0.2900, 0.2860, 0.2682, 0.2803, 0.3389,\n",
       "         0.3076, 0.3000, 0.3048, 0.3253, 0.2978, 0.3037, 0.2904, 0.2842, 0.2998,\n",
       "         0.2653, 0.2777, 0.3346, 0.2948, 0.2725, 0.2593, 0.3174, 0.2900, 0.2705,\n",
       "         0.2947, 0.2705, 0.2958, 0.2920, 0.2842, 0.2900, 0.2832, 0.2646, 0.2777,\n",
       "         0.2764, 0.2764, 0.2872, 0.2800, 0.2659, 0.2567, 0.3003, 0.2918, 0.3047,\n",
       "         0.2959, 0.2928, 0.2789, 0.3037, 0.2911, 0.4346, 0.2738, 0.2914, 0.2822,\n",
       "         0.2879, 0.2961, 0.2955, 0.3057, 0.3271, 0.2803, 0.2918, 0.2892, 0.2971,\n",
       "         0.2803, 0.2836, 0.2807, 0.2959, 0.2744, 0.2805, 0.3561, 0.2825, 0.2822,\n",
       "         0.2788, 0.2781, 0.2734, 0.2715, 0.2822, 0.3328, 0.2842, 0.2760, 0.2779,\n",
       "         0.2881, 0.5528, 0.2979, 0.2447, 0.3029, 0.3114, 0.2920, 0.2842, 0.3193,\n",
       "         0.2916, 0.3604, 0.2567, 0.3252, 0.2745, 0.2900, 0.2704, 0.2938, 0.2756,\n",
       "         0.2881, 0.2666, 0.3292, 0.2606, 0.2939, 0.2722, 0.2764, 0.2725, 0.3154,\n",
       "         0.2680, 0.2979, 0.2881, 0.3272, 0.3076, 0.2762, 0.2916, 0.2725, 0.2553,\n",
       "         0.2725, 0.2802, 0.2818, 0.3076, 0.3946, 0.3193, 0.2741, 0.2982, 0.2897,\n",
       "         0.2699, 0.2761, 0.2977, 0.2671, 0.2959, 0.2803, 0.2686, 0.2636, 0.2861,\n",
       "         0.3090, 0.2861, 0.2803, 0.2803, 0.2607, 0.2920, 0.3017, 0.2744, 0.3099,\n",
       "         0.2685, 0.4283, 0.2766, 0.2939, 0.3325, 0.3111, 0.2700, 0.3934, 0.3037,\n",
       "         0.2571, 0.2720, 0.2800, 0.2669, 0.3043, 0.2543, 0.2744, 0.3115, 0.2728,\n",
       "         0.2686, 0.3563, 0.2704, 0.2750, 0.3076, 0.3057, 0.3115, 0.2978, 0.2994,\n",
       "         0.2975, 0.2900, 0.2979, 0.2825, 0.2920, 0.2861, 0.2979, 0.2718, 0.2673,\n",
       "         0.2981, 0.3635, 0.3018, 0.2875, 0.2801, 0.2958, 0.2864, 0.2470, 0.3422,\n",
       "         0.2744, 0.3037, 0.2861, 0.2752, 0.2782, 0.2822, 0.2684, 0.3010, 0.3135,\n",
       "         0.1586, 0.2822, 0.2784, 0.2958, 0.2578, 0.2937, 0.3352, 0.2654, 0.2607,\n",
       "         0.2770, 0.2644, 0.2911]),\n",
       " 'transformer.h.10.ln_2.bias': tensor([-1.0358e-02,  1.3820e-02,  2.8260e-02,  4.6557e-02,  5.9956e-03,\n",
       "          1.1307e-02,  6.8819e-02,  3.6446e-02,  4.8702e-03,  4.9763e-03,\n",
       "          2.8531e-02,  4.7327e-02,  1.5152e-02,  2.8607e-02,  2.5593e-02,\n",
       "          5.2164e-02,  4.8066e-02,  5.3223e-02,  3.4451e-02, -2.9055e-02,\n",
       "          1.6824e-02, -6.3294e-03,  3.0100e-03,  4.8100e-02,  2.2632e-02,\n",
       "          2.3483e-02,  5.6872e-03,  4.2506e-02,  1.2199e-02, -2.9102e-02,\n",
       "          4.8205e-02, -3.0327e-02,  3.2885e-02,  5.2018e-02,  1.3616e-02,\n",
       "          1.7174e-02, -6.2414e-03,  1.4992e-02,  1.5188e-02,  8.3957e-03,\n",
       "          3.4247e-02,  2.9624e-02,  1.7826e-02,  1.4083e-02,  1.6533e-02,\n",
       "          2.2324e-02,  3.2677e-02,  2.0053e-02,  9.4957e-03, -1.7382e-02,\n",
       "          6.3748e-02,  4.1355e-02,  3.2904e-02,  3.2447e-02,  4.0435e-02,\n",
       "         -2.8565e-03,  2.0369e-02, -1.4023e-02,  2.0943e-02,  6.2948e-03,\n",
       "          2.9956e-02,  2.6207e-02,  3.2395e-02,  1.6449e-02, -1.4525e-02,\n",
       "          2.8430e-02,  1.6217e-02, -4.6950e-03,  5.2596e-02,  3.7110e-02,\n",
       "          1.3538e-02,  4.7081e-02,  2.6471e-02,  1.7197e-02,  3.4794e-02,\n",
       "          1.3930e-02, -1.8007e-02,  2.2802e-03,  6.4147e-02,  1.4225e-02,\n",
       "          8.2972e-04,  1.7301e-02,  1.5907e-02,  3.9303e-02,  4.9839e-02,\n",
       "          3.9953e-02,  4.5833e-02,  1.3956e-01,  1.6589e-02,  1.9164e-02,\n",
       "          2.9428e-02,  1.8867e-02,  3.5480e-02,  3.4520e-02,  2.5352e-02,\n",
       "         -1.6986e-03,  3.1963e-03,  1.0863e-02, -1.9798e-02,  4.9423e-02,\n",
       "          1.1976e-02, -2.8248e-02, -3.1719e-02,  2.6163e-02,  1.4126e-02,\n",
       "          4.0976e-03, -8.0332e-04,  6.1240e-02,  2.2650e-02,  2.2354e-02,\n",
       "          2.0694e-02,  4.3690e-02,  3.0244e-02,  3.6898e-02,  1.8719e-02,\n",
       "          1.1135e-02,  3.0766e-02,  5.8322e-03,  5.2236e-02,  3.1649e-02,\n",
       "          3.5989e-02,  7.6593e-03, -4.7919e-04,  3.2370e-02,  3.6766e-02,\n",
       "          2.4986e-02,  6.0303e-04,  4.1531e-02, -2.0416e-02,  3.6249e-02,\n",
       "          3.8137e-02,  5.3390e-02,  2.8590e-02,  4.0459e-02,  5.7189e-02,\n",
       "          3.0323e-02,  2.6251e-02,  4.2108e-02,  3.3788e-01,  2.4742e-02,\n",
       "         -2.1341e-02,  2.5394e-02,  2.5185e-02,  3.4734e-03,  1.8485e-02,\n",
       "          7.6756e-03,  1.0611e-02,  1.4992e-02,  7.9128e-03,  1.0905e-02,\n",
       "         -3.9157e-03, -2.0122e-02,  1.0011e-02,  3.0892e-02,  2.4538e-03,\n",
       "          1.5397e-02,  5.3747e-02, -1.5423e-02,  3.6599e-02, -7.1308e-03,\n",
       "          6.1582e-03,  3.8073e-02, -6.4656e-03,  3.2223e-02, -3.0139e-03,\n",
       "          3.1230e-02, -1.3427e-02,  2.2051e-02,  3.4040e-03,  2.8121e-02,\n",
       "          2.0565e-02,  4.5798e-02,  1.1976e-02,  1.4449e-02,  3.0251e-02,\n",
       "          2.6776e-02,  8.5797e-02,  2.5977e-04,  4.7272e-02, -1.0841e-03,\n",
       "          1.8195e-02,  1.8218e-02,  2.8540e-02,  6.7993e-03,  3.5639e-02,\n",
       "          2.9599e-02,  2.4892e-02, -2.8580e-03,  2.1860e-02,  1.8337e-02,\n",
       "          8.1896e-03,  7.1606e-03,  1.7517e-02,  1.8818e-02,  1.2455e-02,\n",
       "          5.0942e-02,  1.0982e-02,  2.1877e-02,  6.7266e-03,  4.9079e-03,\n",
       "          2.9072e-02,  2.0166e-02,  1.8988e-02,  6.0607e-02,  3.5498e-02,\n",
       "          3.9689e-02,  1.1732e-02,  3.2019e-02, -7.8117e-03,  1.3688e-02,\n",
       "          2.1697e-02,  5.7341e-02,  4.0743e-02,  6.6843e-02,  3.4915e-02,\n",
       "          1.8039e-02,  8.2446e-03,  1.6047e-02,  3.0304e-02,  4.3722e-02,\n",
       "          1.4338e-02,  1.5648e-02,  3.0412e-02,  8.0503e-04,  4.4321e-02,\n",
       "          3.2069e-02,  2.9099e-03,  3.4809e-02,  3.7059e-02,  3.0682e-02,\n",
       "          4.4311e-02,  3.7483e-02,  2.7851e-02,  2.5533e-02,  2.6303e-02,\n",
       "          2.0085e-02,  4.1493e-02,  8.9645e-03,  3.0944e-03,  2.6097e-02,\n",
       "          6.6764e-02,  2.7084e-03,  2.6569e-02,  3.2081e-02,  2.9702e-03,\n",
       "          1.3219e-02,  2.0836e-02,  1.3685e-02,  3.5987e-03,  1.0517e-02,\n",
       "          1.4312e-02,  1.2074e-02, -1.0478e-02,  2.5274e-02,  2.6911e-02,\n",
       "          1.0097e-01,  9.9682e-03,  1.8130e-02,  4.0114e-02,  4.3335e-02,\n",
       "          3.2085e-03,  4.3071e-02,  3.3993e-02,  3.3701e-02,  2.5201e-03,\n",
       "         -1.5116e-02, -7.2455e-02,  4.2337e-02,  4.0797e-02,  2.2369e-02,\n",
       "          2.2718e-02,  1.6584e-02, -1.3213e-02,  1.1772e-02,  1.1397e-02,\n",
       "          2.9617e-02,  2.3913e-02,  1.8444e-02,  3.3094e-02,  3.8922e-02,\n",
       "          4.6575e-02,  1.2183e-02,  2.6243e-02,  6.8510e-02,  2.2780e-03,\n",
       "          1.0124e-02,  2.2449e-02,  8.6296e-03, -1.6431e-01,  4.9237e-02,\n",
       "          4.8695e-02, -3.1594e-03,  3.1461e-02,  2.8214e-02,  1.3456e-02,\n",
       "          1.9882e-02,  3.4631e-02,  2.4248e-02, -3.5280e-03,  2.1640e-02,\n",
       "          1.2597e-02,  7.1220e-03,  1.1988e-02,  2.5425e-02,  1.4709e-03,\n",
       "          5.3826e-03,  3.6498e-02,  2.5552e-02,  3.3139e-02,  2.6447e-02,\n",
       "         -1.1497e-02,  5.5716e-02,  1.3308e-02, -6.7223e-03,  2.4045e-02,\n",
       "          2.2624e-02,  3.7223e-02,  2.6761e-02,  5.4413e-02,  1.4670e-02,\n",
       "          2.1103e-02,  2.0297e-02,  2.5275e-02, -2.4169e-03,  1.0851e-02,\n",
       "          1.0792e-02, -2.5108e-01,  1.5956e-02,  3.9030e-02, -5.4340e-03,\n",
       "          1.4072e-02, -1.2481e-02,  1.9383e-02,  2.3584e-02,  5.8051e-02,\n",
       "          3.7730e-03,  4.6452e-02,  1.5874e-02,  3.9195e-02,  2.8941e-02,\n",
       "         -8.1308e-03,  2.4481e-02,  2.6067e-02,  9.3105e-03,  3.3713e-02,\n",
       "          3.7100e-02, -1.2273e-02, -1.6410e-02,  2.4022e-02,  4.7408e-02,\n",
       "          3.4378e-02,  4.3000e-02,  2.5137e-02,  4.4269e-03,  4.9077e-02,\n",
       "          3.1481e-02,  1.0652e-02,  2.6449e-02, -1.4687e-02,  1.4857e-02,\n",
       "         -3.2030e-06,  3.4278e-02,  4.2626e-02,  4.3518e-02,  5.9497e-02,\n",
       "          3.0237e-02,  4.7823e-02,  2.2643e-02,  2.5692e-02,  7.3306e-02,\n",
       "          3.6672e-02,  1.4671e-02,  2.3230e-02,  6.9136e-01,  6.4758e-02,\n",
       "          5.6275e-02, -8.1179e-03,  1.2797e-02, -5.9154e-02,  2.2879e-02,\n",
       "          4.0809e-02,  1.1079e-02,  2.3431e-02,  1.9926e-03,  2.5910e-02,\n",
       "          3.1874e-02,  5.4008e-03,  1.6043e-02,  1.9226e-02,  3.7281e-02,\n",
       "          5.1407e-02,  1.7173e-02,  1.5955e-02, -5.9317e-02,  1.2196e-02,\n",
       "          1.0802e-02,  3.0468e-03,  5.8788e-03,  2.2304e-02,  3.2142e-02,\n",
       "          1.3249e-02,  2.8839e-02,  3.7375e-02,  3.6929e-02,  1.7584e-02,\n",
       "          1.9938e-02,  1.0190e-02,  3.5776e-02,  1.7384e-02,  3.5547e-02,\n",
       "          2.4908e-03,  3.4021e-02, -5.4762e-03, -8.3075e-03,  1.9333e-02,\n",
       "          3.5979e-02,  1.6277e-02,  2.9949e-02,  3.6957e-02,  3.3667e-02,\n",
       "          3.0161e-02,  1.7595e-02,  4.1365e-02,  1.5934e-02,  2.7179e-02,\n",
       "          5.5548e-02,  7.0083e-02, -2.4011e-03,  1.1384e-02,  1.8920e-03,\n",
       "         -1.1522e-01,  2.5727e-02,  1.6895e-02,  8.3255e-03,  2.3962e-02,\n",
       "          6.0353e-02,  1.7068e-02,  4.7377e-02,  2.7464e-02,  4.8743e-02,\n",
       "          7.5937e-02,  3.4020e-02,  5.8768e-02,  5.1526e-02,  1.9177e-02,\n",
       "          1.2255e-02,  1.7058e-02, -3.0584e-01,  5.3723e-02,  5.2641e-02,\n",
       "          7.4931e-03,  8.0473e-03,  5.1533e-02,  2.6815e-02,  1.6538e-02,\n",
       "          7.7585e-03,  3.7131e-02,  2.8426e-02,  1.6543e-02,  3.0388e-02,\n",
       "         -9.6813e-03,  2.6446e-02,  5.9391e-02,  3.3866e-02, -1.3877e-02,\n",
       "          5.0415e-02, -7.9023e-03,  3.6284e-02,  1.2733e-02,  2.2542e-02,\n",
       "          3.6630e-02,  9.2280e-03,  3.8719e-02,  4.1514e-02,  4.8284e-02,\n",
       "         -1.4673e-02,  3.9955e-02,  3.1786e-02,  2.8342e-02,  6.0084e-02,\n",
       "         -5.6054e-03, -6.0051e-01,  1.3674e-02,  5.3414e-03,  2.1680e-02,\n",
       "          1.7339e-02,  1.7631e-02,  2.5795e-02,  5.4288e-02,  4.1404e-03,\n",
       "          1.6550e-02,  2.0046e-02,  1.2296e-02,  1.9723e-02,  9.6581e-03,\n",
       "          3.0429e-02, -9.5211e-02,  5.8852e-02,  2.3260e-02,  7.0863e-03,\n",
       "          3.1864e-02,  4.1533e-02,  3.8262e-02,  2.9270e-03, -2.4406e-03,\n",
       "         -7.0459e-04,  2.0805e-02,  3.1979e-02,  8.6200e-03,  4.7225e-02,\n",
       "          1.0877e-02,  6.8129e-03,  4.8274e-02,  2.1957e-02,  2.3721e-02,\n",
       "          3.3818e-02,  1.1655e-02,  4.6021e-02,  1.8045e-02, -1.3827e-02,\n",
       "         -3.9979e-03,  2.9055e-02,  7.4535e-02,  1.1002e-02,  2.0955e-02,\n",
       "         -3.2250e-02,  9.2323e-02,  6.0631e-02,  4.8247e-02,  2.5260e-02,\n",
       "          3.8033e-02,  2.6952e-02,  1.2707e-02,  2.3304e-02, -6.8546e-03,\n",
       "          2.3727e-02,  9.9788e-03, -7.4584e-04,  4.4504e-02,  3.0539e-02,\n",
       "          2.0200e-02,  4.6410e-03, -5.3424e-03,  2.6282e-03,  1.8000e-02,\n",
       "          2.2171e-02,  5.0755e-02,  5.0623e-02,  2.8502e-02, -6.8178e-03,\n",
       "          2.2921e-03,  3.9287e-02,  8.1652e-03,  1.6192e-02,  4.5056e-02,\n",
       "          1.9333e-02,  9.0636e-03,  1.0507e-02,  2.5045e-02,  3.0355e-02,\n",
       "          3.2846e-02,  4.5357e-02,  2.5181e-02,  4.5486e-02,  1.5991e-02,\n",
       "          9.1249e-03, -1.6159e-03, -3.3242e-03,  5.0166e-03, -1.1907e-02,\n",
       "          2.4148e-02,  1.4709e-02,  6.0083e-02, -5.4288e-03,  1.1880e-02,\n",
       "         -1.2682e-02,  9.9845e-03,  3.1314e-02,  5.4775e-02,  2.1177e-02,\n",
       "          3.4766e-02,  2.6360e-02,  5.2954e-02,  2.3196e-02,  2.8086e-02,\n",
       "         -1.5350e-02,  3.5632e-03,  2.0230e-02, -2.5101e-03,  3.2721e-02,\n",
       "         -5.2974e-03,  2.7180e-03,  4.6001e-02,  2.1882e-02,  2.3802e-02,\n",
       "         -3.7108e-03, -8.5181e-03,  2.8182e-02,  2.7818e-02,  2.3665e-02,\n",
       "          2.7919e-02,  7.8592e-04,  3.3945e-02,  2.3061e-02,  2.6832e-02,\n",
       "          4.5391e-02,  1.1655e-02,  2.3164e-03,  5.1892e-02,  1.2260e-02,\n",
       "          8.7936e-03, -1.3305e-02, -4.6087e-04,  3.5252e-02, -1.0717e-02,\n",
       "          5.9545e-03,  2.4296e-02,  3.2646e-02,  1.7622e-03,  6.5688e-02,\n",
       "          2.3266e-02,  2.1682e-02,  3.1347e-02,  2.6992e-02,  4.4732e-02,\n",
       "          4.2366e-02, -1.2863e-03,  7.0720e-03,  4.3547e-03,  2.3147e-02,\n",
       "          4.1584e-02,  5.8816e-03,  4.4269e-02,  2.1353e-03,  6.1128e-02,\n",
       "          6.8275e-02,  4.4310e-02,  4.5049e-02,  3.3080e-02,  8.5815e-03,\n",
       "         -5.4939e-02, -7.2536e-04, -2.6956e-03,  1.9162e-02,  4.3828e-02,\n",
       "          1.7810e-02,  1.5744e-02,  1.9663e-02,  9.2914e-03,  2.1843e-02,\n",
       "          1.8821e-02,  2.9652e-02,  5.2211e-03, -3.3464e-03,  1.2501e-02,\n",
       "          3.5486e-02,  7.3340e-03, -1.1261e-02,  2.0094e-02,  1.5204e-02,\n",
       "          1.0204e-02,  4.1609e-02,  1.3557e-02,  6.7135e-02,  1.2011e-02,\n",
       "          2.5460e-02,  6.1166e-03,  1.5924e-02,  4.5425e-02,  8.7188e-02,\n",
       "          3.5348e-02,  3.0157e-02, -2.1819e-02,  2.8529e-02, -1.4283e-02,\n",
       "          2.1892e-02,  1.8951e-02,  4.7751e-02,  2.6668e-02,  2.9404e-02,\n",
       "          1.0511e-02,  1.5914e-02, -1.1116e-02,  3.7344e-02,  2.0180e-02,\n",
       "          2.2825e-02,  3.1746e-02,  2.1207e-02,  2.7221e-02,  4.5675e-02,\n",
       "          4.1321e-02,  2.7240e-02,  2.8394e-02,  6.6000e-02,  2.5427e-02,\n",
       "          3.3961e-02,  9.0295e-03,  3.4376e-02,  1.4984e-02,  8.0904e-03,\n",
       "          1.6822e-02,  2.2855e-03,  9.1259e-03, -9.2325e-03,  5.7467e-02,\n",
       "          2.9218e-03, -2.2570e-02,  1.7161e-02,  1.2237e-02, -2.6738e-02,\n",
       "          1.0197e-03,  5.3789e-03,  3.9366e-02,  5.4971e-02,  8.0899e-03,\n",
       "          3.5850e-02,  4.6131e-03,  2.0722e-02, -3.1729e-02,  2.9270e-02,\n",
       "          3.3209e-02,  3.2098e-02,  6.1395e-02, -1.2445e-02,  7.2913e-02,\n",
       "          2.4019e-02,  2.5712e-02,  3.7966e-02, -1.0105e-02,  2.5099e-02,\n",
       "          1.4116e-02,  1.3625e-02,  2.1187e-02,  1.3063e-02,  4.3473e-04,\n",
       "          1.3430e-02,  1.5159e-02,  1.6721e-02,  3.1475e-02,  2.6737e-02,\n",
       "         -1.0435e-02,  2.5066e-02,  3.9083e-02,  2.1112e-02,  2.4588e-02,\n",
       "          1.3874e-01,  3.0582e-02,  4.4362e-02,  3.6819e-02,  2.8616e-02,\n",
       "          1.3359e-02,  1.4427e-02,  4.7326e-03,  9.0515e-03,  3.2625e-02,\n",
       "          3.0964e-02,  7.8371e-02,  3.4118e-02,  3.3910e-02,  2.2646e-02,\n",
       "          1.4631e-02,  1.8085e-02, -1.1369e-02, -1.4955e-02,  1.8636e-02,\n",
       "          3.3812e-02,  2.1553e-02,  6.5092e-04]),\n",
       " 'transformer.h.10.mlp.c_fc.weight': tensor([[-0.0470, -0.1844,  0.0954,  ..., -0.1219,  0.0784,  0.0695],\n",
       "         [ 0.0465, -0.2866, -0.0475,  ..., -0.1587,  0.0991,  0.0961],\n",
       "         [ 0.1747, -0.0565, -0.0819,  ...,  0.0196,  0.0371,  0.0941],\n",
       "         ...,\n",
       "         [ 0.0594, -0.0186, -0.2675,  ..., -0.1615,  0.0099, -0.2356],\n",
       "         [-0.0591,  0.0056,  0.0860,  ..., -0.0222, -0.0652, -0.1163],\n",
       "         [-0.1588,  0.0426, -0.0066,  ..., -0.0767,  0.0009, -0.0639]]),\n",
       " 'transformer.h.10.mlp.c_fc.bias': tensor([-0.0678,  0.0492, -0.1440,  ..., -0.0373, -0.3087, -0.1231]),\n",
       " 'transformer.h.10.mlp.c_proj.weight': tensor([[ 0.0526,  0.2037, -0.2281,  ...,  0.0285,  0.0621,  0.0854],\n",
       "         [ 0.1654, -0.2038,  0.0162,  ..., -0.0902, -0.0277, -0.1632],\n",
       "         [ 0.1352,  0.1129, -0.0354,  ...,  0.0646,  0.0649, -0.1546],\n",
       "         ...,\n",
       "         [ 0.4044,  0.2177, -0.1393,  ...,  0.1725,  0.0065,  0.1030],\n",
       "         [ 0.0533,  0.0962, -0.4815,  ..., -0.0038, -0.1052,  0.1185],\n",
       "         [ 0.1796, -0.1290,  0.1392,  ...,  0.0440,  0.2462, -0.1688]]),\n",
       " 'transformer.h.10.mlp.c_proj.bias': tensor([-3.8143e-02,  2.5599e-02, -2.0104e-01,  1.4348e-01,  1.7296e-01,\n",
       "         -1.0449e-01,  2.3975e-01,  3.1738e-01,  2.6895e-01, -3.7742e-02,\n",
       "         -2.1719e-01, -1.3379e-01, -1.6686e-02,  1.1986e-01, -4.6542e-02,\n",
       "         -3.7086e-02, -6.1694e-02,  3.7257e-01,  2.7303e-01, -2.3525e-01,\n",
       "          4.0211e-02,  1.3741e-02,  1.4994e-01, -8.7482e-03, -2.8816e-01,\n",
       "         -4.8289e-02, -1.4627e-01,  1.3170e-01,  5.7696e-02,  7.8080e-02,\n",
       "          1.6892e-01,  1.4323e-01,  1.9676e-01, -2.7084e-01, -1.7095e-02,\n",
       "         -2.2893e-01,  3.7549e-01, -6.1329e-02,  1.2292e-02, -1.4345e-04,\n",
       "          4.6832e-03, -1.4181e-01,  1.1796e-01, -1.0276e-01, -1.2250e-01,\n",
       "         -2.5222e-01,  9.4139e-02,  2.4413e-01,  8.8424e-02,  2.8009e-01,\n",
       "          2.0151e-01, -5.7480e-03, -1.8841e-02,  4.0198e-02,  5.7171e-02,\n",
       "          1.8770e-01, -4.3182e-02,  7.2363e-02, -8.2459e-02,  9.9696e-03,\n",
       "         -1.8823e-01,  7.0356e-02,  3.1884e-01, -2.3913e-01, -7.5639e-01,\n",
       "          1.2948e-01,  7.3434e-02, -1.2257e-02, -2.5637e-01, -9.4662e-02,\n",
       "          1.3555e-01, -2.5064e-02,  1.0826e-01, -1.2222e-01,  6.5764e-02,\n",
       "          6.0241e-03, -8.9593e-02, -3.5348e-01, -1.7470e-01, -1.1654e-01,\n",
       "          1.2474e-02,  1.2593e-01, -5.3945e-02, -9.4816e-02, -2.0751e-01,\n",
       "          1.1186e-02,  2.5762e-01, -5.1091e-01, -6.1145e-02, -5.4759e-02,\n",
       "         -4.2531e-03,  9.5853e-02, -1.2925e-01,  2.4003e-01, -1.2552e-03,\n",
       "          4.7027e-02, -2.4122e-01,  1.9284e-01,  1.5343e-01, -1.4140e-01,\n",
       "         -1.2101e-01,  1.5099e-01,  3.2635e-01,  2.5328e-01, -1.4151e-01,\n",
       "          8.5708e-02,  2.3137e-01,  1.3640e-01, -1.4373e-01,  1.2222e-01,\n",
       "          9.3257e-02,  4.6817e-02,  7.6846e-02,  8.2065e-02, -1.8397e-01,\n",
       "          8.8908e-02, -9.8975e-02,  1.0629e-01,  2.4419e-02, -1.4808e-01,\n",
       "          2.3604e-01,  1.1292e-01,  1.7406e-01,  7.7582e-02,  4.3627e-01,\n",
       "         -7.5567e-02, -8.8554e-02, -1.1853e-01, -1.1230e-01,  7.6000e-02,\n",
       "         -3.1416e-02,  5.9794e-02, -1.9011e-01,  3.0470e-01,  4.3425e-01,\n",
       "          1.6238e-02,  7.3720e-03, -1.9312e-01, -2.5405e-01,  8.1005e-02,\n",
       "          1.3216e-01,  1.8647e-01, -1.5464e-01, -1.7287e-01, -3.6527e-01,\n",
       "          1.5677e-01, -3.1230e-02,  1.5665e-01, -3.5846e-02, -1.6030e-02,\n",
       "         -2.4349e-01,  2.4982e-01,  4.3248e-01,  2.1962e-01,  1.8951e-01,\n",
       "          1.3434e-01,  1.9932e-01,  1.6355e-01,  2.7505e-01, -2.3918e-02,\n",
       "          3.0964e-01, -7.3299e-02, -1.6255e-01, -7.1651e-02,  1.2032e-01,\n",
       "         -6.8780e-02,  5.6922e-02, -1.7021e-01,  1.2268e-01,  1.2964e-01,\n",
       "         -1.4666e-01,  8.4830e-02,  1.5973e-01, -1.0504e-01, -7.7611e-02,\n",
       "          8.3413e-02, -3.7759e-01,  1.8042e-01,  1.2408e-01, -1.7245e-02,\n",
       "          9.2364e-02,  1.3709e-01,  1.1227e-01, -9.1766e-02, -1.3294e-01,\n",
       "          9.1459e-02, -1.3241e-01, -1.1060e-01, -6.8468e-02,  1.0740e-01,\n",
       "          2.2344e-01, -4.6891e-01, -6.7498e-02, -8.1809e-02,  2.2811e-01,\n",
       "         -1.6033e-01, -2.6327e-01, -1.9903e-01,  3.2382e-01,  3.5482e-02,\n",
       "          2.1925e-01, -3.4115e-02,  8.7567e-02,  7.3009e-02,  1.3954e-01,\n",
       "         -1.0720e-01, -1.9729e-01, -7.7086e-02, -1.4805e-02, -2.0860e-01,\n",
       "          6.7832e-02, -2.2851e-03,  1.4290e-01,  1.0806e-01,  1.3177e-01,\n",
       "         -2.1775e-01,  6.9232e-02, -1.3349e-01, -8.3663e-02, -7.0714e-02,\n",
       "         -6.5278e-02, -2.1721e-01,  1.4354e-01, -9.2345e-02,  1.2621e-01,\n",
       "          1.5472e-01,  1.9213e-01,  1.6357e-01,  1.9801e-02, -1.2216e-01,\n",
       "          2.1403e-02,  2.0315e-01,  2.8329e-01, -1.6874e-01,  1.7956e-01,\n",
       "         -1.5323e-01,  6.5958e-02, -1.4719e-01,  1.3041e-01,  4.6650e-02,\n",
       "          1.7008e-01, -1.3723e-01, -4.5214e-02, -1.8821e-01,  3.7930e-02,\n",
       "          1.0018e-01,  4.8997e-02,  8.2434e-02, -2.5882e-01, -2.0671e-01,\n",
       "         -2.0532e-02,  6.6051e-02,  3.0145e-02,  4.8899e-02,  1.3834e-01,\n",
       "          2.6462e-02, -2.9981e-01,  1.1138e-01,  3.3417e-01, -3.5646e-02,\n",
       "         -3.0519e-02,  1.5504e-01, -3.4763e-01, -1.4912e-01, -3.2172e-01,\n",
       "         -1.4177e-01,  5.4598e-01,  1.0665e-01, -2.4090e-01,  4.6356e-02,\n",
       "         -4.4664e-01,  7.1574e-02,  2.0512e-02, -1.9377e-01, -1.6301e-02,\n",
       "         -2.6721e-02,  2.4572e-01, -1.4274e-01,  7.2313e-02,  6.1251e-02,\n",
       "          6.5675e-02, -1.1732e-01,  1.6584e-01, -3.4024e-01,  2.0874e-01,\n",
       "         -3.1980e-02,  1.4726e-02,  2.1803e-01,  4.7385e-02, -1.2282e-01,\n",
       "         -1.4817e-01,  6.5807e-02,  3.3150e-01, -1.6795e-02, -4.9827e-01,\n",
       "          4.5978e-02,  8.4362e-02,  9.1172e-02,  2.0120e-03, -1.1323e-01,\n",
       "          1.6160e-01, -3.7206e-01,  1.2649e-01,  6.5695e-02, -2.6316e-02,\n",
       "         -2.2873e-01, -9.1453e-02,  2.1830e-01, -3.3229e-01,  7.2913e-02,\n",
       "         -6.5246e-02, -3.0352e-01,  6.7573e-02, -1.9244e-01, -4.4533e-01,\n",
       "         -1.0069e-01,  4.8872e-01,  8.0938e-02, -7.3544e-02, -8.3964e-02,\n",
       "         -2.0925e-01, -5.8470e-03,  2.6306e-01,  1.2856e-01, -1.3729e-01,\n",
       "         -5.3144e-02,  4.6033e-01,  2.5003e-02,  8.2404e-02, -1.3840e-02,\n",
       "          1.2217e-01, -3.6007e-02, -6.4687e-02,  7.5287e-02, -1.9078e-01,\n",
       "          7.7334e-03, -2.5034e-01, -8.9020e-02, -1.1531e-01,  4.8968e-02,\n",
       "         -1.8849e-01,  5.2834e-02,  1.7361e-01,  8.8387e-02, -9.5664e-02,\n",
       "          5.0541e-02,  2.1083e-01,  1.2897e-01,  7.9816e-02, -1.6714e-01,\n",
       "         -4.0522e-02,  3.7384e-02,  6.0570e-02, -1.2221e-01,  1.8752e-01,\n",
       "         -2.1690e-02, -5.0092e-01,  1.9677e-01, -5.0628e-01,  1.5160e-01,\n",
       "         -2.7060e-01, -8.4371e-02,  2.5535e-01,  1.5280e-01,  1.8634e-01,\n",
       "         -1.0199e-01, -5.7972e-03,  2.4652e-01, -5.5806e-02, -1.5157e-01,\n",
       "         -1.0008e-01, -1.9642e-02, -2.2094e-01, -1.0768e+00, -2.9864e-01,\n",
       "         -4.2762e-01, -1.1246e-01,  3.9854e-01,  2.4553e-01,  1.9120e-01,\n",
       "          5.4409e-02,  1.8443e-01, -4.2112e-02,  1.1395e-01, -4.3893e-02,\n",
       "          6.0759e-02, -1.1300e-02,  3.4083e-02,  2.1713e-01, -1.8448e-01,\n",
       "          2.0593e-02, -1.9448e-01,  1.4154e-01,  3.2273e-01, -6.9914e-02,\n",
       "         -5.7180e-02, -1.0634e-01, -2.7934e-02,  1.4282e-01, -1.3052e-01,\n",
       "          2.3706e-01,  1.2440e-01,  1.8414e-01,  6.2075e-02, -5.1292e-02,\n",
       "          8.3658e-02, -1.5651e-01, -1.0092e-02,  4.0387e-01,  1.6928e-01,\n",
       "         -1.3300e-01,  3.1057e-01, -5.5125e-02,  2.1672e-01,  4.2086e-03,\n",
       "          1.2447e-01,  7.0247e-02, -5.1777e-02,  8.1937e-02,  2.8656e-01,\n",
       "          4.6151e-03,  1.8913e-01, -2.2937e-01, -1.9747e-01, -2.5782e-01,\n",
       "          1.8636e-01,  5.8540e-02,  4.5639e-02, -1.3394e-01,  6.5096e-03,\n",
       "          4.4221e-01, -7.2945e-02, -5.5352e-03,  1.5902e-01,  3.3598e-01,\n",
       "          2.1134e-01, -3.1201e-02,  1.4178e-01, -1.1607e-01, -1.0096e-01,\n",
       "          2.5346e-01,  1.4458e-01,  7.2361e-02, -1.2401e-02, -3.2370e-01,\n",
       "         -2.0378e-02,  9.1925e-02,  1.3404e+00,  7.8867e-02,  2.6674e-02,\n",
       "          2.0070e-01,  1.6535e-02, -7.3361e-02, -2.4295e-01,  2.9986e-01,\n",
       "          2.5448e-01,  1.2613e-01, -3.9061e-02,  1.1476e-01, -1.2231e-01,\n",
       "         -2.0507e-01, -1.1872e-02,  1.9056e-01,  5.2914e-02,  1.2171e-01,\n",
       "         -2.1321e-01,  1.8319e-01, -7.9405e-02,  5.5996e-02, -5.7639e-02,\n",
       "         -3.2464e-01, -2.7739e-02, -9.1723e-02, -9.4535e-02, -1.4464e-01,\n",
       "         -1.2075e-01,  2.2768e-01,  1.8153e-01, -1.9708e-01, -2.7437e-01,\n",
       "         -5.2851e-01,  1.1129e+00,  7.4122e-02, -1.6188e-01, -1.3519e-02,\n",
       "          1.4743e-01, -9.2692e-02, -4.2594e-02,  1.4096e-01,  2.1862e-01,\n",
       "         -9.8956e-02, -1.5609e-01,  1.0342e-01,  1.8255e-01,  1.4976e-01,\n",
       "         -2.7884e-02,  7.6394e-01, -1.4906e-01,  8.2581e-02,  7.3296e-02,\n",
       "          1.5545e-01,  1.7724e-01, -1.0694e-01, -4.1212e-01, -3.0346e-01,\n",
       "         -2.0468e-01,  1.1816e-02,  1.8647e-01,  2.0743e-01,  1.7826e-01,\n",
       "         -1.3123e-01, -2.0936e-01,  3.1381e-01, -1.2333e-01, -5.8601e-02,\n",
       "          1.4561e-01,  1.2455e-02, -7.0780e-02,  1.2439e-01,  1.9909e-01,\n",
       "         -9.7549e-02, -2.4073e-01,  8.4320e-02,  1.9366e-01,  5.8192e-02,\n",
       "         -2.4837e-01, -3.9474e-01, -3.3803e-01,  1.1430e-01,  2.6951e-02,\n",
       "          5.5158e-02,  9.9056e-02, -1.1751e-01, -5.1982e-02,  6.7939e-02,\n",
       "         -1.4831e-01, -9.2635e-02, -6.9334e-02,  2.3419e-02, -1.3666e-01,\n",
       "          1.6781e-01,  1.1838e-01, -1.0927e-01, -1.3770e-01,  1.3135e-02,\n",
       "          1.3371e-01, -2.7289e-02,  5.5254e-02, -9.8559e-03, -2.1324e-01,\n",
       "         -7.3178e-02,  1.2287e-01, -4.1111e-02, -1.8449e-01, -3.2350e-01,\n",
       "          2.1753e-01,  1.5151e-01,  1.6217e-01,  9.0199e-02, -3.7094e-02,\n",
       "          8.9493e-02, -6.4128e-02, -2.3840e-01,  2.7410e-01,  6.7423e-02,\n",
       "          1.0561e-01, -2.1592e-03, -1.2679e-01, -1.2053e-01,  1.5938e-02,\n",
       "         -3.2527e-01,  4.0235e-02,  2.4296e-01, -1.3199e-01, -1.4000e-01,\n",
       "          1.3745e-01, -7.9453e-02,  8.5562e-02, -9.1363e-02,  1.0521e-02,\n",
       "          1.1684e-01, -1.3988e-01,  4.3998e-02,  1.7960e-02,  1.7531e-01,\n",
       "          1.2315e-01, -1.0354e-01,  9.5456e-03,  1.0831e-01,  4.9891e-03,\n",
       "         -1.4330e-01, -1.2944e-01, -1.4552e-02, -1.2529e-01,  1.0417e-01,\n",
       "         -6.7777e-02,  3.6176e-02, -1.0470e-01, -1.4965e-02, -1.3677e-01,\n",
       "         -2.4409e-01, -2.3566e-01, -1.5233e-01,  3.3304e-01,  4.6872e-02,\n",
       "          1.5761e-03,  2.5426e-01, -3.7104e-01,  3.9172e-01,  1.5297e-01,\n",
       "         -2.3011e-01, -6.7894e-02,  4.3814e-02, -2.0516e-01,  4.7039e-03,\n",
       "         -1.5345e-01,  1.1341e-01, -2.2237e-01,  2.9436e-02,  3.5200e-01,\n",
       "         -2.7242e-01, -1.5071e-01, -2.4958e-01, -6.1204e-02, -2.8815e-01,\n",
       "         -8.7968e-02, -3.6116e-01, -2.8994e-01, -1.9701e-02, -9.4269e-02,\n",
       "         -1.6828e-01,  1.7895e-01,  3.0548e-01, -1.0286e-01, -7.8868e-03,\n",
       "         -1.8351e-01, -2.7882e-01,  1.9623e-01, -2.5421e-02,  2.1852e-01,\n",
       "          4.5399e-01, -4.7588e-03, -5.4432e-02, -5.0468e-02,  5.9853e-02,\n",
       "         -3.3782e-02, -1.2641e-01,  8.0825e-02,  1.2883e-01, -1.6844e-01,\n",
       "          3.6612e-02,  1.4562e-01,  2.2725e-01, -1.8357e-01, -2.7564e-01,\n",
       "          1.2676e-01,  1.8689e-02,  1.1199e-01, -2.4423e-01,  6.6204e-02,\n",
       "          1.6659e-01, -9.4392e-02,  5.8944e-02, -5.7070e-02,  7.3812e-02,\n",
       "          4.0672e-01, -6.2068e-02, -1.2242e-01,  2.2239e-01,  3.8539e-01,\n",
       "          8.9461e-02, -6.2826e-02, -3.5134e-02, -8.7834e-02,  3.4615e-02,\n",
       "          8.4902e-02,  2.8439e-01,  2.1722e-01,  1.0903e-01,  1.2715e-01,\n",
       "         -3.8421e-01, -1.5105e-01,  2.1808e-01, -9.2623e-02, -4.4051e-01,\n",
       "         -3.1955e-01, -2.3065e-01, -5.6844e-02,  2.4761e-01, -5.1167e-02,\n",
       "          2.1335e-01,  1.0087e-01, -2.9482e-01,  1.6396e-01, -6.2869e-02,\n",
       "          3.2561e-02,  1.4373e-01, -2.1226e-01,  1.4838e-01,  3.9979e-02,\n",
       "          1.4560e-01,  1.9304e-02, -1.1265e-01, -4.0770e-01,  3.6567e-02,\n",
       "          6.0423e-02, -2.0730e-01,  1.0954e-01,  5.1026e-02, -3.8509e-02,\n",
       "          1.3629e-01, -3.5795e-01, -1.9559e-01, -4.1739e-02, -2.7428e-02,\n",
       "          2.3496e-01, -2.0647e-01, -6.6377e-02,  1.5882e-01,  7.0732e-02,\n",
       "          1.9729e-01, -2.1172e-01, -5.7085e-02, -1.0428e-02,  2.6602e-01,\n",
       "          2.2054e-01, -1.2878e-01, -1.7998e-01, -9.4714e-02, -4.6447e-02,\n",
       "          6.1832e-02, -2.1316e-01,  9.9077e-02, -1.0367e-01,  9.9358e-02,\n",
       "         -6.2603e-02, -3.2249e-01, -2.1392e-02, -4.3291e-02, -2.7536e-01,\n",
       "         -1.6295e-01,  1.5185e-01,  8.4377e-02, -2.6299e-01, -1.9028e-01,\n",
       "         -3.3593e-01, -1.1183e-01,  8.0995e-02, -2.0961e-01,  7.2705e-02,\n",
       "          3.2803e-02, -9.3140e-02,  2.2211e-01, -5.9392e-02, -1.7534e-01,\n",
       "         -9.2621e-02,  2.6030e-02, -1.9912e-01,  6.9357e-02,  1.6677e-01,\n",
       "         -1.2446e-01,  2.8240e-01,  2.3896e-01, -1.0167e-01, -1.0009e-01,\n",
       "         -1.7404e-01, -5.3099e-02, -3.0209e-01]),\n",
       " 'transformer.ln_f.weight': tensor([1.3971e+00, 1.3750e+00, 1.8870e+00, 1.1688e+00, 1.2724e+00, 1.2508e+00,\n",
       "         9.4198e+00, 1.4371e+00, 1.4527e+00, 1.1856e+00, 1.3945e+00, 1.2796e+00,\n",
       "         1.2071e+00, 1.2951e+00, 1.2776e+00, 1.3480e+00, 1.5088e+00, 1.3729e+00,\n",
       "         1.3427e+00, 2.3761e+00, 1.1377e+00, 1.2909e+00, 1.3477e+00, 1.4775e+00,\n",
       "         1.2540e+00, 1.1999e+00, 1.4932e+00, 1.1637e+00, 1.2590e+00, 1.2305e+00,\n",
       "         1.1833e+00, 1.1914e+00, 1.2228e+00, 1.2792e+00, 1.3294e+00, 1.6213e+00,\n",
       "         1.3804e+01, 1.1871e+00, 1.2235e+00, 1.4578e+00, 1.1687e+00, 1.3164e+00,\n",
       "         1.1444e+00, 1.2628e+00, 1.4781e+00, 1.2426e+00, 1.1744e+00, 1.1602e+00,\n",
       "         1.3637e+00, 2.1280e+00, 1.2371e+00, 1.2336e+00, 1.7410e+00, 1.1568e+00,\n",
       "         1.3303e+00, 1.8593e+00, 1.2932e+00, 1.3320e+00, 1.2148e+00, 1.5415e+00,\n",
       "         1.3781e+00, 1.2070e+00, 1.4030e+00, 1.5724e+00, 7.6159e-03, 1.1836e+00,\n",
       "         1.2148e+00, 1.2604e+00, 1.8500e+00, 1.1540e+00, 1.2933e+00, 1.1572e+00,\n",
       "         1.2341e+00, 1.1055e+00, 1.1680e+00, 1.3321e+00, 1.3856e+00, 3.6001e+00,\n",
       "         1.6204e+00, 1.1333e+00, 1.4368e+00, 1.1365e+00, 1.2749e+00, 1.5402e+00,\n",
       "         9.2773e-01, 1.5039e+00, 2.5029e+00, 4.4275e-03, 1.0613e+00, 1.3566e+00,\n",
       "         1.2504e+00, 1.1983e+00, 1.4295e+00, 1.2386e+00, 1.1792e+00, 1.1883e+00,\n",
       "         1.4453e+00, 1.4384e+00, 1.2305e+00, 1.3109e+00, 1.2305e+00, 1.1997e+00,\n",
       "         3.1531e+00, 1.3615e+00, 1.1858e+00, 1.2148e+00, 1.2228e+00, 8.9936e+00,\n",
       "         1.0824e+00, 1.2424e+00, 1.4070e+00, 1.2314e+00, 1.2359e+00, 1.2810e+00,\n",
       "         1.3169e+00, 1.1992e+00, 1.4846e+00, 1.3867e+00, 1.2227e+00, 1.2774e+00,\n",
       "         1.1955e+00, 1.2539e+00, 1.3414e+00, 1.2502e+00, 1.2220e+00, 1.2655e+00,\n",
       "         1.1805e+00, 1.2932e+00, 1.6978e+00, 1.3635e+00, 1.2106e+00, 1.1450e+00,\n",
       "         1.4414e+00, 1.0931e+00, 1.1859e+00, 1.2156e+00, 1.1804e+00, 1.5686e+00,\n",
       "         8.6240e-02, 1.8252e+00, 1.1971e+00, 1.1500e+00, 3.3033e+00, 1.1137e+00,\n",
       "         1.1841e+00, 1.8482e+00, 1.3211e+00, 1.1996e+00, 1.1784e+00, 1.4120e+00,\n",
       "         1.2726e+00, 1.5131e+00, 1.4775e+00, 1.5084e+00, 1.4086e+00, 1.3018e+00,\n",
       "         1.2469e+00, 1.2008e+00, 1.0666e+00, 1.0909e+00, 3.0489e+00, 1.2242e+00,\n",
       "         1.2333e+00, 1.2970e+00, 1.2137e+00, 1.3484e+00, 1.2782e+00, 4.0765e+00,\n",
       "         1.2149e+00, 1.3308e+00, 1.2631e+00, 1.1915e+00, 1.1758e+00, 1.4181e+00,\n",
       "         1.4744e+00, 1.5844e+00, 2.1523e+00, 1.1229e+00, 1.4097e+00, 1.1849e+00,\n",
       "         1.2051e+00, 1.2154e+00, 1.2320e+00, 1.3685e+00, 1.1289e+00, 1.2304e+00,\n",
       "         1.1187e+00, 1.3789e+00, 1.2056e+00, 1.3168e+00, 1.2865e+00, 1.3707e+00,\n",
       "         1.2933e+00, 1.2151e+00, 1.1296e+00, 1.8137e+00, 1.2315e+00, 1.2476e+00,\n",
       "         1.2515e+00, 1.6609e+00, 1.4583e+00, 1.4180e+00, 1.2085e+00, 1.2292e+00,\n",
       "         1.0586e+00, 1.2148e+00, 1.1842e+00, 1.0864e+00, 1.3871e+00, 1.2393e+00,\n",
       "         1.2228e+00, 1.5026e+00, 1.3742e+00, 2.4785e+00, 1.2004e+00, 1.1891e+00,\n",
       "         1.4659e+00, 1.1916e+00, 1.0978e+00, 1.2148e+00, 1.1180e+00, 1.1934e+00,\n",
       "         1.1934e+00, 1.2339e+00, 1.6256e+00, 1.2190e+00, 1.2476e+00, 1.1685e+00,\n",
       "         1.2186e+00, 1.2413e+00, 1.1367e+00, 1.3399e+00, 3.4147e+00, 1.0761e+00,\n",
       "         1.1924e+00, 1.3913e+00, 1.1215e+00, 1.1398e+00, 1.3053e+00, 1.2300e+00,\n",
       "         1.4287e+00, 1.5445e+00, 1.2461e+00, 1.1179e+00, 1.0352e+00, 1.2579e+00,\n",
       "         1.1846e+00, 1.6518e+00, 1.2148e+00, 1.5199e+00, 2.3705e+00, 1.4342e+00,\n",
       "         1.2745e+00, 1.4321e+00, 1.3017e+00, 1.5673e+00, 1.4878e+00, 1.1600e+00,\n",
       "         1.2305e+00, 1.4492e+00, 1.2450e+00, 1.6015e+00, 1.2074e+00, 1.2931e+00,\n",
       "         1.0899e+00, 1.2818e+00, 6.8271e-03, 1.3498e+00, 1.3882e+00, 1.6141e+00,\n",
       "         2.2603e+00, 4.3566e+00, 1.2119e+00, 1.0664e+00, 1.5068e+00, 1.2935e+00,\n",
       "         1.7190e+00, 1.2120e+00, 1.1749e+00, 1.2177e+00, 1.2027e+00, 1.1525e+00,\n",
       "         1.4620e+00, 1.4274e+00, 1.0562e+00, 1.4126e+00, 1.3862e+00, 1.1511e+00,\n",
       "         1.2874e+00, 2.0521e+00, 1.4653e+00, 1.2819e+00, 1.2038e+00, 1.1852e+00,\n",
       "         1.4243e+00, 1.2345e+00, 1.0954e+00, 1.1217e+00, 1.1998e+00, 1.2631e+00,\n",
       "         1.8584e+00, 1.1845e+00, 1.4605e+00, 1.2383e+00, 1.2808e+00, 1.0243e+00,\n",
       "         1.2522e+00, 1.1446e+00, 3.1141e+00, 1.2562e+00, 1.1038e+00, 2.2026e+00,\n",
       "         1.2352e+00, 1.2740e+00, 1.5308e+01, 1.3327e+00, 1.2991e+00, 1.2305e+00,\n",
       "         1.2227e+00, 1.3008e+00, 2.4603e+00, 1.2306e+00, 1.1791e+00, 1.2395e+00,\n",
       "         1.3017e+00, 1.2238e+00, 9.8373e-01, 1.1771e+00, 1.3761e+00, 1.1659e+00,\n",
       "         1.1485e+00, 1.1823e+00, 1.2148e+00, 1.1784e+00, 1.0820e+00, 1.3048e+00,\n",
       "         1.4846e+00, 1.1753e+00, 1.2101e+00, 1.3441e+00, 1.1446e+00, 1.1445e+00,\n",
       "         1.1766e+00, 1.4649e+00, 1.4105e+00, 1.0483e+00, 1.2181e+00, 1.2429e+00,\n",
       "         1.2293e+00, 1.2272e+00, 1.2309e+00, 1.9298e+00, 1.2051e+00, 1.3829e+00,\n",
       "         1.2752e+00, 1.2049e+00, 1.9575e+00, 1.2054e+00, 1.0039e+00, 1.1939e+00,\n",
       "         1.3718e+00, 2.8912e+00, 2.1898e+00, 1.1977e+00, 1.0975e+00, 3.9985e+00,\n",
       "         1.2511e+00, 1.0346e+00, 1.1375e+00, 1.1822e+00, 1.4023e+00, 1.1227e+00,\n",
       "         1.2915e+00, 3.5039e-02, 1.2217e+01, 1.4350e+00, 1.4025e+00, 2.3862e+00,\n",
       "         8.5499e-01, 1.3179e+00, 1.2637e+00, 1.2388e+00, 1.0809e+00, 1.5234e+00,\n",
       "         1.4024e+00, 1.2991e+00, 1.5354e+00, 1.1690e+00, 1.2194e+00, 2.6955e+00,\n",
       "         1.2617e+00, 1.2485e+00, 1.3482e+00, 6.9770e-01, 1.4888e+00, 1.0986e+00,\n",
       "         1.6696e+00, 1.1986e+00, 1.1655e+00, 1.1134e+00, 1.0508e+00, 1.2227e+00,\n",
       "         2.3545e+00, 1.2345e+00, 1.0825e+00, 1.2153e+00, 1.2073e+00, 1.0666e+00,\n",
       "         4.3418e+00, 1.1837e+00, 1.2441e+00, 1.2461e+00, 1.2586e+00, 1.2292e+00,\n",
       "         1.4278e+00, 1.4742e+00, 1.2469e+00, 1.5043e+00, 1.4920e+00, 1.0824e+00,\n",
       "         1.9560e+00, 1.4904e+00, 1.2004e+00, 1.1992e+00, 1.1798e+00, 1.0748e+00,\n",
       "         1.1701e+00, 1.1871e+00, 1.2570e+00, 1.2104e+00, 1.6994e+01, 1.2695e+00,\n",
       "         1.2397e+00, 1.2462e+00, 1.1837e+00, 1.4884e+00, 1.2487e+00, 1.2075e+00,\n",
       "         1.4805e+00, 2.7156e+00, 1.2308e+00, 1.1758e+00, 1.2199e+01, 1.2564e+00,\n",
       "         1.3756e+00, 1.2305e+00, 1.2151e+00, 3.5184e-02, 1.2539e+00, 1.2619e+00,\n",
       "         1.3423e+00, 1.2802e+00, 1.1453e+00, 1.8877e+00, 1.3793e+00, 2.7507e+00,\n",
       "         1.7741e+00, 1.3170e+00, 1.2972e+00, 1.6555e+00, 1.3009e+00, 1.3419e+00,\n",
       "         1.1063e+00, 1.2773e+00, 9.6680e-01, 1.2736e+00, 1.2227e+00, 1.2159e+00,\n",
       "         1.3187e+00, 1.1759e+00, 1.0922e+00, 1.1300e+00, 1.2853e+00, 1.2227e+00,\n",
       "         1.1478e+00, 1.3477e+00, 1.0232e+00, 1.1962e+00, 1.1798e+00, 7.3442e+00,\n",
       "         5.5998e-03, 4.2853e-02, 1.1763e+00, 1.2247e+00, 1.4425e+00, 1.2482e+00,\n",
       "         1.1936e+00, 1.1623e+00, 1.5431e+00, 1.2553e+00, 1.2461e+00, 1.4025e+00,\n",
       "         1.0510e+00, 1.1926e+00, 1.1642e+00, 1.1370e+00, 1.7419e+01, 1.7540e+00,\n",
       "         1.2953e+00, 1.1212e+00, 1.2787e+00, 1.1915e+00, 1.4268e+00, 4.1753e+00,\n",
       "         1.4481e+00, 1.1768e+00, 1.1994e+00, 1.2464e+00, 1.4068e+00, 1.2426e+00,\n",
       "         1.0352e+00, 2.2258e+00, 1.7040e+00, 1.2463e+00, 1.3851e+00, 1.4013e+00,\n",
       "         1.1661e+00, 1.3970e+00, 1.3403e+00, 1.2852e+00, 1.1684e+00, 1.2515e+00,\n",
       "         1.2318e+00, 1.2731e+00, 1.1832e+00, 2.3393e+00, 2.0250e+00, 2.1031e+00,\n",
       "         1.9473e+00, 1.0853e+00, 1.0114e+00, 1.2650e+00, 1.2014e+00, 1.0996e+00,\n",
       "         1.2435e+00, 1.3647e+00, 1.1999e+00, 1.3419e+00, 1.4270e+00, 1.2332e+00,\n",
       "         2.2816e+00, 1.2234e+00, 1.1839e+00, 2.4615e+00, 1.2603e+00, 1.3412e+00,\n",
       "         1.2818e+00, 1.1999e+00, 1.4258e+00, 1.1138e+00, 1.1914e+00, 2.0622e+00,\n",
       "         1.1712e+00, 1.3323e+00, 2.9923e+00, 1.2178e+00, 1.2220e+00, 1.2960e+00,\n",
       "         1.2466e+00, 1.4102e+00, 1.3290e+00, 1.2458e+00, 1.1273e+00, 1.1836e+00,\n",
       "         1.2652e+00, 1.2907e+00, 1.9197e+00, 1.1735e+00, 1.4725e+00, 1.4414e+00,\n",
       "         1.1830e+00, 1.3088e+00, 1.1055e+00, 1.0831e+00, 1.2468e+00, 1.3466e+00,\n",
       "         1.1992e+00, 1.2368e+00, 1.4933e+00, 1.1602e+00, 1.2542e+00, 1.3133e+00,\n",
       "         1.4812e+00, 1.2707e+00, 1.2185e+00, 1.2779e+00, 1.2339e+00, 1.4316e+00,\n",
       "         1.6659e+00, 1.2227e+00, 1.2312e+00, 1.2383e+00, 1.2305e+00, 1.4299e+00,\n",
       "         1.0813e+00, 1.2005e+00, 1.2228e+00, 1.2314e+00, 1.2383e+00, 1.2539e+00,\n",
       "         1.3949e+00, 1.3330e+00, 1.0798e+00, 1.2699e+00, 1.2942e+00, 1.2252e+00,\n",
       "         1.3091e+00, 1.2312e+00, 1.8579e+00, 1.2031e+00, 1.3398e+00, 1.3956e+00,\n",
       "         1.2026e+00, 1.1759e+00, 1.1842e+00, 1.1479e+00, 1.2016e+00, 1.2587e+00,\n",
       "         1.1211e+00, 1.3564e+00, 1.0669e+00, 1.2955e+00, 1.5078e+00, 2.3227e+00,\n",
       "         1.3065e+00, 1.1133e+00, 1.1542e+00, 6.1745e+00, 1.2328e+00, 1.2865e+00,\n",
       "         1.2617e+00, 1.2497e+00, 1.1554e+00, 1.1533e+00, 1.2032e+00, 2.2578e+00,\n",
       "         1.1680e+00, 1.0742e+00, 1.2881e+00, 1.2808e+00, 1.3027e+00, 1.1446e+00,\n",
       "         1.2920e+00, 1.5471e+00, 1.4432e+00, 1.2617e+00, 1.1531e+00, 1.5527e+00,\n",
       "         1.1369e+00, 1.5745e+00, 1.2476e+00, 1.4768e+00, 1.3202e+00, 1.2254e+00,\n",
       "         1.2874e+00, 2.2262e+00, 1.2796e+00, 1.3802e+00, 1.1289e+00, 1.4846e+00,\n",
       "         1.1908e+00, 1.3086e+00, 1.1986e+00, 1.1980e+00, 1.2156e+00, 1.6095e+00,\n",
       "         1.3010e+00, 1.4810e+00, 2.0002e+00, 1.0530e+00, 2.1401e+00, 1.1956e+00,\n",
       "         1.0898e+00, 1.1557e+00, 1.6530e+00, 1.1836e+00, 1.1818e+00, 1.1835e+00,\n",
       "         1.3206e+00, 3.3972e+00, 1.3472e+00, 1.2540e+00, 1.2671e+00, 1.2726e+00,\n",
       "         1.1836e+00, 1.4586e+00, 1.2540e+00, 1.1450e+00, 1.3078e+00, 1.1806e+00,\n",
       "         1.2149e+00, 1.2552e+00, 1.1542e+00, 1.1541e+00, 1.2383e+00, 1.3058e+00,\n",
       "         1.0963e+00, 1.1029e+00, 1.3066e+00, 1.7412e+00, 1.0508e+00, 1.5009e+00,\n",
       "         1.3564e+00, 1.0530e+01, 1.1796e+00, 1.1801e+00, 1.8887e+00, 1.4579e+00,\n",
       "         1.1528e+00, 6.6027e-01, 1.3696e+00, 1.0898e+00, 1.2464e+00, 1.2540e+00,\n",
       "         1.1379e+00, 1.3102e+00, 1.1453e+00, 1.2852e+00, 1.8692e+00, 1.1606e+00,\n",
       "         2.4319e+00, 1.4304e+00, 1.2322e+00, 1.2283e+00, 2.8226e+00, 1.3143e+00,\n",
       "         1.5046e+00, 1.3252e+00, 1.3366e+00, 1.1009e+00, 1.2071e+00, 1.3483e+00,\n",
       "         1.2312e+00, 1.3353e+00, 1.2706e+00, 1.2247e+00, 1.1510e+00, 1.1626e+00,\n",
       "         1.4471e+00, 1.8308e+00, 1.3415e+00, 1.1664e+00, 1.4809e+00, 1.1465e+00,\n",
       "         1.2681e+00, 2.1403e+00, 1.4574e+00, 1.1446e+00, 1.2617e+00, 1.4746e+00,\n",
       "         1.2107e+00, 1.3090e+00, 1.0051e+00, 1.2245e+00, 1.2793e+00, 1.3636e+00,\n",
       "         1.1871e+00, 1.3660e+00, 1.1758e+00, 1.4514e+00, 1.1525e+00, 1.1731e+00,\n",
       "         4.2194e+00, 1.1660e+00, 1.1625e+00, 1.1034e+00, 1.0980e+00, 1.2070e+00]),\n",
       " 'transformer.ln_f.bias': tensor([ 1.0872e-03,  3.6529e-02, -6.7296e-02,  1.6416e-04, -6.7444e-02,\n",
       "         -7.1351e-02,  5.0393e-01,  9.1723e-02, -4.9340e-02,  3.2622e-03,\n",
       "          4.5723e-02, -6.8674e-03,  2.4039e-02, -2.3481e-02, -1.6724e-02,\n",
       "         -1.7144e-02, -8.3718e-03, -3.1513e-02, -6.8601e-02, -2.3766e-01,\n",
       "          3.6237e-02,  1.6346e-02, -9.8507e-02, -2.1232e-03,  1.1982e-02,\n",
       "          2.8979e-02, -1.2852e-01, -1.5948e-02, -1.9886e-02, -5.3668e-02,\n",
       "          6.9403e-03, -7.6807e-03, -1.0904e-01, -1.9977e-02,  9.6084e-03,\n",
       "          1.0891e-01,  4.5043e+00, -2.6320e-02, -3.5563e-02,  6.8634e-02,\n",
       "         -2.6733e-02,  4.5381e-03, -7.6494e-02, -1.8627e-02,  2.7786e-04,\n",
       "          1.7049e-02,  1.5448e-02, -2.0069e-02, -9.4106e-02,  1.2935e-01,\n",
       "         -2.8602e-02,  1.7971e-02, -1.2255e-01, -6.0040e-02, -2.7152e-02,\n",
       "          2.0868e-01, -7.3314e-02, -1.8849e-02,  3.2550e-02, -1.0382e-01,\n",
       "          3.3463e-02, -5.7886e-02,  2.7034e-02, -1.6745e-01, -1.0472e+00,\n",
       "         -1.6542e-02, -5.1018e-02, -6.8653e-03, -2.1249e-01, -3.1209e-02,\n",
       "         -6.0667e-02,  8.7675e-04,  2.8659e-02, -2.4280e-02, -7.4334e-03,\n",
       "         -1.0984e-02, -9.6567e-02, -4.0275e-01,  3.5209e-02,  4.5582e-03,\n",
       "         -7.4472e-03, -1.4675e-02,  1.0423e-02, -7.6423e-02,  1.5722e-02,\n",
       "          2.2594e-02,  3.4847e-01, -9.9237e-01, -1.4573e-02,  4.1847e-02,\n",
       "         -5.6549e-02, -6.4195e-02, -7.8837e-02, -8.6063e-02, -1.1810e-02,\n",
       "          1.1617e-02, -4.3866e-03,  4.7045e-02,  1.4878e-02,  1.5424e-01,\n",
       "         -1.9613e-02, -1.0770e-01,  1.1270e-01, -6.4523e-03,  4.0445e-02,\n",
       "         -2.7771e-02, -1.7304e-02,  7.3762e-01, -2.5960e-02, -2.7389e-02,\n",
       "         -3.1064e-02,  1.5734e-02, -5.2281e-02,  4.1252e-02, -1.3316e-02,\n",
       "         -4.5049e-02, -1.8180e-03,  7.2320e-03,  1.3693e-02, -3.9412e-02,\n",
       "         -3.4724e-02,  5.1059e-02, -2.0570e-02, -2.1606e-02, -1.3500e-01,\n",
       "          5.4560e-02, -3.6672e-02,  2.2630e-02, -1.0954e-01, -1.3664e-02,\n",
       "          5.5158e-02,  2.8813e-02,  2.7308e-02, -5.6942e-02, -7.8654e-02,\n",
       "          2.3580e-03,  2.0007e-02, -5.7116e-02,  6.4764e-01,  1.0185e-01,\n",
       "         -6.1624e-02, -3.7634e-02, -3.9838e-01,  2.1430e-02, -1.8644e-02,\n",
       "          1.9693e-01,  2.2677e-02, -6.5989e-02, -4.3632e-02,  9.9600e-03,\n",
       "          2.4032e-02, -1.0095e-01, -4.6580e-02,  2.9137e-02, -5.9029e-02,\n",
       "         -3.2612e-02, -1.9738e-03,  2.4192e-03, -3.7447e-02, -3.0108e-02,\n",
       "         -6.3761e-02,  3.3632e-02, -1.8530e-02,  2.2146e-02, -6.4106e-02,\n",
       "          7.4832e-02, -9.5605e-02, -3.6251e-01, -3.0068e-02, -1.1445e-01,\n",
       "         -4.1705e-02, -7.9181e-02,  4.7085e-04,  8.2493e-02, -5.6607e-02,\n",
       "         -3.3807e-02, -2.8627e-01, -4.7230e-02, -1.1380e-01, -4.0840e-02,\n",
       "          5.7112e-03, -2.5453e-02,  6.4612e-02,  3.4492e-02,  2.0566e-02,\n",
       "         -4.5267e-02, -3.4678e-02, -7.2612e-03, -1.8908e-02,  5.7890e-02,\n",
       "         -4.2166e-02, -6.7557e-02,  5.6523e-02, -2.8467e-02,  3.5454e-02,\n",
       "          1.5290e-02,  1.2768e-02, -2.8542e-02,  2.3154e-02, -2.0937e-01,\n",
       "          4.4651e-02, -9.4332e-03, -1.6042e-02,  1.3285e-02, -1.3079e-02,\n",
       "          5.2382e-04,  1.3041e-02, -2.7098e-02,  4.4549e-02, -8.7790e-03,\n",
       "         -1.4647e-02,  9.1764e-02, -3.1280e-02,  2.3198e-01,  4.4123e-02,\n",
       "          1.4304e-02, -5.7298e-02,  7.8618e-03, -1.0237e-03,  2.8485e-02,\n",
       "          1.3268e-02, -9.5455e-03, -2.3109e-04, -2.0369e-02,  8.3394e-02,\n",
       "         -7.1135e-02, -6.4807e-02, -6.1181e-03,  4.6791e-02, -9.2088e-03,\n",
       "          3.4884e-02, -4.5029e-02,  2.7879e-01, -3.7818e-02, -5.4034e-02,\n",
       "         -6.1790e-02, -3.8778e-02,  4.9349e-03,  2.4378e-02,  8.9025e-03,\n",
       "         -3.5052e-03,  1.6581e-01,  5.8664e-02, -3.1299e-03,  2.7989e-02,\n",
       "          2.5872e-02, -1.1119e-02,  7.6097e-02, -2.2228e-02, -1.9689e-02,\n",
       "         -1.3784e-01, -6.6437e-02, -5.2913e-03,  1.7010e-03, -2.6449e-02,\n",
       "          1.1717e-01, -1.1523e-01,  7.0097e-02, -8.2283e-02,  6.1100e-02,\n",
       "         -1.2160e-02,  9.0952e-02,  7.5562e-03,  3.8820e-02,  1.9466e-02,\n",
       "         -6.4488e-02, -9.7399e-01,  1.0671e-03, -7.2186e-03,  8.7493e-02,\n",
       "         -1.1547e-01,  4.3738e-01,  5.4697e-03, -1.5715e-02,  2.8925e-02,\n",
       "         -3.3470e-02, -4.2125e-02,  1.2895e-02, -2.9777e-02, -1.7015e-02,\n",
       "         -2.2735e-02,  1.7061e-02,  4.9545e-02,  1.1104e-01, -5.8314e-03,\n",
       "          5.7407e-02, -2.2805e-02,  2.0941e-02, -3.5016e-01, -2.1634e-02,\n",
       "         -5.8145e-02, -2.1873e-02, -1.3668e-02,  1.2862e-02,  3.6718e-02,\n",
       "          5.1902e-03,  1.0907e-02, -7.8232e-03, -4.5908e-02, -1.7366e-02,\n",
       "         -2.8400e-02,  4.1859e-02, -1.0367e-01,  2.9875e-02, -4.3200e-02,\n",
       "         -2.7472e-02,  7.6173e-03, -7.8905e-03, -4.4235e-01, -2.4563e-02,\n",
       "         -1.7634e-02,  1.2442e-01,  3.7981e-02, -7.6377e-03, -4.1918e+00,\n",
       "         -5.0516e-02,  2.9369e-02, -9.7174e-03,  7.4856e-05,  3.8322e-02,\n",
       "         -2.1775e-01, -1.3928e-03, -4.3413e-02, -4.7812e-02,  1.0623e-02,\n",
       "         -5.4639e-02, -5.3187e-01, -2.2528e-02,  1.0735e-02,  7.7141e-03,\n",
       "         -1.1821e-03, -7.1923e-02, -6.6898e-02, -9.4570e-02,  1.8275e-02,\n",
       "         -5.6802e-03,  3.3925e-02, -6.8035e-03, -2.1191e-02, -3.3668e-02,\n",
       "         -4.5747e-02, -1.7164e-02, -6.4126e-02, -5.9322e-02,  6.6308e-03,\n",
       "         -5.7392e-02, -2.9224e-02, -1.0237e-01, -2.1006e-02,  3.7682e-02,\n",
       "         -8.3238e-03,  1.8629e-01, -3.0289e-02, -8.6108e-02, -3.3981e-02,\n",
       "         -1.6380e-03,  9.5645e-05,  1.8391e-02,  6.6154e-03, -2.5787e-02,\n",
       "         -5.4965e-02,  3.3532e-02,  7.6414e-02, -3.5418e-02,  1.5757e-04,\n",
       "         -4.9215e-01, -1.7935e-02, -4.2474e-02, -3.6654e-02,  3.7187e-03,\n",
       "          8.3721e-02, -7.3905e-02,  1.3349e-02, -8.1251e-01, -2.2964e+00,\n",
       "         -2.3672e-02, -8.1334e-02,  1.5086e-01, -7.6905e-02, -3.1052e-02,\n",
       "          2.1425e-02, -4.8389e-02, -1.4152e-02, -4.3935e-02, -3.7510e-02,\n",
       "         -1.1541e-01,  6.2883e-02, -1.7672e-02,  1.0962e-02, -2.6148e-01,\n",
       "          5.8860e-02,  4.1171e-02, -5.2769e-02, -5.3264e-01, -7.3070e-02,\n",
       "         -3.0272e-02, -3.3503e-02, -2.3348e-02,  1.6839e-02,  1.3835e-02,\n",
       "         -3.1535e-02, -1.2930e-01,  8.2034e-02, -1.7669e-02, -3.7012e-02,\n",
       "         -5.3559e-02, -8.0793e-02, -4.5030e-02,  5.8326e-01, -2.8019e-02,\n",
       "         -2.2854e-02, -2.9491e-02, -1.2646e-02, -1.9085e-02,  7.2778e-02,\n",
       "         -2.9988e-02, -4.3035e-03, -2.3171e-02, -2.9115e-02,  2.8318e-03,\n",
       "         -1.9056e-01, -3.6604e-02,  1.4934e-02, -7.2772e-02,  1.7382e-02,\n",
       "          1.3184e-02,  3.3194e-02,  1.2090e-02, -6.7826e-02, -4.2046e-02,\n",
       "          4.5765e+00,  3.8094e-02, -5.8475e-03, -3.3060e-02, -2.4420e-03,\n",
       "          7.0572e-02, -8.5184e-03, -4.7140e-02, -3.5492e-02,  1.3906e-01,\n",
       "          9.6806e-03,  3.7759e-03,  1.5214e+00,  1.5772e-02, -2.0146e-03,\n",
       "          1.9806e-04, -2.5916e-02,  7.4553e-01,  2.2555e-02,  3.9150e-02,\n",
       "         -4.0612e-02, -6.6488e-02, -1.4694e-02, -1.8814e-01, -2.5680e-02,\n",
       "          2.7539e-01, -8.6698e-02, -5.4068e-02, -3.7796e-02,  1.7496e-01,\n",
       "          1.0016e-01,  1.8288e-02,  1.9015e-02, -4.9247e-02, -1.1344e-01,\n",
       "          3.2417e-03,  1.5069e-02, -2.3991e-02,  1.1169e-02,  5.5201e-02,\n",
       "          6.8813e-02,  1.5437e-02,  1.4457e-02,  3.6382e-02,  3.3006e-02,\n",
       "          1.6601e-03,  3.5841e-02,  2.3049e-02, -3.7833e-02, -8.8917e-01,\n",
       "         -8.5626e-01,  7.6501e-01, -1.6650e-02,  5.3425e-03, -2.0975e-02,\n",
       "         -2.0985e-02, -2.5421e-02,  1.1607e-03, -2.5669e-02,  1.1613e-04,\n",
       "         -2.6443e-02, -1.2821e-02, -1.1060e-02, -6.4586e-02, -1.6700e-03,\n",
       "          6.0491e-02,  7.3683e+00, -6.0230e-02, -2.9137e-02, -1.2580e-02,\n",
       "         -5.3060e-02, -1.8582e-02, -1.7887e-02, -2.9617e-01,  8.0085e-02,\n",
       "          5.4053e-02, -2.8139e-02, -8.7857e-03,  1.0940e-02, -1.9958e-02,\n",
       "         -3.9983e-02, -2.5002e-01,  9.0808e-02, -2.3754e-03,  4.6434e-03,\n",
       "         -6.0453e-02,  6.9979e-03, -3.8280e-02, -5.8416e-02, -1.8324e-02,\n",
       "         -2.6310e-02,  8.2354e-02,  8.0878e-03, -6.1616e-02, -4.6368e-02,\n",
       "         -1.1206e-01,  2.2739e-01, -1.9157e-01, -2.8906e-02,  3.9452e-03,\n",
       "          1.5285e-02, -8.9685e-03, -4.1765e-02,  2.6316e-02, -4.1366e-02,\n",
       "         -6.1208e-03, -1.0726e-02, -5.3724e-02, -1.1064e-02,  5.4608e-02,\n",
       "          1.2026e-01, -5.9791e-02, -1.1439e-02, -3.0206e-01, -6.6082e-03,\n",
       "          7.5021e-02,  3.3470e-02,  3.1955e-02, -8.9656e-03, -2.4131e-02,\n",
       "          2.0099e-02,  1.7902e-01, -4.7128e-02,  3.5336e-02, -5.9965e-02,\n",
       "         -1.0729e-02,  2.5535e-02, -3.2598e-02, -1.1571e-02,  3.9279e-03,\n",
       "         -4.6097e-02, -1.0125e-02, -2.5468e-02, -5.3132e-02,  1.0430e-03,\n",
       "         -5.7897e-02,  1.1562e-01,  1.6695e-02, -9.3858e-03, -1.0967e-01,\n",
       "          1.1385e-01, -1.2587e-02, -2.9855e-02,  6.6515e-03,  1.1277e-03,\n",
       "         -8.8445e-02,  3.5600e-02, -4.7699e-02, -6.5989e-03, -2.5376e-02,\n",
       "         -5.9169e-02, -2.6125e-02,  3.5664e-02,  4.2330e-02, -2.8365e-02,\n",
       "         -1.1422e-01, -1.2717e-02, -5.4891e-02,  2.6614e-02, -2.0510e-02,\n",
       "         -4.0455e-02,  2.5847e-02,  1.8912e-02,  3.9873e-03,  1.2472e-02,\n",
       "         -1.5778e-02, -4.3945e-02, -3.9807e-02,  4.9368e-02, -3.4811e-02,\n",
       "         -3.6738e-02,  6.0444e-02, -3.1983e-02,  2.1002e-02,  5.9787e-02,\n",
       "         -5.9418e-02, -5.6518e-02, -1.9562e-02, -1.0192e-01, -7.3266e-02,\n",
       "          6.0253e-03, -1.2703e-03, -1.7658e-02, -1.7046e-04, -2.2049e-02,\n",
       "         -4.4822e-02, -3.0320e-02,  6.1333e-03, -7.3983e-02, -3.9071e-02,\n",
       "          7.1127e-02, -1.9383e-02,  8.1372e-02, -3.7656e-02, -3.9241e-02,\n",
       "          1.1307e-02,  1.9240e-02, -5.2134e-01, -5.7102e-02,  1.2872e-02,\n",
       "          2.6437e-02, -2.4696e-02, -9.5752e-04, -2.9517e-03, -4.0031e-02,\n",
       "         -2.6403e-01, -1.8459e-02, -4.3772e-02, -6.4264e-02,  6.2169e-04,\n",
       "         -4.2976e-01, -5.2110e-02, -2.7672e-02, -1.3235e-01, -2.0824e-02,\n",
       "         -2.6675e-02, -2.9728e-02,  4.1735e-02,  1.0057e-02,  5.2260e-02,\n",
       "         -7.4459e-02, -2.1856e-02, -1.4217e-02, -6.5240e-02, -2.2235e-02,\n",
       "          1.6941e-01, -9.0145e-03,  2.4160e-02, -2.9787e-02,  1.4448e-01,\n",
       "          1.9557e-02, -5.5833e-03, -5.0508e-02,  3.8701e-02, -2.9668e-02,\n",
       "          3.1690e-02, -6.8745e-03, -1.9214e-02,  2.6903e-01, -7.6019e-03,\n",
       "         -1.5625e-01, -2.6517e-02, -4.4908e-03, -3.7796e-02, -2.0304e-01,\n",
       "         -4.0343e-02, -2.9758e-02,  3.2639e-02,  6.7867e-02,  2.9190e-02,\n",
       "         -8.3563e-02, -7.6448e-02, -7.0672e-02,  9.8573e-03,  3.5905e-02,\n",
       "          4.4131e-02, -5.1119e-03, -1.0302e-02,  1.4177e-02,  1.2777e-02,\n",
       "          4.4026e-02,  2.6884e-02,  5.4663e-02, -5.9550e-02,  2.1386e-03,\n",
       "         -6.3401e-02, -4.6159e-02,  1.7755e-02,  9.3017e-03, -1.3974e-02,\n",
       "         -2.5991e-02,  6.9902e-02, -2.0447e-02, -8.0996e-01, -7.3992e-03,\n",
       "         -6.9028e-02, -2.3947e-01, -1.0159e-01, -3.5832e-02, -1.9236e-01,\n",
       "         -4.7394e-02, -1.6717e-03,  5.3983e-02,  1.0544e-02,  1.4304e-02,\n",
       "         -4.8561e-02, -4.2476e-02, -8.7717e-04,  1.4124e-01,  9.4687e-04,\n",
       "         -4.8157e-02, -1.1013e-01, -4.4088e-02, -4.0713e-02, -5.9785e-02,\n",
       "         -1.6111e-02,  8.9078e-02, -4.9754e-02, -6.3769e-02,  1.4608e-02,\n",
       "         -4.4700e-02,  1.0339e-02,  3.8344e-02,  5.5821e-02, -4.3954e-02,\n",
       "          4.0682e-02,  1.2429e-02,  1.1265e-03, -9.7955e-02, -3.3169e-02,\n",
       "         -5.4159e-02, -6.5162e-02, -6.4554e-02,  3.4367e-02, -5.5316e-02,\n",
       "          1.6239e-01, -9.1327e-03,  2.1942e-02,  1.7757e-03, -7.4256e-02,\n",
       "          2.2889e-02, -9.6414e-02, -2.9426e-02,  2.1863e-02, -2.4523e-02,\n",
       "          5.9060e-02,  2.9360e-01,  6.2494e-02,  3.8487e-04,  9.1539e-02,\n",
       "          3.1131e-02,  3.3019e-03,  4.5760e-01, -5.7599e-02,  3.4124e-02,\n",
       "         -1.0095e-02, -2.5538e-02,  3.4450e-02])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a608bba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.transformer.h.9': GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'model.transformer.h.10': GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'model.transformer.ln_f': LayerNorm((768,), eps=1e-05, elementwise_affine=True)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "533af3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_layers = []\n",
    "final_layers = []\n",
    "for i in out_layers:\n",
    "   final_layers.append(out_layers[i])\n",
    "final_model = torch.nn.ModuleList(final_layers)\n",
    "\n",
    "loaded_model = final_model.load_state_dict(stage_sd, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ca33386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-1): 2 x GPT2Block(\n",
       "    (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (attn): GPT2Attention(\n",
       "      (c_attn): Conv1D(nf=2304, nx=768)\n",
       "      (c_proj): Conv1D(nf=768, nx=768)\n",
       "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): GPT2MLP(\n",
       "      (c_fc): Conv1D(nf=3072, nx=768)\n",
       "      (c_proj): Conv1D(nf=768, nx=3072)\n",
       "      (act): NewGELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8dcabd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['0.ln_1.weight', '0.ln_1.bias', '0.attn.c_attn.weight', '0.attn.c_attn.bias', '0.attn.c_proj.weight', '0.attn.c_proj.bias', '0.ln_2.weight', '0.ln_2.bias', '0.mlp.c_fc.weight', '0.mlp.c_fc.bias', '0.mlp.c_proj.weight', '0.mlp.c_proj.bias', '1.ln_1.weight', '1.ln_1.bias', '1.attn.c_attn.weight', '1.attn.c_attn.bias', '1.attn.c_proj.weight', '1.attn.c_proj.bias', '1.ln_2.weight', '1.ln_2.bias', '1.mlp.c_fc.weight', '1.mlp.c_fc.bias', '1.mlp.c_proj.weight', '1.mlp.c_proj.bias', '2.weight', '2.bias'], unexpected_keys=['transformer.h.9.ln_1.weight', 'transformer.h.9.ln_1.bias', 'transformer.h.9.attn.c_attn.weight', 'transformer.h.9.attn.c_attn.bias', 'transformer.h.9.attn.c_proj.weight', 'transformer.h.9.attn.c_proj.bias', 'transformer.h.9.ln_2.weight', 'transformer.h.9.ln_2.bias', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.10.ln_1.weight', 'transformer.h.10.ln_1.bias', 'transformer.h.10.attn.c_attn.weight', 'transformer.h.10.attn.c_attn.bias', 'transformer.h.10.attn.c_proj.weight', 'transformer.h.10.attn.c_proj.bias', 'transformer.h.10.ln_2.weight', 'transformer.h.10.ln_2.bias', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.10.mlp.c_proj.bias', 'transformer.ln_f.weight', 'transformer.ln_f.bias'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6464b434",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Build mapping for layers\u001b[39;00m\n\u001b[1;32m      8\u001b[0m modulelist_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[43mout_layers\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m layer_name:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# Extract original layer number (e.g., 'model.transformer.h.9' -> 9)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         original_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(layer_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_layers' is not defined"
     ]
    }
   ],
   "source": [
    "# When building the state dict, remap the keys to match ModuleList indexing\n",
    "from safetensors import safe_open\n",
    "\n",
    "# stage_sd = {}\n",
    "layer_mapping = {}  # Map original layer index to new ModuleList index\n",
    "out_layers = \n",
    "# Build mapping for layers\n",
    "modulelist_idx = 0\n",
    "for layer_name, layer in out_layers.items():\n",
    "    if 'h.' in layer_name:\n",
    "        # Extract original layer number (e.g., 'model.transformer.h.9' -> 9)\n",
    "        original_idx = int(layer_name.split('h.')[1])\n",
    "        layer_mapping[original_idx] = modulelist_idx\n",
    "        modulelist_idx += 1\n",
    "    elif 'ln_f' in layer_name:\n",
    "        # ln_f is the last layer in ModuleList\n",
    "        layer_mapping['ln_f'] = modulelist_idx\n",
    "    elif 'wte' in layer_name:\n",
    "        layer_mapping['wte'] = modulelist_idx\n",
    "    elif 'wpe' in layer_name:\n",
    "        layer_mapping['wpe'] = modulelist_idx\n",
    "        \n",
    "# Load weights with remapped keys\n",
    "with safe_open(\"../../../data/model.safetensors\", framework=\"pt\") as f:\n",
    "    for k in results:\n",
    "        for key in f.keys():\n",
    "            if k == key:\n",
    "                # Remap the key to match ModuleList indexing\n",
    "                if 'h.' in k:\n",
    "                    original_idx = int(k.split('h.')[1].split('.')[0])\n",
    "                    new_idx = layer_mapping[original_idx]\n",
    "                    # Replace h.9 with 0, h.10 with 1, etc.\n",
    "                    new_key = k.replace(f'h.{original_idx}', str(new_idx))\n",
    "                elif 'ln_f' in k:\n",
    "                    new_key = k.replace('ln_f', str(layer_mapping['ln_f']))\n",
    "                else:\n",
    "                    new_key = k\n",
    "                \n",
    "                stage_sd[new_key] = f.get_tensor(k)\n",
    "\n",
    "# Now load into ModuleList\n",
    "final_layers = list(out_layers.values())\n",
    "final_model = torch.nn.ModuleList(final_layers)\n",
    "loaded_model = final_model.load_state_dict(stage_sd, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0653a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4196eadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-1): 2 x GPT2Block(\n",
       "    (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (attn): GPT2Attention(\n",
       "      (c_attn): Conv1D(nf=2304, nx=768)\n",
       "      (c_proj): Conv1D(nf=768, nx=768)\n",
       "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): GPT2MLP(\n",
       "      (c_fc): Conv1D(nf=3072, nx=768)\n",
       "      (c_proj): Conv1D(nf=768, nx=3072)\n",
       "      (act): NewGELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (3): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "71f6b4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['3.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_head = torch.nn.Linear(768, 50257, bias=False)\n",
    "\n",
    "for module in hollo_modelA:\n",
    "    if isinstance(module, torch.nn.Embedding):\n",
    "        lm_head.weight = module.weight\n",
    "        break\n",
    "    \n",
    "_modelA = torch.nn.ModuleList(list(hollo_modelA) + [lm_head])\n",
    "_modelA.load_state_dict(loaded_modelA, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2e979633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model.transformer.h.6': GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "), 'model.transformer.h.7': GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "modelB = get_model_per_node(config, model, num_nodes=4, local_rank=2, model_name='causal_gpt2', weights_path=\"../../../data/model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b3ef41a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-1): 2 x GPT2Block(\n",
       "    (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (attn): GPT2Attention(\n",
       "      (c_attn): Conv1D(nf=2304, nx=768)\n",
       "      (c_proj): Conv1D(nf=768, nx=768)\n",
       "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): GPT2MLP(\n",
       "      (c_fc): Conv1D(nf=3072, nx=768)\n",
       "      (c_proj): Conv1D(nf=768, nx=3072)\n",
       "      (act): NewGELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8143e901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model.transformer.h.3': GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "), 'model.transformer.h.4': GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "modelC = get_model_per_node(config, model, num_nodes=4, local_rank=1, model_name='causal_gpt2', weights_path=\"../../../data/model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6ba0d166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-1): 2 x GPT2Block(\n",
       "    (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (attn): GPT2Attention(\n",
       "      (c_attn): Conv1D(nf=2304, nx=768)\n",
       "      (c_proj): Conv1D(nf=768, nx=768)\n",
       "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): GPT2MLP(\n",
       "      (c_fc): Conv1D(nf=3072, nx=768)\n",
       "      (c_proj): Conv1D(nf=768, nx=3072)\n",
       "      (act): NewGELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1f77cbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model.transformer.wte': Embedding(50257, 768), 'model.transformer.wpe': Embedding(1024, 768)}\n"
     ]
    }
   ],
   "source": [
    "modelD = get_model_per_node(config, model, num_nodes=4, local_rank=0, model_name='causal_gpt2', weights_path=\"../../../data/model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "30f913fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(50257, 768)\n",
       "  (1): Embedding(1024, 768)\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ae1dce9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17250,   616,  1438,   318,   220]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "text = 'Hi my name is '\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4f9f4b1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "layer_norm(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m out\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m modelC:\n\u001b[0;32m----> 7\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/trainLLM/lib/python3.10/site-packages/transformers/modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/trainLLM/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/trainLLM/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/trainLLM/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/trainLLM/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:413\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, past_key_values, cache_position, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_value\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.58\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    411\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor], Optional[\u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mFloatTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]]:\n\u001b[1;32m    412\u001b[0m     residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 413\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m     attn_output, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\n\u001b[1;32m    415\u001b[0m         hidden_states,\n\u001b[1;32m    416\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    423\u001b[0m     )\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;66;03m# residual connection\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/trainLLM/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/trainLLM/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/trainLLM/lib/python3.10/site-packages/torch/nn/modules/normalization.py:217\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/trainLLM/lib/python3.10/site-packages/torch/nn/functional.py:2905\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2897\u001b[0m         layer_norm,\n\u001b[1;32m   2898\u001b[0m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2903\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2904\u001b[0m     )\n\u001b[0;32m-> 2905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2906\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2907\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: layer_norm(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "x = modelD[0](inputs['input_ids'])\n",
    "pos_embeds = torch.arange(x.shape[1], dtype=torch.long)\n",
    "out = modelD[1](pos_embeds)\n",
    "x = x + out\n",
    "\n",
    "for layer in modelC:\n",
    "    x = layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f6033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify weights are loaded\n",
    "for name, param in modelD.named_parameters():\n",
    "    print(f\"{name}: shape={param.shape}, mean={param.mean():.4f}, std={param.std():.4f}\")\n",
    "    break  # Just show first param to verify it's not random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030052e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
