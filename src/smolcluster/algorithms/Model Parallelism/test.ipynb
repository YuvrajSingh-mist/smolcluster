{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89dfafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08a02456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "857b92d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.n_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5d2015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a7984e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcdbe27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Block(\n",
       "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (attn): GPT2Attention(\n",
       "    (c_attn): Conv1D(nf=2304, nx=768)\n",
       "    (c_proj): Conv1D(nf=768, nx=768)\n",
       "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (mlp): GPT2MLP(\n",
       "    (c_fc): Conv1D(nf=3072, nx=768)\n",
       "    (c_proj): Conv1D(nf=768, nx=3072)\n",
       "    (act): NewGELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.h[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file\n",
    "\n",
    "state_dict = load_file(\"../../../data/model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49978696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h.0.attn.bias\n",
      "h.0.attn.c_attn.bias\n",
      "h.0.attn.c_attn.weight\n",
      "h.0.attn.c_proj.bias\n",
      "h.0.attn.c_proj.weight\n",
      "h.0.ln_1.bias\n",
      "h.0.ln_1.weight\n",
      "h.0.ln_2.bias\n",
      "h.0.ln_2.weight\n",
      "h.0.mlp.c_fc.bias\n",
      "h.0.mlp.c_fc.weight\n",
      "h.0.mlp.c_proj.bias\n",
      "h.0.mlp.c_proj.weight\n",
      "h.1.attn.bias\n",
      "h.1.attn.c_attn.bias\n",
      "h.1.attn.c_attn.weight\n",
      "h.1.attn.c_proj.bias\n",
      "h.1.attn.c_proj.weight\n",
      "h.1.ln_1.bias\n",
      "h.1.ln_1.weight\n",
      "h.1.ln_2.bias\n",
      "h.1.ln_2.weight\n",
      "h.1.mlp.c_fc.bias\n",
      "h.1.mlp.c_fc.weight\n",
      "h.1.mlp.c_proj.bias\n",
      "h.1.mlp.c_proj.weight\n",
      "h.10.attn.bias\n",
      "h.10.attn.c_attn.bias\n",
      "h.10.attn.c_attn.weight\n",
      "h.10.attn.c_proj.bias\n",
      "h.10.attn.c_proj.weight\n",
      "h.10.ln_1.bias\n",
      "h.10.ln_1.weight\n",
      "h.10.ln_2.bias\n",
      "h.10.ln_2.weight\n",
      "h.10.mlp.c_fc.bias\n",
      "h.10.mlp.c_fc.weight\n",
      "h.10.mlp.c_proj.bias\n",
      "h.10.mlp.c_proj.weight\n",
      "h.11.attn.bias\n",
      "h.11.attn.c_attn.bias\n",
      "h.11.attn.c_attn.weight\n",
      "h.11.attn.c_proj.bias\n",
      "h.11.attn.c_proj.weight\n",
      "h.11.ln_1.bias\n",
      "h.11.ln_1.weight\n",
      "h.11.ln_2.bias\n",
      "h.11.ln_2.weight\n",
      "h.11.mlp.c_fc.bias\n",
      "h.11.mlp.c_fc.weight\n",
      "h.11.mlp.c_proj.bias\n",
      "h.11.mlp.c_proj.weight\n",
      "h.2.attn.bias\n",
      "h.2.attn.c_attn.bias\n",
      "h.2.attn.c_attn.weight\n",
      "h.2.attn.c_proj.bias\n",
      "h.2.attn.c_proj.weight\n",
      "h.2.ln_1.bias\n",
      "h.2.ln_1.weight\n",
      "h.2.ln_2.bias\n",
      "h.2.ln_2.weight\n",
      "h.2.mlp.c_fc.bias\n",
      "h.2.mlp.c_fc.weight\n",
      "h.2.mlp.c_proj.bias\n",
      "h.2.mlp.c_proj.weight\n",
      "h.3.attn.bias\n",
      "h.3.attn.c_attn.bias\n",
      "h.3.attn.c_attn.weight\n",
      "h.3.attn.c_proj.bias\n",
      "h.3.attn.c_proj.weight\n",
      "h.3.ln_1.bias\n",
      "h.3.ln_1.weight\n",
      "h.3.ln_2.bias\n",
      "h.3.ln_2.weight\n",
      "h.3.mlp.c_fc.bias\n",
      "h.3.mlp.c_fc.weight\n",
      "h.3.mlp.c_proj.bias\n",
      "h.3.mlp.c_proj.weight\n",
      "h.4.attn.bias\n",
      "h.4.attn.c_attn.bias\n",
      "h.4.attn.c_attn.weight\n",
      "h.4.attn.c_proj.bias\n",
      "h.4.attn.c_proj.weight\n",
      "h.4.ln_1.bias\n",
      "h.4.ln_1.weight\n",
      "h.4.ln_2.bias\n",
      "h.4.ln_2.weight\n",
      "h.4.mlp.c_fc.bias\n",
      "h.4.mlp.c_fc.weight\n",
      "h.4.mlp.c_proj.bias\n",
      "h.4.mlp.c_proj.weight\n",
      "h.5.attn.bias\n",
      "h.5.attn.c_attn.bias\n",
      "h.5.attn.c_attn.weight\n",
      "h.5.attn.c_proj.bias\n",
      "h.5.attn.c_proj.weight\n",
      "h.5.ln_1.bias\n",
      "h.5.ln_1.weight\n",
      "h.5.ln_2.bias\n",
      "h.5.ln_2.weight\n",
      "h.5.mlp.c_fc.bias\n",
      "h.5.mlp.c_fc.weight\n",
      "h.5.mlp.c_proj.bias\n",
      "h.5.mlp.c_proj.weight\n",
      "h.6.attn.bias\n",
      "h.6.attn.c_attn.bias\n",
      "h.6.attn.c_attn.weight\n",
      "h.6.attn.c_proj.bias\n",
      "h.6.attn.c_proj.weight\n",
      "h.6.ln_1.bias\n",
      "h.6.ln_1.weight\n",
      "h.6.ln_2.bias\n",
      "h.6.ln_2.weight\n",
      "h.6.mlp.c_fc.bias\n",
      "h.6.mlp.c_fc.weight\n",
      "h.6.mlp.c_proj.bias\n",
      "h.6.mlp.c_proj.weight\n",
      "h.7.attn.bias\n",
      "h.7.attn.c_attn.bias\n",
      "h.7.attn.c_attn.weight\n",
      "h.7.attn.c_proj.bias\n",
      "h.7.attn.c_proj.weight\n",
      "h.7.ln_1.bias\n",
      "h.7.ln_1.weight\n",
      "h.7.ln_2.bias\n",
      "h.7.ln_2.weight\n",
      "h.7.mlp.c_fc.bias\n",
      "h.7.mlp.c_fc.weight\n",
      "h.7.mlp.c_proj.bias\n",
      "h.7.mlp.c_proj.weight\n",
      "h.8.attn.bias\n",
      "h.8.attn.c_attn.bias\n",
      "h.8.attn.c_attn.weight\n",
      "h.8.attn.c_proj.bias\n",
      "h.8.attn.c_proj.weight\n",
      "h.8.ln_1.bias\n",
      "h.8.ln_1.weight\n",
      "h.8.ln_2.bias\n",
      "h.8.ln_2.weight\n",
      "h.8.mlp.c_fc.bias\n",
      "h.8.mlp.c_fc.weight\n",
      "h.8.mlp.c_proj.bias\n",
      "h.8.mlp.c_proj.weight\n",
      "h.9.attn.bias\n",
      "h.9.attn.c_attn.bias\n",
      "h.9.attn.c_attn.weight\n",
      "h.9.attn.c_proj.bias\n",
      "h.9.attn.c_proj.weight\n",
      "h.9.ln_1.bias\n",
      "h.9.ln_1.weight\n",
      "h.9.ln_2.bias\n",
      "h.9.ln_2.weight\n",
      "h.9.mlp.c_fc.bias\n",
      "h.9.mlp.c_fc.weight\n",
      "h.9.mlp.c_proj.bias\n",
      "h.9.mlp.c_proj.weight\n",
      "ln_f.bias\n",
      "ln_f.weight\n",
      "wpe.weight\n",
      "wte.weight\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "stage_sd = {}\n",
    "owm_key = [model.transformer.h[0], model.transformer.h[1], model.transformer.ln_f]\n",
    "with safe_open(\"../../../data/model.safetensors\", framework=\"pt\") as f:\n",
    "    for k in f.keys():\n",
    "        print(k)\n",
    "        # if owns_key(k):\n",
    "        #     stage_sd[k] = f.get_tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f07bde17",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "for layer in model.transformer.h:\n",
    "            layers.append(layer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5543e53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " GPT2Block(\n",
       "   (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): GPT2Attention(\n",
       "     (c_attn): Conv1D(nf=2304, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=768)\n",
       "     (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): GPT2MLP(\n",
       "     (c_fc): Conv1D(nf=3072, nx=768)\n",
       "     (c_proj): Conv1D(nf=768, nx=3072)\n",
       "     (act): NewGELUActivation()\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6330b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_per_node = 6\n",
    "local_rank = 0\n",
    "out_layers = layers[layers_per_node * local_rank : ((layers_per_node * local_rank) + layers_per_node) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa1ea45",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mout_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.transformer.h.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "from typing import List\n",
    "import torch\n",
    "\n",
    "def get_layers_per_node(config: AutoConfig, model, num_nodes: int, local_rank: int, model_name: str) -> List:\n",
    "    \n",
    "    out_layers = {}\n",
    "    \n",
    "    if model_name == 'causal_gpt2':\n",
    "        \n",
    "        total_layers = config.n_layer\n",
    "        \n",
    "        layers_per_node = total_layers // num_nodes\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        for layer in model.transformer.h:\n",
    "            layers.append(layer)     \n",
    "            \n",
    "        if local_rank == 0:\n",
    "            out_layers['model.transformer.wte'] = model.transformer.wte\n",
    "            out_layers['model.transformer.wpe'] = model.transformer.wpe\n",
    "   \n",
    "        \n",
    "        elif local_rank == num_nodes - 1:\n",
    "            selected_layers = layers[layers_per_node * local_rank : ((layers_per_node * local_rank) + layers_per_node) - 1]\n",
    "            \n",
    "            for layer in selected_layers:\n",
    "                out_layers[f'model.transformer.h.{layers.index(layer)}'] = layer\n",
    "                \n",
    "            out_layers['model.transformer.ln_f'] = model.transformer.ln_f   \n",
    "        \n",
    "        \n",
    "        else:\n",
    "            selected_layers = layers[layers_per_node * local_rank : ((layers_per_node * local_rank) + layers_per_node) - 1]\n",
    "            \n",
    "            for layer in selected_layers:\n",
    "                out_layers[f'model.transformer.h.{layers.index(layer)}'] = layer\n",
    "        \n",
    "        return out_layers\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71a0b21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_layers = get_layers_per_node(config, model, num_nodes=4, local_rank=3, model_name='causal_gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13f48c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_layers\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b369a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in out_layers['model.transformer.h.10'].named_parameters():\n",
    "    results.append('h.10.' + i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29f0213d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h.10.ln_1.weight',\n",
       " 'h.10.ln_1.bias',\n",
       " 'h.10.attn.c_attn.weight',\n",
       " 'h.10.attn.c_attn.bias',\n",
       " 'h.10.attn.c_proj.weight',\n",
       " 'h.10.attn.c_proj.bias',\n",
       " 'h.10.ln_2.weight',\n",
       " 'h.10.ln_2.bias',\n",
       " 'h.10.mlp.c_fc.weight',\n",
       " 'h.10.mlp.c_fc.bias',\n",
       " 'h.10.mlp.c_proj.weight',\n",
       " 'h.10.mlp.c_proj.bias']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "73da9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "stage_sd = {}\n",
    "with safe_open(\"../../../data/model.safetensors\", framework=\"pt\") as f:\n",
    "    for k in f.keys():\n",
    "        \n",
    "        if k in results:\n",
    "            stage_sd[k] = f.get_tensor(k)\n",
    "        #     stage_sd[k] = f.get_tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "31a4314f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h.10.attn.c_attn.bias': tensor([-0.0301,  0.1360, -0.3842,  ..., -0.0599,  0.1059,  0.0276]),\n",
       " 'h.10.attn.c_attn.weight': tensor([[ 0.2200,  0.2637,  0.0422,  ...,  0.1725,  0.3419,  0.0662],\n",
       "         [-0.1269, -0.0215, -0.0951,  ..., -0.0543, -0.2407, -0.0239],\n",
       "         [ 0.0709, -0.0726, -0.0253,  ...,  0.2005, -0.0454,  0.0693],\n",
       "         ...,\n",
       "         [ 0.0642, -0.0317,  0.1332,  ..., -0.1037,  0.2958,  0.0867],\n",
       "         [-0.1892, -0.1039,  0.0752,  ..., -0.0223,  0.0835, -0.0417],\n",
       "         [ 0.1380,  0.1194, -0.1244,  ..., -0.2325, -0.0402, -0.0117]]),\n",
       " 'h.10.attn.c_proj.bias': tensor([-1.2379e-02,  1.4348e-02, -4.4527e-03, -4.5073e-02, -1.2405e-02,\n",
       "          8.0911e-02,  1.5559e-01,  5.4038e-02,  6.7509e-02,  3.0687e-02,\n",
       "          3.0247e-01, -9.8182e-03,  8.1174e-02, -1.7205e-01,  5.2295e-02,\n",
       "          1.3546e-01, -2.1004e-01, -2.1952e-01,  4.9703e-02,  2.3138e-02,\n",
       "          2.2932e-02,  2.2249e-03, -7.0906e-02, -3.5156e-02,  2.0411e-01,\n",
       "         -1.2486e-01,  1.3384e-01, -1.9214e-01,  1.9044e-02,  5.3139e-02,\n",
       "          4.9103e-02, -1.6615e-01, -7.5499e-02, -5.3073e-02, -2.0856e-02,\n",
       "         -1.9295e-01,  2.2115e-01, -1.9902e-01, -1.3765e-01,  1.6515e-01,\n",
       "          1.0707e-02, -7.1831e-02, -1.4753e-01, -5.0490e-03,  1.0966e-01,\n",
       "          2.3185e-01,  1.3112e-02, -3.1720e-02, -2.3691e-02,  1.8010e-01,\n",
       "          1.8339e-02,  9.8531e-02, -1.4694e-01,  2.2167e-01,  1.2269e-01,\n",
       "          9.8755e-02,  2.4772e-01, -1.0158e-01,  1.1977e-01,  3.5989e-02,\n",
       "         -2.9133e-02,  1.5159e-01, -1.1415e-01,  1.8912e-01, -3.2423e-01,\n",
       "         -6.3471e-03,  1.6377e-01,  1.2220e-01, -8.6118e-02, -1.3037e-02,\n",
       "         -5.2970e-02, -1.0829e-01, -1.8177e-01,  4.8571e-03, -6.8857e-02,\n",
       "          1.1943e-02, -5.5937e-02,  7.0200e-03,  1.0460e-01,  1.6986e-01,\n",
       "          3.8501e-02, -9.4758e-02, -1.2970e-01, -6.8998e-02,  2.8991e-02,\n",
       "         -1.7656e-02, -2.3231e-01, -8.2934e-01,  1.1315e-01, -1.6878e-01,\n",
       "         -3.1707e-02,  1.0165e-01, -3.6213e-02,  6.3447e-02, -8.6974e-02,\n",
       "         -6.0940e-03,  1.4906e-01, -5.0091e-02, -2.1105e-01,  6.6510e-02,\n",
       "          2.8093e-02,  1.1587e-01,  1.9580e-01, -1.6246e-01,  1.3696e-01,\n",
       "          1.2521e-01,  3.3358e-02,  1.4560e-01,  1.2057e-01, -2.6127e-01,\n",
       "         -1.1684e-01, -1.4144e-01,  6.9537e-02, -2.9555e-01,  7.2843e-02,\n",
       "          6.6022e-02, -2.3665e-02,  2.7204e-01, -1.1845e-01,  1.0308e-01,\n",
       "         -7.6212e-02,  7.3581e-02,  1.7829e-01,  3.0658e-01,  7.5543e-02,\n",
       "         -2.3775e-01,  1.6170e-01,  2.6796e-03,  7.2205e-02,  3.4932e-02,\n",
       "          8.4839e-02, -3.6620e-02, -5.3438e-02,  5.1749e-02, -1.1686e-01,\n",
       "          1.7398e-01, -2.4470e-01, -8.3547e-02, -3.4163e-01,  1.8377e-02,\n",
       "         -5.8818e-02,  4.8629e-02, -2.3429e-01, -9.5695e-02, -4.4188e-02,\n",
       "          2.9766e-02,  2.6909e-01, -2.1946e-03,  1.6594e-01,  6.6815e-02,\n",
       "         -1.6380e-02,  6.0249e-02, -3.1730e-01, -1.3451e-01, -1.0723e-01,\n",
       "          1.1293e-01, -1.7714e-01, -5.2138e-02, -2.5410e-01,  1.0667e-01,\n",
       "          3.1836e-01, -9.3654e-02,  1.2745e-01,  1.7573e-02, -2.3658e-01,\n",
       "         -7.7755e-02, -9.6747e-02, -1.2382e-01, -2.3488e-01, -2.1386e-01,\n",
       "         -1.1236e-01,  1.6579e-02, -4.6551e-02,  2.0709e-01, -2.9475e-02,\n",
       "          9.7892e-02, -6.1209e-02,  3.5287e-02,  3.5706e-02,  1.8173e-01,\n",
       "         -1.1351e-01,  1.9125e-01, -3.7715e-02,  3.8817e-02,  1.3485e-01,\n",
       "          9.9754e-02,  7.3885e-02,  5.5447e-02,  4.0234e-03,  1.6806e-01,\n",
       "          3.4928e-02,  7.2623e-02, -8.7083e-02, -8.3372e-02, -1.8134e-01,\n",
       "         -5.7460e-02,  1.2240e-01, -1.8635e-01, -2.3672e-01, -1.9521e-01,\n",
       "         -6.1426e-02,  2.4562e-01, -6.4236e-02, -5.1840e-02,  9.9109e-02,\n",
       "         -1.0095e-01, -6.6365e-02,  3.0682e-02, -1.1143e-01,  2.7270e-01,\n",
       "          1.6731e-01,  4.0085e-02, -8.9662e-02, -2.2507e-01, -1.5903e-01,\n",
       "         -1.1118e-01, -3.7577e-02, -4.5636e-03, -1.0169e-01,  2.2616e-02,\n",
       "         -6.4782e-02, -5.8231e-02,  1.8412e-01,  1.5927e-01,  7.2231e-02,\n",
       "         -8.2410e-03,  6.3502e-02, -6.5254e-03, -1.5480e-01,  1.2239e-01,\n",
       "          1.3907e-01, -1.0959e-01,  2.1398e-01,  2.8403e-02,  1.3976e-01,\n",
       "         -1.1511e-02,  4.8689e-02, -4.7400e-02, -3.5375e-02,  8.7291e-02,\n",
       "         -1.8668e-01,  8.7162e-03, -1.9849e-01,  3.6719e-02, -1.1307e-01,\n",
       "          6.4984e-03, -1.0104e-01, -1.4648e-01,  1.6499e-01, -3.4259e-02,\n",
       "         -1.7418e-01, -1.7965e-01, -4.7325e-03, -1.2874e-02, -8.9389e-02,\n",
       "          1.1376e-01,  3.0038e-01,  1.0216e-01, -7.3336e-02,  6.5745e-02,\n",
       "          1.2904e-01, -1.9826e-02,  4.9556e-02,  1.8150e-01, -2.7042e-01,\n",
       "         -1.3421e-01,  6.5607e-01, -3.2256e-02, -3.9979e-03,  9.1274e-02,\n",
       "          2.6122e-01, -1.3429e-01,  1.9112e-01,  1.4294e-01,  1.2402e-01,\n",
       "         -3.2374e-02, -7.0890e-02, -7.6397e-02,  1.8777e-01,  8.0358e-03,\n",
       "          5.5245e-02,  1.3889e-01, -7.8599e-02,  1.7570e-01, -9.1254e-02,\n",
       "          1.2744e-01, -9.5908e-02, -1.7724e-01, -8.9019e-03, -2.7369e-02,\n",
       "          9.9424e-02,  1.1946e-01, -2.7375e-01, -4.3034e-02,  2.9473e-01,\n",
       "         -2.6759e-01,  8.6330e-02, -1.5584e-01,  5.6866e-02, -7.5608e-02,\n",
       "         -2.4506e-02,  8.9672e-02,  3.6124e-02,  4.0310e-03,  2.1819e-01,\n",
       "          4.2471e-02,  1.1455e-01, -1.6826e-01, -5.9011e-02, -1.1176e-01,\n",
       "          4.5981e-02, -4.7308e-03,  4.8670e-01, -3.9340e-02, -2.2350e-01,\n",
       "         -1.1150e-02, -2.9153e-01,  7.9229e-02, -7.2109e-02,  2.1014e-01,\n",
       "         -8.0384e-02,  9.5033e-02,  3.4228e-02, -1.3234e-01,  2.3086e-01,\n",
       "          5.0849e-02, -2.0079e-01,  1.9656e-01,  2.7933e-02, -1.2391e-01,\n",
       "         -7.4246e-02, -1.7753e-02,  1.6751e-01, -1.5976e-02,  1.3733e-01,\n",
       "         -1.5928e-01,  3.8927e-01, -4.2314e-03,  1.7543e-02, -4.4693e-02,\n",
       "          8.8815e-04, -1.1453e-01,  2.5587e-01, -8.0434e-02,  3.5012e-01,\n",
       "          1.7482e-01,  2.1464e-02, -2.6677e-01, -2.0562e-01,  1.5906e-02,\n",
       "         -1.2838e-01,  1.7999e-01, -8.8452e-02, -2.4351e-02,  1.3537e-01,\n",
       "          8.5065e-03,  1.1358e-01, -1.2907e-01, -1.0531e-01,  5.6472e-02,\n",
       "          2.4469e-02, -6.0273e-02,  2.8088e-02, -1.2912e-01,  1.4083e-02,\n",
       "         -3.4086e-01, -1.8941e-02, -5.0269e-02,  1.2974e-01,  1.2473e-02,\n",
       "          2.0904e-01, -7.4330e-02,  2.1350e-01, -2.9879e+00, -5.1382e-02,\n",
       "          1.4264e-01, -7.9323e-02, -6.7639e-02,  2.5396e-01,  1.8843e-01,\n",
       "          9.9903e-03,  1.8879e-01, -1.1036e-02, -6.2546e-02,  8.2697e-02,\n",
       "          1.0746e-01, -2.6098e-02, -3.2315e-01,  4.2068e-02,  5.8130e-02,\n",
       "          2.9191e-01,  3.3065e-02,  1.6791e-01,  2.9781e-03, -2.0477e-01,\n",
       "          9.5641e-02, -1.3596e-01,  1.7567e-01, -3.0255e-02,  4.8722e-02,\n",
       "         -3.3768e-02, -9.5191e-02, -1.0229e-01, -8.7678e-02,  1.7230e-02,\n",
       "         -5.7168e-02,  1.4702e-01, -1.5486e-01,  1.0167e-01, -4.2474e-02,\n",
       "         -1.1334e-01, -1.4780e-01, -9.4148e-02, -2.7555e-01, -2.1301e-01,\n",
       "          3.0041e-02,  1.4375e-01,  5.2278e-02, -2.4965e-01,  1.3375e-01,\n",
       "         -2.1917e-01, -9.1171e-03,  2.6620e-01,  1.1913e-01,  2.1140e-02,\n",
       "         -8.6450e-02,  1.2354e-02,  2.9133e-02, -5.8175e-02,  1.7748e-02,\n",
       "          1.4167e-01,  1.7459e-01,  1.3773e-01, -1.8140e-01,  1.5937e-02,\n",
       "          2.0348e-01,  6.6218e-02,  1.4351e-01,  4.2973e-02,  7.4120e-02,\n",
       "         -2.5265e-02, -1.3975e-01,  2.0339e-01, -1.1828e-01,  1.5121e-01,\n",
       "          1.1890e-01, -2.7605e-01,  1.6106e+00,  3.2741e-02,  1.5666e-01,\n",
       "         -1.6812e-01,  8.7540e-02,  1.4451e-01,  2.2068e-01,  7.4422e-02,\n",
       "          1.4012e-02, -1.4879e-01,  2.2443e-02,  1.6478e-01,  4.7355e-02,\n",
       "          2.0962e-01,  3.0320e-01, -2.9832e-02, -1.3447e-01, -1.9306e-01,\n",
       "         -7.2619e-02, -1.4449e-01, -1.2948e-01, -3.4933e-03,  2.8817e-01,\n",
       "          8.8448e-02,  4.4275e-02,  1.1327e-02,  1.4317e-01, -9.3672e-02,\n",
       "         -4.8162e-02, -9.6565e-02, -1.9665e-01, -5.8748e-02, -1.8242e-01,\n",
       "         -3.6885e-01,  3.8491e+00, -9.8925e-02, -3.5064e-02,  4.9440e-02,\n",
       "          8.3612e-02,  2.5126e-01, -1.0279e-01,  9.6826e-02, -2.9162e-01,\n",
       "          7.8400e-02, -9.0043e-02, -6.3061e-02, -1.3142e-01, -7.6966e-04,\n",
       "         -6.6267e-02,  3.6277e-01, -4.1938e-02,  1.0638e-02, -1.1431e-01,\n",
       "          1.3131e-01, -7.7928e-02,  7.3319e-02, -4.6778e-02, -4.3071e-03,\n",
       "         -1.1415e-01,  4.7491e-02,  4.3709e-02, -1.5840e-01, -8.2766e-02,\n",
       "          6.3536e-02, -4.7262e-02, -8.8036e-02, -6.6898e-02, -4.9939e-02,\n",
       "         -2.1676e-01, -4.5011e-02, -7.7135e-02, -1.2026e-03, -6.2871e-02,\n",
       "          2.4192e-02, -5.8020e-02,  6.1375e-02,  1.0589e-01,  1.9872e-02,\n",
       "         -1.0491e-01, -1.3099e-01, -2.6912e-01,  4.5072e-02, -3.6764e-02,\n",
       "          7.5673e-02,  1.2889e-01, -9.2520e-02,  1.3375e-02, -1.2862e-01,\n",
       "         -1.1480e-01, -1.2475e-01, -1.0492e-01, -4.6326e-02, -3.0426e-01,\n",
       "          3.5528e-02, -1.1242e-01, -7.5240e-02,  8.1291e-03, -2.5517e-01,\n",
       "          3.0017e-02,  2.3827e-01, -1.7993e-01, -1.0315e-01, -2.3549e-02,\n",
       "          1.4136e-02,  2.0478e-01, -1.7341e-01,  1.5418e-01,  4.8663e-02,\n",
       "         -7.9738e-02, -7.5500e-03,  2.5583e-01, -2.0869e-01, -1.5328e-01,\n",
       "         -8.1470e-02,  2.5862e-01,  3.6970e-01, -1.7248e-01,  1.4724e-01,\n",
       "         -1.4826e-02,  8.1561e-02, -2.9888e-02, -1.1907e-01, -1.9521e-02,\n",
       "          1.3730e-01, -8.7003e-02, -4.3825e-02, -2.9017e-01, -1.5796e-01,\n",
       "          4.7715e-03,  2.9769e-02,  6.3667e-04,  8.6675e-02,  1.3762e-01,\n",
       "          4.7474e-02, -8.9161e-02,  1.4309e-01, -1.1020e-01, -7.4191e-02,\n",
       "          8.4554e-02, -7.8401e-02, -1.4910e-02,  2.4917e-01,  9.8512e-02,\n",
       "         -1.3347e-02, -1.3149e-01,  1.4435e-01,  4.7064e-02, -1.1919e-01,\n",
       "          2.2155e-01, -1.4150e-01,  1.5482e-01,  2.8138e-02,  2.7679e-01,\n",
       "         -5.6556e-02,  2.9770e-01, -1.5242e-01, -1.4212e-01,  4.8245e-02,\n",
       "          5.1145e-02, -2.4877e-01,  1.4711e-01, -3.6850e-02,  3.4200e-02,\n",
       "          3.4856e-02,  9.6491e-02, -2.9448e-03,  1.0233e-03, -1.1796e-01,\n",
       "         -3.0176e-01, -1.0404e-01, -8.7887e-02, -7.9003e-02, -1.2622e-01,\n",
       "          1.4097e-01, -1.7600e-02,  2.4899e-01,  1.0704e-01, -8.2967e-02,\n",
       "         -6.7200e-02,  1.0821e-01, -8.9861e-02,  1.2028e-01, -6.8952e-02,\n",
       "          1.1850e-01, -1.8197e-01, -1.1319e-01, -2.6780e-02,  7.9156e-02,\n",
       "         -4.5832e-02, -5.2018e-02, -7.9909e-02, -2.2927e-03, -1.3758e-01,\n",
       "         -2.5597e-02, -1.3735e-01, -1.2317e-01,  2.6385e-02,  1.2720e-01,\n",
       "         -2.2807e-02,  9.6982e-02, -7.3102e-03, -5.6895e-03, -4.9237e-02,\n",
       "          3.2314e-02, -1.9534e-01, -4.7456e-02, -1.7260e-01,  1.0746e-01,\n",
       "         -5.2415e-02,  1.0207e-01, -2.6180e-02, -2.9488e-02,  2.5588e-01,\n",
       "         -1.1691e-01, -1.7254e-02, -5.3564e-02,  1.0267e-01, -8.4233e-02,\n",
       "          2.6397e-02,  1.1934e-01, -9.6089e-02,  2.0718e-02, -1.3928e-01,\n",
       "         -2.2855e-01, -2.5989e-01, -2.5050e-01,  1.2405e-01, -1.3548e-01,\n",
       "         -6.2826e-03, -2.8458e-01, -1.2420e-01, -2.9676e-02,  4.5543e-02,\n",
       "          5.3763e-03,  1.6633e-01, -1.4238e-01,  2.0877e-02, -1.2927e-01,\n",
       "          1.5561e-02,  1.7643e-01, -2.1712e-01,  9.7189e-02,  9.8672e-02,\n",
       "         -1.0300e-01,  1.5900e-01,  1.8163e-01,  2.4923e-01, -1.9131e-02,\n",
       "          7.6086e-02,  9.9275e-02,  1.6313e-01,  1.0650e-01,  8.4541e-02,\n",
       "          7.1349e-02, -1.9356e-03, -5.1919e-02, -1.7568e-01, -3.6663e-02,\n",
       "         -5.9383e-02,  1.1216e-01,  1.3886e-01, -1.3169e-01,  1.7795e-02,\n",
       "         -7.5414e-02,  2.3237e-01, -8.1315e-02,  1.1739e-02, -1.7310e-01,\n",
       "         -1.1895e-01,  3.2130e-02, -7.2317e-02,  9.5463e-02,  9.6840e-03,\n",
       "          2.2047e-03,  2.4560e-02,  1.3156e-01,  1.4928e-01, -6.8467e-02,\n",
       "          7.2495e-02,  2.0334e-01,  1.9862e-01,  8.6380e-02, -3.2466e-02,\n",
       "         -1.3583e-01,  4.2324e-02, -3.4869e-01,  2.3828e-01, -2.2848e-01,\n",
       "          1.3376e-01,  2.7762e-01, -3.1245e-02,  5.4983e-02,  7.5708e-02,\n",
       "          2.6616e-01, -6.6431e-02,  4.6051e-02,  2.8558e-01, -9.8300e-02,\n",
       "         -5.1377e-02, -2.8476e-02, -5.9318e-02,  9.7747e-03,  6.6608e-02,\n",
       "         -1.5685e-01, -1.5462e-01, -2.4600e-01,  8.7477e-02, -4.8798e-02,\n",
       "          1.0550e-01,  5.3802e-02,  3.2799e-02, -1.0552e-01, -4.6069e-04,\n",
       "         -1.8872e-01,  1.1710e-01,  5.2023e-02, -5.3095e-02, -5.5921e-03,\n",
       "          3.3713e-02, -5.2039e-02, -1.5190e-01]),\n",
       " 'h.10.attn.c_proj.weight': tensor([[-0.0077, -0.5188,  0.0783,  ..., -0.0935, -0.1252,  0.1297],\n",
       "         [-0.3012,  0.2455, -0.0883,  ...,  0.0785,  0.2385, -0.1301],\n",
       "         [-0.3693,  0.1506,  0.2052,  ..., -0.0831, -0.2656, -0.1792],\n",
       "         ...,\n",
       "         [ 0.2251,  0.0240, -0.0106,  ..., -0.1443, -0.0599, -0.1167],\n",
       "         [ 0.0778, -0.1356,  0.0710,  ...,  0.1302,  0.1659,  0.0141],\n",
       "         [ 0.0468,  0.1248,  0.0349,  ...,  0.2004,  0.0141, -0.1468]]),\n",
       " 'h.10.ln_1.bias': tensor([ 3.0510e-02,  6.0018e-03,  4.8768e-02,  1.1650e-02,  5.8796e-03,\n",
       "          1.0598e-02, -6.7249e-02,  2.5557e-02,  1.3905e-02,  6.4351e-04,\n",
       "          7.5819e-03,  1.2247e-02,  2.6726e-02,  2.7891e-02,  4.7979e-02,\n",
       "         -4.1496e-03,  4.0992e-02,  3.4726e-02, -1.0701e-03,  1.3254e-02,\n",
       "          3.3631e-02,  2.3287e-02,  2.1054e-02,  2.5587e-02,  2.0324e-02,\n",
       "          6.3015e-03, -1.6431e-03,  1.5146e-02,  2.8475e-02,  6.5443e-03,\n",
       "          1.0149e-02, -6.4570e-03, -9.9454e-03,  2.3009e-02,  2.5093e-02,\n",
       "          5.7307e-02, -2.3542e-02,  5.4855e-03,  3.6255e-02,  6.7605e-05,\n",
       "          3.6737e-03, -2.2789e-03, -6.6622e-03,  1.3133e-02,  3.4681e-02,\n",
       "          1.6549e-02,  1.7798e-02,  9.1896e-03,  7.5546e-03,  5.7225e-03,\n",
       "          3.0501e-02, -7.7824e-03,  1.6269e-02, -1.4698e-02,  1.7723e-02,\n",
       "         -1.2181e-02, -3.4919e-03,  2.8184e-02,  5.7460e-04,  1.9307e-02,\n",
       "          2.8484e-02,  2.0697e-02,  3.4364e-02,  5.2619e-03,  1.0895e+00,\n",
       "          8.9252e-03, -1.7973e-02, -2.6218e-02,  4.1295e-02,  1.5583e-02,\n",
       "          4.8572e-03,  2.7360e-02,  2.5208e-02,  2.6618e-02,  2.2383e-02,\n",
       "          3.0180e-02, -2.0396e-02,  1.3613e-02,  1.3994e-02,  3.2356e-02,\n",
       "          4.5118e-02,  1.0150e-02,  1.5576e-02,  2.3248e-02,  6.8681e-02,\n",
       "          2.1442e-02,  3.6212e-02, -1.7378e-03,  1.6896e-02,  2.0278e-02,\n",
       "          1.5742e-03,  1.2599e-02,  4.4826e-02, -8.9105e-04,  1.5220e-02,\n",
       "          1.0788e-02,  6.8030e-03,  2.6381e-02,  3.6601e-02,  6.5487e-02,\n",
       "          3.1313e-03, -2.7101e-02, -3.9119e-02,  1.7792e-02,  2.0577e-02,\n",
       "          2.1596e-02,  3.7847e-02,  1.0212e-02,  7.9026e-03,  1.4136e-02,\n",
       "          1.0731e-02,  2.6045e-02,  1.9629e-02,  5.3064e-02,  1.7490e-02,\n",
       "         -7.8047e-03,  5.6762e-02,  1.0151e-02,  3.9767e-02,  4.1502e-02,\n",
       "          2.9220e-02,  1.8263e-02,  3.7876e-03, -2.8561e-03,  4.4087e-03,\n",
       "          3.1142e-02,  1.5206e-02,  4.4540e-02,  4.8803e-02,  2.2513e-02,\n",
       "          1.9234e-02,  2.6071e-02,  1.8358e-02,  1.0985e-02,  1.7072e-02,\n",
       "          1.1037e-02,  2.7748e-02,  4.3213e-02, -6.5276e-01, -1.0676e-03,\n",
       "          4.7908e-03, -5.9358e-03,  4.9437e-02,  2.0611e-02,  1.2362e-02,\n",
       "         -1.6437e-02, -1.2943e-02,  7.8778e-03,  7.7959e-03,  2.8179e-02,\n",
       "          4.6312e-02, -3.7110e-02,  1.7228e-02,  2.0611e-02,  2.1190e-03,\n",
       "          6.7950e-04,  1.7173e-02,  2.7729e-02,  9.7434e-03, -1.8524e-02,\n",
       "         -4.4523e-02,  1.8437e-02,  1.0640e-02,  2.7398e-02,  2.5514e-02,\n",
       "          4.5742e-02,  1.2592e-03,  1.3448e-01,  1.7151e-03,  3.0443e-02,\n",
       "          1.3813e-02,  2.7351e-02,  3.7165e-02,  2.1619e-02,  3.5051e-02,\n",
       "          3.2485e-02,  7.6267e-02,  1.8186e-02, -6.8216e-03,  1.6186e-02,\n",
       "          2.4216e-02, -2.9053e-03,  3.0967e-02,  3.0941e-02,  4.1112e-02,\n",
       "          1.6433e-02,  6.9999e-03,  1.0342e-02,  1.1311e-02, -1.0954e-02,\n",
       "          1.7435e-02,  4.8904e-02,  2.9742e-02,  1.6672e-02,  3.0743e-02,\n",
       "          9.5988e-02,  2.1865e-02,  4.1136e-02,  4.5287e-02,  2.8203e-02,\n",
       "          6.6434e-03,  7.2262e-03,  2.5223e-02,  2.5595e-02,  1.0206e-02,\n",
       "          1.4698e-02,  3.6713e-02,  2.1287e-02,  2.7897e-02,  8.4845e-03,\n",
       "         -3.1251e-03,  4.7961e-02,  3.6884e-02,  4.4813e-02,  3.6081e-02,\n",
       "          2.1300e-02,  1.9595e-02,  1.8230e-02,  4.9084e-02,  1.8052e-02,\n",
       "          8.8896e-03,  2.7559e-02,  3.0454e-03,  8.2039e-03, -1.0471e-02,\n",
       "         -2.6374e-04,  5.2323e-03,  2.1517e-02,  3.4661e-02,  5.8228e-03,\n",
       "          2.0718e-02,  6.4387e-03, -2.5122e-02,  1.8809e-02,  7.2337e-03,\n",
       "          7.7876e-03,  1.5827e-02,  1.1656e-02,  2.1921e-02,  1.4640e-02,\n",
       "          3.8638e-02,  1.1814e-02,  2.4043e-02,  1.2504e-02,  2.3457e-02,\n",
       "          8.9652e-04,  4.5214e-03,  2.9194e-02,  2.6070e-02,  2.9030e-02,\n",
       "          3.8022e-02,  4.5631e-02,  5.0841e-03,  8.6518e-03,  3.4771e-02,\n",
       "         -2.9929e-02,  2.8767e-02,  2.6812e-02, -6.3973e-03,  2.6378e-02,\n",
       "          1.7356e-02,  2.4563e-02,  2.6616e-02, -1.5714e-03,  3.1854e-02,\n",
       "          1.7033e-02, -9.0867e-02, -8.8382e-03,  3.5924e-02,  2.0487e-02,\n",
       "          3.1361e-02, -6.6589e-03,  2.1889e-02, -8.9931e-03,  1.0533e-03,\n",
       "          2.1037e-02,  5.5251e-03,  2.7291e-02,  1.7257e-02,  4.9234e-03,\n",
       "          1.4868e-02,  1.6623e-02,  2.9330e-03,  1.0793e-01,  1.2949e-02,\n",
       "          1.7930e-02,  1.3331e-02,  2.7704e-02, -1.5497e-01,  6.9195e-02,\n",
       "          1.6382e-02,  3.6435e-03,  3.6038e-02,  2.4597e-02,  2.9102e-02,\n",
       "          2.8022e-02,  1.9410e-02,  2.1548e-02,  2.6269e-02,  4.4157e-03,\n",
       "          1.2594e-02,  1.5880e-02, -1.2743e-02,  3.1621e-02,  5.0564e-03,\n",
       "          3.8002e-03,  1.7110e-02,  2.5296e-02,  4.4084e-02,  2.9926e-02,\n",
       "          8.9388e-03,  8.0685e-02,  2.9842e-02,  2.0275e-02,  1.8288e-01,\n",
       "          1.2359e-02,  4.6401e-02, -2.3895e-03,  4.8557e-03,  1.7429e-02,\n",
       "          4.1916e-02,  1.8273e-02,  2.0372e-02,  2.2133e-02,  3.2574e-03,\n",
       "         -1.3338e-02, -1.8723e-01,  1.0802e-02,  1.8939e-02,  2.5256e-02,\n",
       "          3.1490e-03,  9.3702e-03,  4.4415e-03,  7.3213e-03,  7.3003e-03,\n",
       "          2.9991e-02,  1.6974e-02,  2.8924e-02,  2.9901e-02, -5.3843e-04,\n",
       "          6.7884e-03,  1.4092e-02, -1.5407e-03, -4.1260e-03,  1.0127e-02,\n",
       "         -3.5204e-03, -5.3762e-03,  2.0368e-02,  1.2082e-03,  2.2934e-02,\n",
       "          1.5206e-02, -1.4959e-02,  1.2037e-02,  1.2362e-02, -1.2875e-02,\n",
       "          1.6643e-02,  4.5399e-02,  3.3174e-02,  4.1726e-02,  2.6364e-02,\n",
       "          1.2428e-02,  4.2257e-02, -3.1136e-02,  2.2604e-02,  8.6213e-03,\n",
       "          9.7748e-02,  6.5618e-03, -2.5439e-03,  2.5821e-03,  1.2533e-02,\n",
       "          3.2014e-02, -5.8792e-03,  3.8993e-02,  2.9207e-01,  6.5573e-02,\n",
       "          3.7718e-03,  3.6122e-02, -8.5052e-03,  3.5195e-02,  1.1074e-02,\n",
       "          4.3378e-02,  3.2003e-03,  2.5859e-02,  1.2299e-02,  2.2928e-02,\n",
       "         -2.3925e-02,  1.5934e-02,  2.9323e-02, -3.9099e-03,  5.1672e-02,\n",
       "          3.0027e-02,  2.3198e-02, -1.1945e-02, -2.1119e-01,  5.8699e-02,\n",
       "          1.6626e-02,  4.8430e-02,  1.1477e-02,  2.9299e-02,  1.2431e-02,\n",
       "          3.2892e-02, -2.4925e-02,  1.2931e-02,  6.6905e-03,  5.6148e-03,\n",
       "          3.2051e-02, -3.6190e-03,  2.8784e-02, -7.4883e-02,  1.3950e-02,\n",
       "          2.6382e-02,  1.3927e-02,  3.2732e-02,  1.0389e-02,  3.6522e-02,\n",
       "          3.8695e-03,  1.8970e-02,  8.8188e-03,  2.5616e-02,  1.8713e-02,\n",
       "          2.5290e-02,  3.0087e-02,  3.5146e-02,  1.6163e-02,  1.6035e-02,\n",
       "          3.4702e-02,  1.7713e-02,  4.2986e-02,  1.5878e-02,  1.5618e-02,\n",
       "         -6.7364e-02,  1.6589e-02,  2.3507e-02,  2.9140e-02,  3.2753e-02,\n",
       "         -3.6422e-03,  1.5391e-02,  8.8451e-03,  1.6420e-02, -2.5854e-03,\n",
       "         -1.1436e-02,  4.4180e-03, -3.5285e-02,  3.6272e-02, -1.3829e-02,\n",
       "          1.0876e-02,  4.2532e-02, -3.6222e-02,  3.4925e-02,  1.0801e-03,\n",
       "          1.1326e-02,  1.0099e-02,  3.1453e-02, -6.8046e-03,  3.5503e-03,\n",
       "          1.5443e-02,  4.0166e-02,  2.1864e-02,  4.5181e-05,  5.6395e-03,\n",
       "          2.1827e-02, -1.5863e-03,  1.7870e-02,  1.5306e-02, -1.4041e-02,\n",
       "          2.0903e-02,  1.7877e-02,  1.4547e-02,  1.1389e-02,  5.7616e-03,\n",
       "          5.5374e-02,  2.1508e-02,  2.7936e-02,  3.7233e-02,  3.0709e-02,\n",
       "          2.0045e-02,  2.4502e-02,  3.2306e-02,  2.4381e-02,  5.7804e-02,\n",
       "          2.6354e-01, -3.4994e-02,  1.7011e-02,  1.8178e-02,  1.3185e-02,\n",
       "          1.8638e-03,  1.6515e-02,  7.2046e-03, -2.0771e-02,  3.0423e-02,\n",
       "         -1.0573e-02,  4.3190e-02,  2.9087e-02,  2.3918e-02,  1.8108e-02,\n",
       "          2.2516e-02, -7.7928e-02,  4.8908e-02,  1.2752e-02,  9.5487e-03,\n",
       "         -1.3659e-02,  1.6999e-02,  1.3089e-02,  1.0188e-01,  3.1624e-02,\n",
       "          4.4236e-02,  2.6660e-03, -2.2002e-02,  9.4993e-03,  1.6732e-02,\n",
       "          6.7471e-03,  1.0948e-02,  3.9674e-02,  2.4001e-02,  2.6092e-02,\n",
       "          4.9369e-02,  1.8497e-02,  3.0572e-02,  3.1680e-02,  1.5310e-02,\n",
       "          1.7420e-02,  5.5267e-02,  2.0003e-02,  9.6060e-03, -6.1582e-04,\n",
       "          1.8077e-02,  1.8408e-01,  6.8998e-02,  3.1370e-02,  1.9246e-02,\n",
       "          1.1786e-02, -1.2548e-02,  9.0407e-03,  2.3702e-02,  4.8123e-02,\n",
       "          2.7501e-02,  3.3255e-02,  7.5798e-03, -1.2386e-03,  4.6698e-02,\n",
       "         -6.0752e-03,  6.5236e-03, -4.5752e-03,  3.1878e-02,  2.2800e-02,\n",
       "          4.0039e-02,  1.9241e-02,  1.9338e-02,  3.4379e-02,  3.2265e-02,\n",
       "          2.6210e-02,  1.1994e-02,  1.2377e-02,  2.0400e-02,  8.6980e-02,\n",
       "          2.9149e-03,  2.9756e-02,  2.5734e-02,  3.5196e-02,  5.1832e-02,\n",
       "          3.8598e-02,  1.5860e-02,  9.6417e-03,  6.9731e-03,  1.0494e-02,\n",
       "          7.7392e-03,  1.3177e-02,  4.7104e-02,  2.4319e-02,  3.4188e-02,\n",
       "          5.6501e-02,  3.2135e-02,  1.6710e-02,  3.8981e-02,  3.1749e-02,\n",
       "         -2.5556e-02,  2.8888e-02,  1.9070e-02,  5.1650e-02, -1.5914e-02,\n",
       "         -1.2977e-02,  6.6083e-03,  1.7860e-02,  3.1013e-02,  1.8371e-02,\n",
       "         -2.1300e-02,  2.5543e-02,  1.6410e-02, -6.5174e-03,  1.3495e-02,\n",
       "          8.7851e-03,  4.6246e-02,  1.8821e-03,  2.9014e-02,  1.1800e-02,\n",
       "          5.9435e-04,  3.8069e-02, -1.1412e-03,  2.3119e-02,  1.1591e-02,\n",
       "          4.3060e-02,  3.3098e-02,  2.1665e-02,  1.8575e-02,  3.6334e-02,\n",
       "          4.9192e-03,  1.9173e-02,  5.5739e-03, -4.8481e-02, -3.4651e-03,\n",
       "          4.6214e-02, -9.8203e-03,  1.5743e-02,  3.0009e-02,  1.9906e-02,\n",
       "          4.1677e-02,  8.9290e-03,  3.6726e-02,  1.1614e-02,  3.5722e-02,\n",
       "          5.2057e-02,  1.4911e-02,  1.7501e-02,  2.3691e-02,  2.0107e-02,\n",
       "          1.6700e-02,  3.2877e-02,  9.7055e-02,  7.1827e-04,  3.3868e-02,\n",
       "          2.0839e-02,  3.9532e-02,  1.3293e-02,  3.6185e-02,  2.6945e-03,\n",
       "          5.1187e-02,  5.1772e-02,  1.7860e-02,  1.9585e-02,  3.2763e-02,\n",
       "         -1.5987e-01, -1.0280e-02,  2.8637e-02,  2.1631e-02,  3.6269e-02,\n",
       "          4.1857e-02,  1.4414e-02,  3.6165e-02,  9.4467e-03,  7.0197e-02,\n",
       "         -1.2440e-02,  2.1275e-03,  1.5799e-03, -1.6614e-04,  1.1726e-02,\n",
       "          1.7327e-02,  1.7329e-02,  2.2099e-02, -4.4030e-03,  1.4518e-02,\n",
       "          1.3263e-02,  3.3477e-02,  4.7591e-04,  3.0322e-02,  2.9178e-02,\n",
       "         -1.4136e-02,  1.3277e-02,  3.4933e-02, -1.6847e-03, -2.2079e-03,\n",
       "          1.9391e-02,  3.5811e-02,  3.1967e-02,  3.7433e-03,  4.5169e-02,\n",
       "          2.0756e-02,  7.0152e-03,  2.5443e-02,  3.5833e-03, -1.0657e-01,\n",
       "          4.4172e-02, -9.5086e-04,  1.4159e-02, -3.8349e-03,  3.2159e-02,\n",
       "          1.5454e-02,  1.0590e-02,  1.9344e-02,  7.1228e-03,  1.7016e-02,\n",
       "          2.7252e-02,  1.0541e-02,  2.8562e-02, -7.8883e-03,  4.8528e-02,\n",
       "          9.2735e-03, -4.7732e-04,  1.3732e-02, -1.8557e-03,  2.5011e-02,\n",
       "          9.9024e-04,  2.0201e-02,  1.6506e-02,  5.9075e-02,  4.0285e-02,\n",
       "          6.5056e-03,  2.1686e-02,  1.7892e-02,  2.1786e-02,  3.1710e-03,\n",
       "          1.0477e-02,  1.5669e-03,  4.0309e-02,  2.2216e-02,  3.4789e-02,\n",
       "         -3.0456e-03,  6.2019e-03,  2.2039e-02,  9.4936e-03,  2.4101e-02,\n",
       "          1.6185e-03,  1.7310e-02, -5.9819e-03,  7.8453e-03, -2.8414e-03,\n",
       "          7.8690e-03,  4.5540e-03,  3.1039e-03,  4.9698e-02,  3.7590e-02,\n",
       "         -8.4337e-04,  5.3732e-02,  5.3245e-02,  2.3421e-02,  3.3265e-02,\n",
       "          3.5699e-02,  1.9311e-02, -7.2357e-05,  9.5435e-03,  7.3847e-02,\n",
       "          2.7004e-04,  2.7659e-02,  2.8465e-02,  2.6450e-02,  2.4385e-02,\n",
       "          1.3997e-01,  5.8820e-02,  1.8040e-03,  2.9881e-02,  9.1413e-03,\n",
       "          1.3223e-02,  1.0460e-02,  2.1818e-03,  4.4793e-02,  2.0962e-02,\n",
       "          3.1776e-02,  6.9040e-02,  1.6514e-02,  3.4750e-02,  1.9679e-02,\n",
       "          3.2600e-02,  1.8007e-03, -4.3986e-02,  2.1791e-02,  3.6372e-02,\n",
       "          2.4327e-02,  5.0891e-03,  3.7223e-02]),\n",
       " 'h.10.ln_1.weight': tensor([0.4269, 0.3799, 0.3893, 0.3629, 0.3722, 0.3487, 0.5020, 0.3584, 0.3821,\n",
       "         0.3207, 0.4149, 0.3587, 0.3574, 0.3838, 0.4463, 0.3977, 0.3977, 0.3702,\n",
       "         0.3779, 0.3975, 0.3311, 0.3544, 0.3800, 0.4131, 0.3798, 0.3877, 0.4171,\n",
       "         0.3595, 0.3612, 0.3603, 0.3588, 0.4113, 0.3604, 0.3545, 0.3667, 0.4339,\n",
       "         0.3249, 0.3704, 0.3545, 0.3721, 0.3368, 0.3487, 0.3353, 0.3564, 0.3506,\n",
       "         0.3993, 0.3607, 0.3410, 0.4021, 0.3760, 0.3486, 0.3444, 0.3885, 0.3701,\n",
       "         0.3740, 0.3779, 0.3729, 0.4284, 0.3385, 0.4539, 0.3883, 0.3629, 0.4170,\n",
       "         0.3713, 0.9214, 0.3348, 0.3570, 0.4068, 0.4061, 0.3641, 0.3857, 0.3037,\n",
       "         0.3584, 0.3480, 0.3252, 0.3683, 0.4444, 0.4629, 0.3827, 0.3628, 0.3694,\n",
       "         0.3467, 0.3526, 0.3801, 0.3851, 0.4228, 0.4093, 0.7403, 0.3598, 0.3877,\n",
       "         0.3584, 0.3423, 0.3475, 0.3584, 0.3424, 0.3330, 0.3847, 0.4186, 0.4209,\n",
       "         0.4701, 0.3586, 0.3724, 0.4209, 0.3873, 0.3735, 0.3428, 0.4019, 0.3808,\n",
       "         0.3334, 0.3721, 0.3839, 0.3805, 0.3675, 0.3779, 0.3794, 0.3740, 0.4325,\n",
       "         0.3949, 0.3448, 0.4574, 0.3780, 0.3578, 0.3412, 0.3506, 0.4140, 0.3799,\n",
       "         0.3388, 0.4181, 0.3878, 0.3740, 0.3879, 0.3373, 0.4092, 0.3597, 0.3545,\n",
       "         0.3415, 0.3582, 0.4604, 0.2745, 0.3591, 0.3707, 0.3878, 0.4010, 0.3506,\n",
       "         0.4058, 0.3760, 0.3916, 0.3913, 0.3663, 0.3670, 0.3782, 0.3946, 0.4417,\n",
       "         0.4209, 0.3869, 0.3525, 0.3730, 0.3864, 0.3505, 0.4150, 0.4600, 0.3799,\n",
       "         0.3870, 0.4170, 0.3722, 0.3547, 0.3877, 0.5442, 0.3619, 0.3896, 0.3617,\n",
       "         0.3643, 0.3731, 0.3980, 0.3877, 0.3663, 0.3780, 0.3408, 0.4256, 0.3529,\n",
       "         0.3271, 0.3438, 0.3584, 0.4188, 0.3390, 0.3503, 0.3532, 0.3881, 0.3629,\n",
       "         0.3963, 0.3746, 0.3604, 0.3701, 0.3977, 0.3623, 0.4951, 0.3287, 0.3498,\n",
       "         0.3665, 0.4218, 0.3889, 0.4014, 0.3759, 0.3662, 0.3255, 0.3897, 0.3525,\n",
       "         0.3092, 0.4251, 0.3579, 0.3555, 0.4457, 0.3956, 0.4703, 0.3759, 0.3488,\n",
       "         0.4288, 0.3623, 0.2928, 0.3678, 0.3938, 0.3628, 0.3643, 0.4017, 0.3761,\n",
       "         0.3565, 0.3459, 0.3525, 0.3604, 0.3486, 0.3274, 0.3842, 0.4756, 0.3351,\n",
       "         0.3486, 0.3936, 0.3776, 0.3408, 0.4105, 0.3850, 0.4303, 0.4073, 0.3716,\n",
       "         0.3623, 0.3284, 0.3761, 0.3558, 0.4561, 0.3662, 0.3891, 0.3492, 0.3952,\n",
       "         0.3525, 0.4122, 0.3604, 0.4110, 0.3520, 0.3603, 0.3528, 0.3653, 0.3701,\n",
       "         0.3705, 0.3632, 0.3702, 0.3464, 0.3315, 0.9082, 0.4844, 0.3878, 0.4224,\n",
       "         0.4873, 0.5058, 0.3504, 0.3468, 0.4508, 0.3556, 0.4170, 0.3428, 0.3680,\n",
       "         0.3494, 0.3252, 0.3216, 0.3488, 0.5176, 0.4359, 0.4386, 0.4021, 0.3604,\n",
       "         0.6687, 0.4509, 0.3995, 0.3760, 0.3447, 0.3291, 0.4286, 0.3506, 0.3464,\n",
       "         0.3728, 0.3721, 0.3877, 0.3631, 0.3889, 0.4053, 0.3542, 0.3467, 0.3470,\n",
       "         0.3740, 0.3438, 0.3880, 0.3232, 0.3345, 0.4736, 0.3486, 0.3643, 0.2282,\n",
       "         0.3596, 0.4405, 0.3682, 0.3545, 0.4109, 0.3877, 0.3549, 0.3821, 0.4138,\n",
       "         0.3649, 0.3937, 0.4467, 0.3380, 0.3823, 0.3390, 0.3613, 0.3486, 0.3947,\n",
       "         0.3479, 0.3369, 0.3642, 0.4576, 0.3565, 0.3604, 0.4678, 0.3507, 0.3409,\n",
       "         0.3938, 0.4287, 0.3874, 0.3395, 0.3938, 0.3597, 0.3819, 0.3784, 0.3355,\n",
       "         0.4237, 0.3854, 0.3697, 0.3742, 0.3560, 0.4006, 0.3878, 0.3462, 0.3679,\n",
       "         0.4106, 0.3858, 0.4077, 0.3658, 0.3292, 0.4183, 0.3876, 0.3637, 0.3541,\n",
       "         0.3504, 0.3995, 0.3469, 0.3624, 0.0751, 0.3525, 0.4702, 0.3971, 0.4287,\n",
       "         0.2670, 0.3829, 0.3473, 0.3740, 0.3528, 0.4322, 0.3682, 0.4757, 0.4069,\n",
       "         0.3330, 0.3643, 0.3799, 0.3565, 0.3373, 0.3736, 0.7194, 0.3672, 0.3409,\n",
       "         0.3674, 0.3385, 0.3377, 0.3506, 0.3413, 0.3721, 0.4098, 0.3594, 0.3478,\n",
       "         0.3721, 0.4006, 0.3331, 0.3447, 0.3565, 0.3330, 0.3424, 0.3428, 0.3373,\n",
       "         0.3643, 0.3677, 0.3486, 0.4034, 0.4038, 0.3532, 0.3037, 0.4288, 0.3565,\n",
       "         0.3787, 0.3585, 0.3193, 0.3662, 0.3684, 0.3512, 0.3473, 0.2831, 0.3468,\n",
       "         0.3501, 0.3975, 0.3371, 0.4131, 0.3237, 0.3936, 0.3959, 0.4275, 0.3546,\n",
       "         0.3813, 0.3963, 0.3406, 0.4351, 0.3786, 0.3426, 0.0793, 0.3633, 0.3564,\n",
       "         0.3762, 0.3504, 0.3385, 0.4036, 0.3662, 0.4053, 0.3807, 0.3608, 0.3440,\n",
       "         0.3097, 0.3402, 0.4296, 0.3451, 0.3604, 0.2707, 0.3778, 0.3840, 0.3506,\n",
       "         0.3514, 0.3593, 0.3371, 0.4033, 0.3897, 0.3751, 0.3271, 0.3663, 0.3678,\n",
       "         0.3529, 0.3464, 0.4229, 0.7445, 0.0817, 0.3701, 0.3506, 0.4114, 0.3385,\n",
       "         0.3502, 0.3604, 0.3820, 0.3760, 0.3740, 0.4229, 0.3527, 0.3547, 0.3826,\n",
       "         0.3491, 0.2555, 0.3135, 0.3976, 0.3545, 0.3741, 0.3881, 0.3794, 0.4218,\n",
       "         0.4206, 0.3507, 0.3447, 0.3866, 0.4392, 0.3490, 0.3339, 0.3701, 0.3780,\n",
       "         0.3899, 0.3635, 0.4133, 0.3878, 0.3506, 0.3316, 0.3702, 0.3428, 0.3724,\n",
       "         0.3866, 0.3740, 0.3621, 0.3695, 0.5004, 0.4188, 0.4083, 0.3567, 0.3604,\n",
       "         0.3875, 0.3604, 0.3508, 0.3427, 0.4058, 0.3494, 0.3581, 0.3841, 0.3709,\n",
       "         0.3975, 0.3938, 0.3547, 0.3913, 0.3528, 0.3857, 0.4092, 0.3637, 0.3604,\n",
       "         0.4512, 0.3335, 0.4250, 0.3740, 0.3817, 0.4403, 0.3930, 0.3623, 0.3752,\n",
       "         0.3800, 0.3534, 0.3797, 0.3926, 0.3470, 0.3711, 0.3545, 0.3976, 0.4579,\n",
       "         0.3926, 0.3929, 0.4056, 0.4692, 0.4213, 0.3706, 0.3444, 0.3660, 0.4895,\n",
       "         0.3365, 0.3584, 0.4805, 0.3617, 0.3545, 0.3374, 0.4227, 0.3780, 0.3525,\n",
       "         0.4015, 0.3311, 0.4190, 0.3645, 0.3760, 0.3750, 0.3546, 0.3500, 0.3741,\n",
       "         0.3622, 0.3557, 0.3994, 0.3468, 0.3529, 0.3643, 0.3603, 0.3565, 0.3712,\n",
       "         0.3629, 0.3825, 0.3493, 0.3762, 0.3700, 0.4971, 0.3995, 0.3662, 0.3802,\n",
       "         0.3957, 0.3652, 0.3694, 0.3959, 0.4159, 0.3516, 0.4100, 0.3723, 0.3806,\n",
       "         0.3580, 0.3900, 0.3955, 0.3956, 0.3434, 0.3506, 0.3741, 0.3774, 0.3721,\n",
       "         0.3769, 0.3700, 0.3580, 0.3467, 0.3721, 0.4273, 0.3748, 0.3468, 0.3407,\n",
       "         0.4152, 0.5294, 0.3857, 0.3896, 0.4077, 0.4439, 0.3799, 0.3541, 0.4308,\n",
       "         0.3727, 0.4526, 0.3488, 0.4519, 0.4253, 0.3896, 0.3559, 0.3797, 0.3531,\n",
       "         0.3832, 0.3592, 0.4759, 0.3464, 0.4093, 0.3818, 0.3389, 0.3770, 0.4151,\n",
       "         0.3417, 0.3628, 0.3565, 0.3741, 0.4168, 0.3625, 0.3644, 0.3720, 0.3192,\n",
       "         0.3486, 0.3301, 0.3642, 0.4055, 0.5101, 0.3756, 0.3604, 0.3867, 0.3780,\n",
       "         0.3490, 0.3807, 0.4044, 0.3124, 0.3692, 0.3579, 0.3563, 0.3252, 0.3525,\n",
       "         0.3859, 0.3624, 0.3754, 0.3485, 0.3446, 0.3584, 0.4422, 0.3619, 0.4193,\n",
       "         0.3468, 0.4541, 0.3491, 0.3587, 0.4319, 0.4347, 0.3656, 0.4070, 0.4190,\n",
       "         0.3837, 0.3899, 0.3525, 0.3579, 0.3858, 0.3467, 0.3527, 0.4534, 0.3567,\n",
       "         0.3506, 0.4093, 0.3447, 0.3662, 0.3467, 0.3721, 0.4247, 0.4153, 0.4012,\n",
       "         0.3857, 0.3780, 0.3708, 0.3316, 0.3564, 0.3564, 0.3896, 0.3534, 0.3613,\n",
       "         0.4041, 0.4477, 0.4032, 0.3485, 0.3692, 0.4135, 0.3936, 0.2861, 0.4619,\n",
       "         0.3525, 0.4006, 0.3798, 0.3356, 0.3679, 0.3562, 0.3254, 0.3975, 0.4228,\n",
       "         0.2575, 0.3506, 0.3588, 0.3804, 0.3326, 0.3760, 0.4110, 0.3343, 0.3214,\n",
       "         0.3534, 0.3275, 0.3462]),\n",
       " 'h.10.ln_2.bias': tensor([-1.0358e-02,  1.3820e-02,  2.8260e-02,  4.6557e-02,  5.9956e-03,\n",
       "          1.1307e-02,  6.8819e-02,  3.6446e-02,  4.8702e-03,  4.9763e-03,\n",
       "          2.8531e-02,  4.7327e-02,  1.5152e-02,  2.8607e-02,  2.5593e-02,\n",
       "          5.2164e-02,  4.8066e-02,  5.3223e-02,  3.4451e-02, -2.9055e-02,\n",
       "          1.6824e-02, -6.3294e-03,  3.0100e-03,  4.8100e-02,  2.2632e-02,\n",
       "          2.3483e-02,  5.6872e-03,  4.2506e-02,  1.2199e-02, -2.9102e-02,\n",
       "          4.8205e-02, -3.0327e-02,  3.2885e-02,  5.2018e-02,  1.3616e-02,\n",
       "          1.7174e-02, -6.2414e-03,  1.4992e-02,  1.5188e-02,  8.3957e-03,\n",
       "          3.4247e-02,  2.9624e-02,  1.7826e-02,  1.4083e-02,  1.6533e-02,\n",
       "          2.2324e-02,  3.2677e-02,  2.0053e-02,  9.4957e-03, -1.7382e-02,\n",
       "          6.3748e-02,  4.1355e-02,  3.2904e-02,  3.2447e-02,  4.0435e-02,\n",
       "         -2.8565e-03,  2.0369e-02, -1.4023e-02,  2.0943e-02,  6.2948e-03,\n",
       "          2.9956e-02,  2.6207e-02,  3.2395e-02,  1.6449e-02, -1.4525e-02,\n",
       "          2.8430e-02,  1.6217e-02, -4.6950e-03,  5.2596e-02,  3.7110e-02,\n",
       "          1.3538e-02,  4.7081e-02,  2.6471e-02,  1.7197e-02,  3.4794e-02,\n",
       "          1.3930e-02, -1.8007e-02,  2.2802e-03,  6.4147e-02,  1.4225e-02,\n",
       "          8.2972e-04,  1.7301e-02,  1.5907e-02,  3.9303e-02,  4.9839e-02,\n",
       "          3.9953e-02,  4.5833e-02,  1.3956e-01,  1.6589e-02,  1.9164e-02,\n",
       "          2.9428e-02,  1.8867e-02,  3.5480e-02,  3.4520e-02,  2.5352e-02,\n",
       "         -1.6986e-03,  3.1963e-03,  1.0863e-02, -1.9798e-02,  4.9423e-02,\n",
       "          1.1976e-02, -2.8248e-02, -3.1719e-02,  2.6163e-02,  1.4126e-02,\n",
       "          4.0976e-03, -8.0332e-04,  6.1240e-02,  2.2650e-02,  2.2354e-02,\n",
       "          2.0694e-02,  4.3690e-02,  3.0244e-02,  3.6898e-02,  1.8719e-02,\n",
       "          1.1135e-02,  3.0766e-02,  5.8322e-03,  5.2236e-02,  3.1649e-02,\n",
       "          3.5989e-02,  7.6593e-03, -4.7919e-04,  3.2370e-02,  3.6766e-02,\n",
       "          2.4986e-02,  6.0303e-04,  4.1531e-02, -2.0416e-02,  3.6249e-02,\n",
       "          3.8137e-02,  5.3390e-02,  2.8590e-02,  4.0459e-02,  5.7189e-02,\n",
       "          3.0323e-02,  2.6251e-02,  4.2108e-02,  3.3788e-01,  2.4742e-02,\n",
       "         -2.1341e-02,  2.5394e-02,  2.5185e-02,  3.4734e-03,  1.8485e-02,\n",
       "          7.6756e-03,  1.0611e-02,  1.4992e-02,  7.9128e-03,  1.0905e-02,\n",
       "         -3.9157e-03, -2.0122e-02,  1.0011e-02,  3.0892e-02,  2.4538e-03,\n",
       "          1.5397e-02,  5.3747e-02, -1.5423e-02,  3.6599e-02, -7.1308e-03,\n",
       "          6.1582e-03,  3.8073e-02, -6.4656e-03,  3.2223e-02, -3.0139e-03,\n",
       "          3.1230e-02, -1.3427e-02,  2.2051e-02,  3.4040e-03,  2.8121e-02,\n",
       "          2.0565e-02,  4.5798e-02,  1.1976e-02,  1.4449e-02,  3.0251e-02,\n",
       "          2.6776e-02,  8.5797e-02,  2.5977e-04,  4.7272e-02, -1.0841e-03,\n",
       "          1.8195e-02,  1.8218e-02,  2.8540e-02,  6.7993e-03,  3.5639e-02,\n",
       "          2.9599e-02,  2.4892e-02, -2.8580e-03,  2.1860e-02,  1.8337e-02,\n",
       "          8.1896e-03,  7.1606e-03,  1.7517e-02,  1.8818e-02,  1.2455e-02,\n",
       "          5.0942e-02,  1.0982e-02,  2.1877e-02,  6.7266e-03,  4.9079e-03,\n",
       "          2.9072e-02,  2.0166e-02,  1.8988e-02,  6.0607e-02,  3.5498e-02,\n",
       "          3.9689e-02,  1.1732e-02,  3.2019e-02, -7.8117e-03,  1.3688e-02,\n",
       "          2.1697e-02,  5.7341e-02,  4.0743e-02,  6.6843e-02,  3.4915e-02,\n",
       "          1.8039e-02,  8.2446e-03,  1.6047e-02,  3.0304e-02,  4.3722e-02,\n",
       "          1.4338e-02,  1.5648e-02,  3.0412e-02,  8.0503e-04,  4.4321e-02,\n",
       "          3.2069e-02,  2.9099e-03,  3.4809e-02,  3.7059e-02,  3.0682e-02,\n",
       "          4.4311e-02,  3.7483e-02,  2.7851e-02,  2.5533e-02,  2.6303e-02,\n",
       "          2.0085e-02,  4.1493e-02,  8.9645e-03,  3.0944e-03,  2.6097e-02,\n",
       "          6.6764e-02,  2.7084e-03,  2.6569e-02,  3.2081e-02,  2.9702e-03,\n",
       "          1.3219e-02,  2.0836e-02,  1.3685e-02,  3.5987e-03,  1.0517e-02,\n",
       "          1.4312e-02,  1.2074e-02, -1.0478e-02,  2.5274e-02,  2.6911e-02,\n",
       "          1.0097e-01,  9.9682e-03,  1.8130e-02,  4.0114e-02,  4.3335e-02,\n",
       "          3.2085e-03,  4.3071e-02,  3.3993e-02,  3.3701e-02,  2.5201e-03,\n",
       "         -1.5116e-02, -7.2455e-02,  4.2337e-02,  4.0797e-02,  2.2369e-02,\n",
       "          2.2718e-02,  1.6584e-02, -1.3213e-02,  1.1772e-02,  1.1397e-02,\n",
       "          2.9617e-02,  2.3913e-02,  1.8444e-02,  3.3094e-02,  3.8922e-02,\n",
       "          4.6575e-02,  1.2183e-02,  2.6243e-02,  6.8510e-02,  2.2780e-03,\n",
       "          1.0124e-02,  2.2449e-02,  8.6296e-03, -1.6431e-01,  4.9237e-02,\n",
       "          4.8695e-02, -3.1594e-03,  3.1461e-02,  2.8214e-02,  1.3456e-02,\n",
       "          1.9882e-02,  3.4631e-02,  2.4248e-02, -3.5280e-03,  2.1640e-02,\n",
       "          1.2597e-02,  7.1220e-03,  1.1988e-02,  2.5425e-02,  1.4709e-03,\n",
       "          5.3826e-03,  3.6498e-02,  2.5552e-02,  3.3139e-02,  2.6447e-02,\n",
       "         -1.1497e-02,  5.5716e-02,  1.3308e-02, -6.7223e-03,  2.4045e-02,\n",
       "          2.2624e-02,  3.7223e-02,  2.6761e-02,  5.4413e-02,  1.4670e-02,\n",
       "          2.1103e-02,  2.0297e-02,  2.5275e-02, -2.4169e-03,  1.0851e-02,\n",
       "          1.0792e-02, -2.5108e-01,  1.5956e-02,  3.9030e-02, -5.4340e-03,\n",
       "          1.4072e-02, -1.2481e-02,  1.9383e-02,  2.3584e-02,  5.8051e-02,\n",
       "          3.7730e-03,  4.6452e-02,  1.5874e-02,  3.9195e-02,  2.8941e-02,\n",
       "         -8.1308e-03,  2.4481e-02,  2.6067e-02,  9.3105e-03,  3.3713e-02,\n",
       "          3.7100e-02, -1.2273e-02, -1.6410e-02,  2.4022e-02,  4.7408e-02,\n",
       "          3.4378e-02,  4.3000e-02,  2.5137e-02,  4.4269e-03,  4.9077e-02,\n",
       "          3.1481e-02,  1.0652e-02,  2.6449e-02, -1.4687e-02,  1.4857e-02,\n",
       "         -3.2030e-06,  3.4278e-02,  4.2626e-02,  4.3518e-02,  5.9497e-02,\n",
       "          3.0237e-02,  4.7823e-02,  2.2643e-02,  2.5692e-02,  7.3306e-02,\n",
       "          3.6672e-02,  1.4671e-02,  2.3230e-02,  6.9136e-01,  6.4758e-02,\n",
       "          5.6275e-02, -8.1179e-03,  1.2797e-02, -5.9154e-02,  2.2879e-02,\n",
       "          4.0809e-02,  1.1079e-02,  2.3431e-02,  1.9926e-03,  2.5910e-02,\n",
       "          3.1874e-02,  5.4008e-03,  1.6043e-02,  1.9226e-02,  3.7281e-02,\n",
       "          5.1407e-02,  1.7173e-02,  1.5955e-02, -5.9317e-02,  1.2196e-02,\n",
       "          1.0802e-02,  3.0468e-03,  5.8788e-03,  2.2304e-02,  3.2142e-02,\n",
       "          1.3249e-02,  2.8839e-02,  3.7375e-02,  3.6929e-02,  1.7584e-02,\n",
       "          1.9938e-02,  1.0190e-02,  3.5776e-02,  1.7384e-02,  3.5547e-02,\n",
       "          2.4908e-03,  3.4021e-02, -5.4762e-03, -8.3075e-03,  1.9333e-02,\n",
       "          3.5979e-02,  1.6277e-02,  2.9949e-02,  3.6957e-02,  3.3667e-02,\n",
       "          3.0161e-02,  1.7595e-02,  4.1365e-02,  1.5934e-02,  2.7179e-02,\n",
       "          5.5548e-02,  7.0083e-02, -2.4011e-03,  1.1384e-02,  1.8920e-03,\n",
       "         -1.1522e-01,  2.5727e-02,  1.6895e-02,  8.3255e-03,  2.3962e-02,\n",
       "          6.0353e-02,  1.7068e-02,  4.7377e-02,  2.7464e-02,  4.8743e-02,\n",
       "          7.5937e-02,  3.4020e-02,  5.8768e-02,  5.1526e-02,  1.9177e-02,\n",
       "          1.2255e-02,  1.7058e-02, -3.0584e-01,  5.3723e-02,  5.2641e-02,\n",
       "          7.4931e-03,  8.0473e-03,  5.1533e-02,  2.6815e-02,  1.6538e-02,\n",
       "          7.7585e-03,  3.7131e-02,  2.8426e-02,  1.6543e-02,  3.0388e-02,\n",
       "         -9.6813e-03,  2.6446e-02,  5.9391e-02,  3.3866e-02, -1.3877e-02,\n",
       "          5.0415e-02, -7.9023e-03,  3.6284e-02,  1.2733e-02,  2.2542e-02,\n",
       "          3.6630e-02,  9.2280e-03,  3.8719e-02,  4.1514e-02,  4.8284e-02,\n",
       "         -1.4673e-02,  3.9955e-02,  3.1786e-02,  2.8342e-02,  6.0084e-02,\n",
       "         -5.6054e-03, -6.0051e-01,  1.3674e-02,  5.3414e-03,  2.1680e-02,\n",
       "          1.7339e-02,  1.7631e-02,  2.5795e-02,  5.4288e-02,  4.1404e-03,\n",
       "          1.6550e-02,  2.0046e-02,  1.2296e-02,  1.9723e-02,  9.6581e-03,\n",
       "          3.0429e-02, -9.5211e-02,  5.8852e-02,  2.3260e-02,  7.0863e-03,\n",
       "          3.1864e-02,  4.1533e-02,  3.8262e-02,  2.9270e-03, -2.4406e-03,\n",
       "         -7.0459e-04,  2.0805e-02,  3.1979e-02,  8.6200e-03,  4.7225e-02,\n",
       "          1.0877e-02,  6.8129e-03,  4.8274e-02,  2.1957e-02,  2.3721e-02,\n",
       "          3.3818e-02,  1.1655e-02,  4.6021e-02,  1.8045e-02, -1.3827e-02,\n",
       "         -3.9979e-03,  2.9055e-02,  7.4535e-02,  1.1002e-02,  2.0955e-02,\n",
       "         -3.2250e-02,  9.2323e-02,  6.0631e-02,  4.8247e-02,  2.5260e-02,\n",
       "          3.8033e-02,  2.6952e-02,  1.2707e-02,  2.3304e-02, -6.8546e-03,\n",
       "          2.3727e-02,  9.9788e-03, -7.4584e-04,  4.4504e-02,  3.0539e-02,\n",
       "          2.0200e-02,  4.6410e-03, -5.3424e-03,  2.6282e-03,  1.8000e-02,\n",
       "          2.2171e-02,  5.0755e-02,  5.0623e-02,  2.8502e-02, -6.8178e-03,\n",
       "          2.2921e-03,  3.9287e-02,  8.1652e-03,  1.6192e-02,  4.5056e-02,\n",
       "          1.9333e-02,  9.0636e-03,  1.0507e-02,  2.5045e-02,  3.0355e-02,\n",
       "          3.2846e-02,  4.5357e-02,  2.5181e-02,  4.5486e-02,  1.5991e-02,\n",
       "          9.1249e-03, -1.6159e-03, -3.3242e-03,  5.0166e-03, -1.1907e-02,\n",
       "          2.4148e-02,  1.4709e-02,  6.0083e-02, -5.4288e-03,  1.1880e-02,\n",
       "         -1.2682e-02,  9.9845e-03,  3.1314e-02,  5.4775e-02,  2.1177e-02,\n",
       "          3.4766e-02,  2.6360e-02,  5.2954e-02,  2.3196e-02,  2.8086e-02,\n",
       "         -1.5350e-02,  3.5632e-03,  2.0230e-02, -2.5101e-03,  3.2721e-02,\n",
       "         -5.2974e-03,  2.7180e-03,  4.6001e-02,  2.1882e-02,  2.3802e-02,\n",
       "         -3.7108e-03, -8.5181e-03,  2.8182e-02,  2.7818e-02,  2.3665e-02,\n",
       "          2.7919e-02,  7.8592e-04,  3.3945e-02,  2.3061e-02,  2.6832e-02,\n",
       "          4.5391e-02,  1.1655e-02,  2.3164e-03,  5.1892e-02,  1.2260e-02,\n",
       "          8.7936e-03, -1.3305e-02, -4.6087e-04,  3.5252e-02, -1.0717e-02,\n",
       "          5.9545e-03,  2.4296e-02,  3.2646e-02,  1.7622e-03,  6.5688e-02,\n",
       "          2.3266e-02,  2.1682e-02,  3.1347e-02,  2.6992e-02,  4.4732e-02,\n",
       "          4.2366e-02, -1.2863e-03,  7.0720e-03,  4.3547e-03,  2.3147e-02,\n",
       "          4.1584e-02,  5.8816e-03,  4.4269e-02,  2.1353e-03,  6.1128e-02,\n",
       "          6.8275e-02,  4.4310e-02,  4.5049e-02,  3.3080e-02,  8.5815e-03,\n",
       "         -5.4939e-02, -7.2536e-04, -2.6956e-03,  1.9162e-02,  4.3828e-02,\n",
       "          1.7810e-02,  1.5744e-02,  1.9663e-02,  9.2914e-03,  2.1843e-02,\n",
       "          1.8821e-02,  2.9652e-02,  5.2211e-03, -3.3464e-03,  1.2501e-02,\n",
       "          3.5486e-02,  7.3340e-03, -1.1261e-02,  2.0094e-02,  1.5204e-02,\n",
       "          1.0204e-02,  4.1609e-02,  1.3557e-02,  6.7135e-02,  1.2011e-02,\n",
       "          2.5460e-02,  6.1166e-03,  1.5924e-02,  4.5425e-02,  8.7188e-02,\n",
       "          3.5348e-02,  3.0157e-02, -2.1819e-02,  2.8529e-02, -1.4283e-02,\n",
       "          2.1892e-02,  1.8951e-02,  4.7751e-02,  2.6668e-02,  2.9404e-02,\n",
       "          1.0511e-02,  1.5914e-02, -1.1116e-02,  3.7344e-02,  2.0180e-02,\n",
       "          2.2825e-02,  3.1746e-02,  2.1207e-02,  2.7221e-02,  4.5675e-02,\n",
       "          4.1321e-02,  2.7240e-02,  2.8394e-02,  6.6000e-02,  2.5427e-02,\n",
       "          3.3961e-02,  9.0295e-03,  3.4376e-02,  1.4984e-02,  8.0904e-03,\n",
       "          1.6822e-02,  2.2855e-03,  9.1259e-03, -9.2325e-03,  5.7467e-02,\n",
       "          2.9218e-03, -2.2570e-02,  1.7161e-02,  1.2237e-02, -2.6738e-02,\n",
       "          1.0197e-03,  5.3789e-03,  3.9366e-02,  5.4971e-02,  8.0899e-03,\n",
       "          3.5850e-02,  4.6131e-03,  2.0722e-02, -3.1729e-02,  2.9270e-02,\n",
       "          3.3209e-02,  3.2098e-02,  6.1395e-02, -1.2445e-02,  7.2913e-02,\n",
       "          2.4019e-02,  2.5712e-02,  3.7966e-02, -1.0105e-02,  2.5099e-02,\n",
       "          1.4116e-02,  1.3625e-02,  2.1187e-02,  1.3063e-02,  4.3473e-04,\n",
       "          1.3430e-02,  1.5159e-02,  1.6721e-02,  3.1475e-02,  2.6737e-02,\n",
       "         -1.0435e-02,  2.5066e-02,  3.9083e-02,  2.1112e-02,  2.4588e-02,\n",
       "          1.3874e-01,  3.0582e-02,  4.4362e-02,  3.6819e-02,  2.8616e-02,\n",
       "          1.3359e-02,  1.4427e-02,  4.7326e-03,  9.0515e-03,  3.2625e-02,\n",
       "          3.0964e-02,  7.8371e-02,  3.4118e-02,  3.3910e-02,  2.2646e-02,\n",
       "          1.4631e-02,  1.8085e-02, -1.1369e-02, -1.4955e-02,  1.8636e-02,\n",
       "          3.3812e-02,  2.1553e-02,  6.5092e-04]),\n",
       " 'h.10.ln_2.weight': tensor([0.2976, 0.2666, 0.2978, 0.2740, 0.3013, 0.2871, 0.5526, 0.2613, 0.2840,\n",
       "         0.2607, 0.2947, 0.2736, 0.2764, 0.2916, 0.3057, 0.2851, 0.3029, 0.2802,\n",
       "         0.2998, 0.3194, 0.2549, 0.2699, 0.2869, 0.2764, 0.2822, 0.2803, 0.2859,\n",
       "         0.2704, 0.2784, 0.2747, 0.2725, 0.3135, 0.2933, 0.2725, 0.2881, 0.3330,\n",
       "         0.2535, 0.2802, 0.2626, 0.2842, 0.2744, 0.2588, 0.2627, 0.2859, 0.2897,\n",
       "         0.2822, 0.2789, 0.2646, 0.3172, 0.2881, 0.2787, 0.2839, 0.2794, 0.2920,\n",
       "         0.2900, 0.3467, 0.2915, 0.3166, 0.2666, 0.3272, 0.3092, 0.2781, 0.2900,\n",
       "         0.3012, 0.1870, 0.2705, 0.2763, 0.3206, 0.3549, 0.2705, 0.2959, 0.2180,\n",
       "         0.2725, 0.2929, 0.2627, 0.2920, 0.2958, 0.3896, 0.3016, 0.2939, 0.2998,\n",
       "         0.2686, 0.2780, 0.3057, 0.3236, 0.3111, 0.3226, 0.0201, 0.2874, 0.2666,\n",
       "         0.2783, 0.2679, 0.2900, 0.2904, 0.2789, 0.2607, 0.2795, 0.2881, 0.2705,\n",
       "         0.2946, 0.2607, 0.2395, 0.3780, 0.3029, 0.2822, 0.2788, 0.3033, 0.3589,\n",
       "         0.2764, 0.2685, 0.2932, 0.2761, 0.2814, 0.2951, 0.2826, 0.2872, 0.3173,\n",
       "         0.2856, 0.2469, 0.3256, 0.2900, 0.2794, 0.2705, 0.2959, 0.3114, 0.2873,\n",
       "         0.2725, 0.2822, 0.3213, 0.2803, 0.2837, 0.2725, 0.2956, 0.2833, 0.2898,\n",
       "         0.2704, 0.2822, 0.3363, 1.0951, 0.2872, 0.2915, 0.2899, 0.3654, 0.2666,\n",
       "         0.2900, 0.3300, 0.2971, 0.2979, 0.2725, 0.2896, 0.2921, 0.2955, 0.3170,\n",
       "         0.3057, 0.2888, 0.2728, 0.2887, 0.2931, 0.2737, 0.3213, 0.3665, 0.2842,\n",
       "         0.3056, 0.3076, 0.2900, 0.2894, 0.2917, 0.4131, 0.2704, 0.3154, 0.2783,\n",
       "         0.2791, 0.2780, 0.3042, 0.2998, 0.2739, 0.3017, 0.2607, 0.3018, 0.2835,\n",
       "         0.2820, 0.2705, 0.2744, 0.2998, 0.2588, 0.2607, 0.2686, 0.2822, 0.2801,\n",
       "         0.2939, 0.2725, 0.3172, 0.2822, 0.2959, 0.2686, 0.3595, 0.2616, 0.2958,\n",
       "         0.2777, 0.3174, 0.3146, 0.2980, 0.2783, 0.2823, 0.2764, 0.2897, 0.2725,\n",
       "         0.2407, 0.3135, 0.2763, 0.2816, 0.3184, 0.2839, 0.3071, 0.2881, 0.2760,\n",
       "         0.3230, 0.2842, 0.1939, 0.2666, 0.2752, 0.2725, 0.2586, 0.3012, 0.3156,\n",
       "         0.2803, 0.2705, 0.2705, 0.2829, 0.2608, 0.2645, 0.2968, 0.4358, 0.2705,\n",
       "         0.2750, 0.3017, 0.2955, 0.2705, 0.2968, 0.3001, 0.3099, 0.3223, 0.2822,\n",
       "         0.2664, 0.2646, 0.2881, 0.2762, 0.3076, 0.2840, 0.2921, 0.2861, 0.2764,\n",
       "         0.2744, 0.2861, 0.2761, 0.3478, 0.3037, 0.2957, 0.2861, 0.2859, 0.2815,\n",
       "         0.2979, 0.2784, 0.2958, 0.2824, 0.2595, 0.0720, 0.3310, 0.2822, 0.2901,\n",
       "         0.3643, 0.3545, 0.2743, 0.2810, 0.3217, 0.2705, 0.2782, 0.2666, 0.2621,\n",
       "         0.2715, 0.2568, 0.2526, 0.2979, 0.3584, 0.3213, 0.2979, 0.2950, 0.2666,\n",
       "         0.5094, 0.3096, 0.2885, 0.2807, 0.2761, 0.2607, 0.3096, 0.2600, 0.2646,\n",
       "         0.2920, 0.2725, 0.2979, 0.2900, 0.2920, 0.2978, 0.2646, 0.2588, 0.2782,\n",
       "         0.2800, 0.2641, 0.3124, 0.2627, 0.2646, 0.3487, 0.2858, 0.2798, 0.2509,\n",
       "         0.2780, 0.3033, 0.2900, 0.2724, 0.3086, 0.3528, 0.2744, 0.2687, 0.2897,\n",
       "         0.2719, 0.2822, 0.5527, 0.2822, 0.2822, 0.2803, 0.2920, 0.2781, 0.2862,\n",
       "         0.2842, 0.2666, 0.2972, 0.3071, 0.2764, 0.2861, 0.3059, 0.2752, 0.2685,\n",
       "         0.3044, 0.3034, 0.3036, 0.3057, 0.2822, 0.2863, 0.2959, 0.2689, 0.2803,\n",
       "         0.2529, 0.2737, 0.2979, 0.3076, 0.2822, 0.2975, 0.2810, 0.2822, 0.2822,\n",
       "         0.2930, 0.2706, 0.4616, 0.2686, 0.2659, 0.3373, 0.2996, 0.2702, 0.2659,\n",
       "         0.3018, 0.2951, 0.2725, 0.2783, 0.0522, 0.2702, 0.3266, 0.2979, 0.3172,\n",
       "         0.2367, 0.2881, 0.2851, 0.2697, 0.2802, 0.3057, 0.3096, 0.3252, 0.3017,\n",
       "         0.2763, 0.2801, 0.3233, 0.2890, 0.2574, 0.3055, 0.6621, 0.3052, 0.2707,\n",
       "         0.2900, 0.2734, 0.2735, 0.2657, 0.2707, 0.2920, 0.3076, 0.2959, 0.2631,\n",
       "         0.3017, 0.3112, 0.2585, 0.3474, 0.2744, 0.2567, 0.2625, 0.2796, 0.2646,\n",
       "         0.2978, 0.2822, 0.2654, 0.2978, 0.2847, 0.2861, 0.2133, 0.3018, 0.2741,\n",
       "         0.2998, 0.2704, 0.2604, 0.2847, 0.2862, 0.2805, 0.2554, 0.2232, 0.2705,\n",
       "         0.2806, 0.2833, 0.2666, 0.3174, 0.2666, 0.2900, 0.2901, 0.3153, 0.3271,\n",
       "         0.3017, 0.3501, 0.2744, 0.3037, 0.2783, 0.2694, 0.0606, 0.2783, 0.2876,\n",
       "         0.2889, 0.2801, 0.2744, 0.3054, 0.3021, 0.3090, 0.2940, 0.2783, 0.2687,\n",
       "         0.1821, 0.2900, 0.2822, 0.2867, 0.2744, 0.1579, 0.2822, 0.2959, 0.2722,\n",
       "         0.2702, 0.2863, 0.2749, 0.2895, 0.2939, 0.2764, 0.2575, 0.2992, 0.2686,\n",
       "         0.2705, 0.2685, 0.3664, 0.0253, 0.0485, 0.2920, 0.2743, 0.2920, 0.2666,\n",
       "         0.2803, 0.2817, 0.3225, 0.2725, 0.2842, 0.3001, 0.2606, 0.2725, 0.2751,\n",
       "         0.2722, 0.1523, 0.2143, 0.2899, 0.2790, 0.2978, 0.2764, 0.2939, 0.3815,\n",
       "         0.3144, 0.2643, 0.2773, 0.3252, 0.3054, 0.2705, 0.2705, 0.2969, 0.2782,\n",
       "         0.2811, 0.2828, 0.3013, 0.2744, 0.2783, 0.2795, 0.2665, 0.2525, 0.2822,\n",
       "         0.2998, 0.2939, 0.2803, 0.2842, 0.4467, 0.3174, 0.3037, 0.2666, 0.2981,\n",
       "         0.2963, 0.2602, 0.2685, 0.2859, 0.2900, 0.2744, 0.2861, 0.3075, 0.2900,\n",
       "         0.3075, 0.2861, 0.2830, 0.3485, 0.2764, 0.2959, 0.3012, 0.2761, 0.2744,\n",
       "         0.3428, 0.2783, 0.3252, 0.2939, 0.2919, 0.3531, 0.2986, 0.2744, 0.2910,\n",
       "         0.2782, 0.2803, 0.2978, 0.2854, 0.2900, 0.2860, 0.2682, 0.2803, 0.3389,\n",
       "         0.3076, 0.3000, 0.3048, 0.3253, 0.2978, 0.3037, 0.2904, 0.2842, 0.2998,\n",
       "         0.2653, 0.2777, 0.3346, 0.2948, 0.2725, 0.2593, 0.3174, 0.2900, 0.2705,\n",
       "         0.2947, 0.2705, 0.2958, 0.2920, 0.2842, 0.2900, 0.2832, 0.2646, 0.2777,\n",
       "         0.2764, 0.2764, 0.2872, 0.2800, 0.2659, 0.2567, 0.3003, 0.2918, 0.3047,\n",
       "         0.2959, 0.2928, 0.2789, 0.3037, 0.2911, 0.4346, 0.2738, 0.2914, 0.2822,\n",
       "         0.2879, 0.2961, 0.2955, 0.3057, 0.3271, 0.2803, 0.2918, 0.2892, 0.2971,\n",
       "         0.2803, 0.2836, 0.2807, 0.2959, 0.2744, 0.2805, 0.3561, 0.2825, 0.2822,\n",
       "         0.2788, 0.2781, 0.2734, 0.2715, 0.2822, 0.3328, 0.2842, 0.2760, 0.2779,\n",
       "         0.2881, 0.5528, 0.2979, 0.2447, 0.3029, 0.3114, 0.2920, 0.2842, 0.3193,\n",
       "         0.2916, 0.3604, 0.2567, 0.3252, 0.2745, 0.2900, 0.2704, 0.2938, 0.2756,\n",
       "         0.2881, 0.2666, 0.3292, 0.2606, 0.2939, 0.2722, 0.2764, 0.2725, 0.3154,\n",
       "         0.2680, 0.2979, 0.2881, 0.3272, 0.3076, 0.2762, 0.2916, 0.2725, 0.2553,\n",
       "         0.2725, 0.2802, 0.2818, 0.3076, 0.3946, 0.3193, 0.2741, 0.2982, 0.2897,\n",
       "         0.2699, 0.2761, 0.2977, 0.2671, 0.2959, 0.2803, 0.2686, 0.2636, 0.2861,\n",
       "         0.3090, 0.2861, 0.2803, 0.2803, 0.2607, 0.2920, 0.3017, 0.2744, 0.3099,\n",
       "         0.2685, 0.4283, 0.2766, 0.2939, 0.3325, 0.3111, 0.2700, 0.3934, 0.3037,\n",
       "         0.2571, 0.2720, 0.2800, 0.2669, 0.3043, 0.2543, 0.2744, 0.3115, 0.2728,\n",
       "         0.2686, 0.3563, 0.2704, 0.2750, 0.3076, 0.3057, 0.3115, 0.2978, 0.2994,\n",
       "         0.2975, 0.2900, 0.2979, 0.2825, 0.2920, 0.2861, 0.2979, 0.2718, 0.2673,\n",
       "         0.2981, 0.3635, 0.3018, 0.2875, 0.2801, 0.2958, 0.2864, 0.2470, 0.3422,\n",
       "         0.2744, 0.3037, 0.2861, 0.2752, 0.2782, 0.2822, 0.2684, 0.3010, 0.3135,\n",
       "         0.1586, 0.2822, 0.2784, 0.2958, 0.2578, 0.2937, 0.3352, 0.2654, 0.2607,\n",
       "         0.2770, 0.2644, 0.2911]),\n",
       " 'h.10.mlp.c_fc.bias': tensor([-0.0678,  0.0492, -0.1440,  ..., -0.0373, -0.3087, -0.1231]),\n",
       " 'h.10.mlp.c_fc.weight': tensor([[-0.0470, -0.1844,  0.0954,  ..., -0.1219,  0.0784,  0.0695],\n",
       "         [ 0.0465, -0.2866, -0.0475,  ..., -0.1587,  0.0991,  0.0961],\n",
       "         [ 0.1747, -0.0565, -0.0819,  ...,  0.0196,  0.0371,  0.0941],\n",
       "         ...,\n",
       "         [ 0.0594, -0.0186, -0.2675,  ..., -0.1615,  0.0099, -0.2356],\n",
       "         [-0.0591,  0.0056,  0.0860,  ..., -0.0222, -0.0652, -0.1163],\n",
       "         [-0.1588,  0.0426, -0.0066,  ..., -0.0767,  0.0009, -0.0639]]),\n",
       " 'h.10.mlp.c_proj.bias': tensor([-3.8143e-02,  2.5599e-02, -2.0104e-01,  1.4348e-01,  1.7296e-01,\n",
       "         -1.0449e-01,  2.3975e-01,  3.1738e-01,  2.6895e-01, -3.7742e-02,\n",
       "         -2.1719e-01, -1.3379e-01, -1.6686e-02,  1.1986e-01, -4.6542e-02,\n",
       "         -3.7086e-02, -6.1694e-02,  3.7257e-01,  2.7303e-01, -2.3525e-01,\n",
       "          4.0211e-02,  1.3741e-02,  1.4994e-01, -8.7482e-03, -2.8816e-01,\n",
       "         -4.8289e-02, -1.4627e-01,  1.3170e-01,  5.7696e-02,  7.8080e-02,\n",
       "          1.6892e-01,  1.4323e-01,  1.9676e-01, -2.7084e-01, -1.7095e-02,\n",
       "         -2.2893e-01,  3.7549e-01, -6.1329e-02,  1.2292e-02, -1.4345e-04,\n",
       "          4.6832e-03, -1.4181e-01,  1.1796e-01, -1.0276e-01, -1.2250e-01,\n",
       "         -2.5222e-01,  9.4139e-02,  2.4413e-01,  8.8424e-02,  2.8009e-01,\n",
       "          2.0151e-01, -5.7480e-03, -1.8841e-02,  4.0198e-02,  5.7171e-02,\n",
       "          1.8770e-01, -4.3182e-02,  7.2363e-02, -8.2459e-02,  9.9696e-03,\n",
       "         -1.8823e-01,  7.0356e-02,  3.1884e-01, -2.3913e-01, -7.5639e-01,\n",
       "          1.2948e-01,  7.3434e-02, -1.2257e-02, -2.5637e-01, -9.4662e-02,\n",
       "          1.3555e-01, -2.5064e-02,  1.0826e-01, -1.2222e-01,  6.5764e-02,\n",
       "          6.0241e-03, -8.9593e-02, -3.5348e-01, -1.7470e-01, -1.1654e-01,\n",
       "          1.2474e-02,  1.2593e-01, -5.3945e-02, -9.4816e-02, -2.0751e-01,\n",
       "          1.1186e-02,  2.5762e-01, -5.1091e-01, -6.1145e-02, -5.4759e-02,\n",
       "         -4.2531e-03,  9.5853e-02, -1.2925e-01,  2.4003e-01, -1.2552e-03,\n",
       "          4.7027e-02, -2.4122e-01,  1.9284e-01,  1.5343e-01, -1.4140e-01,\n",
       "         -1.2101e-01,  1.5099e-01,  3.2635e-01,  2.5328e-01, -1.4151e-01,\n",
       "          8.5708e-02,  2.3137e-01,  1.3640e-01, -1.4373e-01,  1.2222e-01,\n",
       "          9.3257e-02,  4.6817e-02,  7.6846e-02,  8.2065e-02, -1.8397e-01,\n",
       "          8.8908e-02, -9.8975e-02,  1.0629e-01,  2.4419e-02, -1.4808e-01,\n",
       "          2.3604e-01,  1.1292e-01,  1.7406e-01,  7.7582e-02,  4.3627e-01,\n",
       "         -7.5567e-02, -8.8554e-02, -1.1853e-01, -1.1230e-01,  7.6000e-02,\n",
       "         -3.1416e-02,  5.9794e-02, -1.9011e-01,  3.0470e-01,  4.3425e-01,\n",
       "          1.6238e-02,  7.3720e-03, -1.9312e-01, -2.5405e-01,  8.1005e-02,\n",
       "          1.3216e-01,  1.8647e-01, -1.5464e-01, -1.7287e-01, -3.6527e-01,\n",
       "          1.5677e-01, -3.1230e-02,  1.5665e-01, -3.5846e-02, -1.6030e-02,\n",
       "         -2.4349e-01,  2.4982e-01,  4.3248e-01,  2.1962e-01,  1.8951e-01,\n",
       "          1.3434e-01,  1.9932e-01,  1.6355e-01,  2.7505e-01, -2.3918e-02,\n",
       "          3.0964e-01, -7.3299e-02, -1.6255e-01, -7.1651e-02,  1.2032e-01,\n",
       "         -6.8780e-02,  5.6922e-02, -1.7021e-01,  1.2268e-01,  1.2964e-01,\n",
       "         -1.4666e-01,  8.4830e-02,  1.5973e-01, -1.0504e-01, -7.7611e-02,\n",
       "          8.3413e-02, -3.7759e-01,  1.8042e-01,  1.2408e-01, -1.7245e-02,\n",
       "          9.2364e-02,  1.3709e-01,  1.1227e-01, -9.1766e-02, -1.3294e-01,\n",
       "          9.1459e-02, -1.3241e-01, -1.1060e-01, -6.8468e-02,  1.0740e-01,\n",
       "          2.2344e-01, -4.6891e-01, -6.7498e-02, -8.1809e-02,  2.2811e-01,\n",
       "         -1.6033e-01, -2.6327e-01, -1.9903e-01,  3.2382e-01,  3.5482e-02,\n",
       "          2.1925e-01, -3.4115e-02,  8.7567e-02,  7.3009e-02,  1.3954e-01,\n",
       "         -1.0720e-01, -1.9729e-01, -7.7086e-02, -1.4805e-02, -2.0860e-01,\n",
       "          6.7832e-02, -2.2851e-03,  1.4290e-01,  1.0806e-01,  1.3177e-01,\n",
       "         -2.1775e-01,  6.9232e-02, -1.3349e-01, -8.3663e-02, -7.0714e-02,\n",
       "         -6.5278e-02, -2.1721e-01,  1.4354e-01, -9.2345e-02,  1.2621e-01,\n",
       "          1.5472e-01,  1.9213e-01,  1.6357e-01,  1.9801e-02, -1.2216e-01,\n",
       "          2.1403e-02,  2.0315e-01,  2.8329e-01, -1.6874e-01,  1.7956e-01,\n",
       "         -1.5323e-01,  6.5958e-02, -1.4719e-01,  1.3041e-01,  4.6650e-02,\n",
       "          1.7008e-01, -1.3723e-01, -4.5214e-02, -1.8821e-01,  3.7930e-02,\n",
       "          1.0018e-01,  4.8997e-02,  8.2434e-02, -2.5882e-01, -2.0671e-01,\n",
       "         -2.0532e-02,  6.6051e-02,  3.0145e-02,  4.8899e-02,  1.3834e-01,\n",
       "          2.6462e-02, -2.9981e-01,  1.1138e-01,  3.3417e-01, -3.5646e-02,\n",
       "         -3.0519e-02,  1.5504e-01, -3.4763e-01, -1.4912e-01, -3.2172e-01,\n",
       "         -1.4177e-01,  5.4598e-01,  1.0665e-01, -2.4090e-01,  4.6356e-02,\n",
       "         -4.4664e-01,  7.1574e-02,  2.0512e-02, -1.9377e-01, -1.6301e-02,\n",
       "         -2.6721e-02,  2.4572e-01, -1.4274e-01,  7.2313e-02,  6.1251e-02,\n",
       "          6.5675e-02, -1.1732e-01,  1.6584e-01, -3.4024e-01,  2.0874e-01,\n",
       "         -3.1980e-02,  1.4726e-02,  2.1803e-01,  4.7385e-02, -1.2282e-01,\n",
       "         -1.4817e-01,  6.5807e-02,  3.3150e-01, -1.6795e-02, -4.9827e-01,\n",
       "          4.5978e-02,  8.4362e-02,  9.1172e-02,  2.0120e-03, -1.1323e-01,\n",
       "          1.6160e-01, -3.7206e-01,  1.2649e-01,  6.5695e-02, -2.6316e-02,\n",
       "         -2.2873e-01, -9.1453e-02,  2.1830e-01, -3.3229e-01,  7.2913e-02,\n",
       "         -6.5246e-02, -3.0352e-01,  6.7573e-02, -1.9244e-01, -4.4533e-01,\n",
       "         -1.0069e-01,  4.8872e-01,  8.0938e-02, -7.3544e-02, -8.3964e-02,\n",
       "         -2.0925e-01, -5.8470e-03,  2.6306e-01,  1.2856e-01, -1.3729e-01,\n",
       "         -5.3144e-02,  4.6033e-01,  2.5003e-02,  8.2404e-02, -1.3840e-02,\n",
       "          1.2217e-01, -3.6007e-02, -6.4687e-02,  7.5287e-02, -1.9078e-01,\n",
       "          7.7334e-03, -2.5034e-01, -8.9020e-02, -1.1531e-01,  4.8968e-02,\n",
       "         -1.8849e-01,  5.2834e-02,  1.7361e-01,  8.8387e-02, -9.5664e-02,\n",
       "          5.0541e-02,  2.1083e-01,  1.2897e-01,  7.9816e-02, -1.6714e-01,\n",
       "         -4.0522e-02,  3.7384e-02,  6.0570e-02, -1.2221e-01,  1.8752e-01,\n",
       "         -2.1690e-02, -5.0092e-01,  1.9677e-01, -5.0628e-01,  1.5160e-01,\n",
       "         -2.7060e-01, -8.4371e-02,  2.5535e-01,  1.5280e-01,  1.8634e-01,\n",
       "         -1.0199e-01, -5.7972e-03,  2.4652e-01, -5.5806e-02, -1.5157e-01,\n",
       "         -1.0008e-01, -1.9642e-02, -2.2094e-01, -1.0768e+00, -2.9864e-01,\n",
       "         -4.2762e-01, -1.1246e-01,  3.9854e-01,  2.4553e-01,  1.9120e-01,\n",
       "          5.4409e-02,  1.8443e-01, -4.2112e-02,  1.1395e-01, -4.3893e-02,\n",
       "          6.0759e-02, -1.1300e-02,  3.4083e-02,  2.1713e-01, -1.8448e-01,\n",
       "          2.0593e-02, -1.9448e-01,  1.4154e-01,  3.2273e-01, -6.9914e-02,\n",
       "         -5.7180e-02, -1.0634e-01, -2.7934e-02,  1.4282e-01, -1.3052e-01,\n",
       "          2.3706e-01,  1.2440e-01,  1.8414e-01,  6.2075e-02, -5.1292e-02,\n",
       "          8.3658e-02, -1.5651e-01, -1.0092e-02,  4.0387e-01,  1.6928e-01,\n",
       "         -1.3300e-01,  3.1057e-01, -5.5125e-02,  2.1672e-01,  4.2086e-03,\n",
       "          1.2447e-01,  7.0247e-02, -5.1777e-02,  8.1937e-02,  2.8656e-01,\n",
       "          4.6151e-03,  1.8913e-01, -2.2937e-01, -1.9747e-01, -2.5782e-01,\n",
       "          1.8636e-01,  5.8540e-02,  4.5639e-02, -1.3394e-01,  6.5096e-03,\n",
       "          4.4221e-01, -7.2945e-02, -5.5352e-03,  1.5902e-01,  3.3598e-01,\n",
       "          2.1134e-01, -3.1201e-02,  1.4178e-01, -1.1607e-01, -1.0096e-01,\n",
       "          2.5346e-01,  1.4458e-01,  7.2361e-02, -1.2401e-02, -3.2370e-01,\n",
       "         -2.0378e-02,  9.1925e-02,  1.3404e+00,  7.8867e-02,  2.6674e-02,\n",
       "          2.0070e-01,  1.6535e-02, -7.3361e-02, -2.4295e-01,  2.9986e-01,\n",
       "          2.5448e-01,  1.2613e-01, -3.9061e-02,  1.1476e-01, -1.2231e-01,\n",
       "         -2.0507e-01, -1.1872e-02,  1.9056e-01,  5.2914e-02,  1.2171e-01,\n",
       "         -2.1321e-01,  1.8319e-01, -7.9405e-02,  5.5996e-02, -5.7639e-02,\n",
       "         -3.2464e-01, -2.7739e-02, -9.1723e-02, -9.4535e-02, -1.4464e-01,\n",
       "         -1.2075e-01,  2.2768e-01,  1.8153e-01, -1.9708e-01, -2.7437e-01,\n",
       "         -5.2851e-01,  1.1129e+00,  7.4122e-02, -1.6188e-01, -1.3519e-02,\n",
       "          1.4743e-01, -9.2692e-02, -4.2594e-02,  1.4096e-01,  2.1862e-01,\n",
       "         -9.8956e-02, -1.5609e-01,  1.0342e-01,  1.8255e-01,  1.4976e-01,\n",
       "         -2.7884e-02,  7.6394e-01, -1.4906e-01,  8.2581e-02,  7.3296e-02,\n",
       "          1.5545e-01,  1.7724e-01, -1.0694e-01, -4.1212e-01, -3.0346e-01,\n",
       "         -2.0468e-01,  1.1816e-02,  1.8647e-01,  2.0743e-01,  1.7826e-01,\n",
       "         -1.3123e-01, -2.0936e-01,  3.1381e-01, -1.2333e-01, -5.8601e-02,\n",
       "          1.4561e-01,  1.2455e-02, -7.0780e-02,  1.2439e-01,  1.9909e-01,\n",
       "         -9.7549e-02, -2.4073e-01,  8.4320e-02,  1.9366e-01,  5.8192e-02,\n",
       "         -2.4837e-01, -3.9474e-01, -3.3803e-01,  1.1430e-01,  2.6951e-02,\n",
       "          5.5158e-02,  9.9056e-02, -1.1751e-01, -5.1982e-02,  6.7939e-02,\n",
       "         -1.4831e-01, -9.2635e-02, -6.9334e-02,  2.3419e-02, -1.3666e-01,\n",
       "          1.6781e-01,  1.1838e-01, -1.0927e-01, -1.3770e-01,  1.3135e-02,\n",
       "          1.3371e-01, -2.7289e-02,  5.5254e-02, -9.8559e-03, -2.1324e-01,\n",
       "         -7.3178e-02,  1.2287e-01, -4.1111e-02, -1.8449e-01, -3.2350e-01,\n",
       "          2.1753e-01,  1.5151e-01,  1.6217e-01,  9.0199e-02, -3.7094e-02,\n",
       "          8.9493e-02, -6.4128e-02, -2.3840e-01,  2.7410e-01,  6.7423e-02,\n",
       "          1.0561e-01, -2.1592e-03, -1.2679e-01, -1.2053e-01,  1.5938e-02,\n",
       "         -3.2527e-01,  4.0235e-02,  2.4296e-01, -1.3199e-01, -1.4000e-01,\n",
       "          1.3745e-01, -7.9453e-02,  8.5562e-02, -9.1363e-02,  1.0521e-02,\n",
       "          1.1684e-01, -1.3988e-01,  4.3998e-02,  1.7960e-02,  1.7531e-01,\n",
       "          1.2315e-01, -1.0354e-01,  9.5456e-03,  1.0831e-01,  4.9891e-03,\n",
       "         -1.4330e-01, -1.2944e-01, -1.4552e-02, -1.2529e-01,  1.0417e-01,\n",
       "         -6.7777e-02,  3.6176e-02, -1.0470e-01, -1.4965e-02, -1.3677e-01,\n",
       "         -2.4409e-01, -2.3566e-01, -1.5233e-01,  3.3304e-01,  4.6872e-02,\n",
       "          1.5761e-03,  2.5426e-01, -3.7104e-01,  3.9172e-01,  1.5297e-01,\n",
       "         -2.3011e-01, -6.7894e-02,  4.3814e-02, -2.0516e-01,  4.7039e-03,\n",
       "         -1.5345e-01,  1.1341e-01, -2.2237e-01,  2.9436e-02,  3.5200e-01,\n",
       "         -2.7242e-01, -1.5071e-01, -2.4958e-01, -6.1204e-02, -2.8815e-01,\n",
       "         -8.7968e-02, -3.6116e-01, -2.8994e-01, -1.9701e-02, -9.4269e-02,\n",
       "         -1.6828e-01,  1.7895e-01,  3.0548e-01, -1.0286e-01, -7.8868e-03,\n",
       "         -1.8351e-01, -2.7882e-01,  1.9623e-01, -2.5421e-02,  2.1852e-01,\n",
       "          4.5399e-01, -4.7588e-03, -5.4432e-02, -5.0468e-02,  5.9853e-02,\n",
       "         -3.3782e-02, -1.2641e-01,  8.0825e-02,  1.2883e-01, -1.6844e-01,\n",
       "          3.6612e-02,  1.4562e-01,  2.2725e-01, -1.8357e-01, -2.7564e-01,\n",
       "          1.2676e-01,  1.8689e-02,  1.1199e-01, -2.4423e-01,  6.6204e-02,\n",
       "          1.6659e-01, -9.4392e-02,  5.8944e-02, -5.7070e-02,  7.3812e-02,\n",
       "          4.0672e-01, -6.2068e-02, -1.2242e-01,  2.2239e-01,  3.8539e-01,\n",
       "          8.9461e-02, -6.2826e-02, -3.5134e-02, -8.7834e-02,  3.4615e-02,\n",
       "          8.4902e-02,  2.8439e-01,  2.1722e-01,  1.0903e-01,  1.2715e-01,\n",
       "         -3.8421e-01, -1.5105e-01,  2.1808e-01, -9.2623e-02, -4.4051e-01,\n",
       "         -3.1955e-01, -2.3065e-01, -5.6844e-02,  2.4761e-01, -5.1167e-02,\n",
       "          2.1335e-01,  1.0087e-01, -2.9482e-01,  1.6396e-01, -6.2869e-02,\n",
       "          3.2561e-02,  1.4373e-01, -2.1226e-01,  1.4838e-01,  3.9979e-02,\n",
       "          1.4560e-01,  1.9304e-02, -1.1265e-01, -4.0770e-01,  3.6567e-02,\n",
       "          6.0423e-02, -2.0730e-01,  1.0954e-01,  5.1026e-02, -3.8509e-02,\n",
       "          1.3629e-01, -3.5795e-01, -1.9559e-01, -4.1739e-02, -2.7428e-02,\n",
       "          2.3496e-01, -2.0647e-01, -6.6377e-02,  1.5882e-01,  7.0732e-02,\n",
       "          1.9729e-01, -2.1172e-01, -5.7085e-02, -1.0428e-02,  2.6602e-01,\n",
       "          2.2054e-01, -1.2878e-01, -1.7998e-01, -9.4714e-02, -4.6447e-02,\n",
       "          6.1832e-02, -2.1316e-01,  9.9077e-02, -1.0367e-01,  9.9358e-02,\n",
       "         -6.2603e-02, -3.2249e-01, -2.1392e-02, -4.3291e-02, -2.7536e-01,\n",
       "         -1.6295e-01,  1.5185e-01,  8.4377e-02, -2.6299e-01, -1.9028e-01,\n",
       "         -3.3593e-01, -1.1183e-01,  8.0995e-02, -2.0961e-01,  7.2705e-02,\n",
       "          3.2803e-02, -9.3140e-02,  2.2211e-01, -5.9392e-02, -1.7534e-01,\n",
       "         -9.2621e-02,  2.6030e-02, -1.9912e-01,  6.9357e-02,  1.6677e-01,\n",
       "         -1.2446e-01,  2.8240e-01,  2.3896e-01, -1.0167e-01, -1.0009e-01,\n",
       "         -1.7404e-01, -5.3099e-02, -3.0209e-01]),\n",
       " 'h.10.mlp.c_proj.weight': tensor([[ 0.0526,  0.2037, -0.2281,  ...,  0.0285,  0.0621,  0.0854],\n",
       "         [ 0.1654, -0.2038,  0.0162,  ..., -0.0902, -0.0277, -0.1632],\n",
       "         [ 0.1352,  0.1129, -0.0354,  ...,  0.0646,  0.0649, -0.1546],\n",
       "         ...,\n",
       "         [ 0.4044,  0.2177, -0.1393,  ...,  0.1725,  0.0065,  0.1030],\n",
       "         [ 0.0533,  0.0962, -0.4815,  ..., -0.0038, -0.1052,  0.1185],\n",
       "         [ 0.1796, -0.1290,  0.1392,  ...,  0.0440,  0.2462, -0.1688]])}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533af3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
